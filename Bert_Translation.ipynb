{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/naoya526/jpn2ita/blob/main/Bert_Translation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b42af237",
      "metadata": {
        "id": "b42af237"
      },
      "source": [
        "## Import Module"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5f189bde",
      "metadata": {
        "id": "5f189bde"
      },
      "source": [
        "I used materials below:\n",
        "[1]`06_Attention_and_Transformers_in_BERT.ipynb`\n",
        "[2]`English_to_italian_automatic_translation.ipynb`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "61e92cdc",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "61e92cdc",
        "outputId": "5b433b36-c15e-4a91-8cdd-a4865e2be25a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2.0.2\n",
            "2.6.0+cu124\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import re\n",
        "import random\n",
        "import itertools\n",
        "import math\n",
        "from pathlib import Path\n",
        "\n",
        "import tqdm\n",
        "\n",
        "import numpy as np\n",
        "print(np.__version__)\n",
        "\n",
        "import torch\n",
        "print(torch.__version__)\n",
        "\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.optim import Adam\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "\n",
        "import transformers\n",
        "from tokenizers import BertWordPieceTokenizer\n",
        "from transformers import BertTokenizer, BertConfig\n",
        "\n",
        "### Suppress useless warnings\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\", message=\"The secret `HF_TOKEN` does not exist\")\n",
        "\n",
        "from collections import defaultdict\n",
        "from transformers import AutoTokenizer"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6151fdbd",
      "metadata": {
        "id": "6151fdbd"
      },
      "source": [
        "## Define Model\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "C06d3zDIDp9k",
      "metadata": {
        "id": "C06d3zDIDp9k"
      },
      "source": [
        "\n",
        "### Encoder (Bert) part\n",
        "Here, There's the function for implementing Encoder(Bert). I implemented with refering to [1]`06_Attention_and_Transformers_in_BERT.ipynb` and the paper.\n",
        "- `MultiHeadAttention`\n",
        "- `PositionwiseFeedForward`\n",
        "- `Encoder Block`\n",
        "- `BertEmbeddings` (Embedding for words)\n",
        "- `Bert`\n",
        "Bert is highly possible to understand meaning, but it is not enough for produce translation.\n",
        "Hence, In the next part, I implement Decoder. It is quite similar to Bert."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "b9f946b7",
      "metadata": {
        "id": "b9f946b7"
      },
      "outputs": [],
      "source": [
        "class MultiHeadAttention(nn.Module):\n",
        "    \"\"\"\n",
        "    - Query, Key, Value\n",
        "    - Scaled Dot Product Attention: softmax(QK^T / sqrt(d_k))V\n",
        "    \"\"\"\n",
        "    def __init__(self, d_model, num_heads, dropout=0.1):\n",
        "        super().__init__()\n",
        "        assert d_model % num_heads == 0, \"d_model must be divisible by num_heads\"\n",
        "\n",
        "        self.d_model = d_model\n",
        "        self.num_heads = num_heads\n",
        "        self.head_dim = d_model // num_heads\n",
        "        self.dropout = torch.nn.Dropout(dropout)\n",
        "\n",
        "        # Q, K, V linear Conversion\n",
        "        self.query = torch.nn.Linear(d_model, d_model)\n",
        "        self.key = torch.nn.Linear(d_model, d_model)\n",
        "        self.value = torch.nn.Linear(d_model, d_model)\n",
        "\n",
        "        self.out_proj = torch.nn.Linear(d_model, d_model)\n",
        "\n",
        "    def forward(self, x, mask=None):\n",
        "        batch_size, seq_len, d_model = x.shape\n",
        "\n",
        "        # step1: Q, K, V\n",
        "        query = self.query(x)  # (batch, seq_len, d_model)\n",
        "        key = self.key(x)      # (batch, seq_len, d_model)\n",
        "        value = self.value(x)  # (batch, seq_len, d_model)\n",
        "\n",
        "        # step2: Multi-Head\n",
        "        query = query.view(batch_size, seq_len, self.num_heads, self.head_dim)\n",
        "        key = key.view(batch_size, seq_len, self.num_heads, self.head_dim)  # 修正: query.shape → batch_size\n",
        "        value = value.view(batch_size, seq_len, self.num_heads, self.head_dim)\n",
        "\n",
        "        # step3: Change Dimention for Calclate Efficiently\n",
        "        query = query.permute(0, 2, 1, 3)  # (batch, num_heads, seq_len, head_dim)\n",
        "        key = key.permute(0, 2, 1, 3)\n",
        "        value = value.permute(0, 2, 1, 3)\n",
        "\n",
        "        # ステップ4: Scaled Dot-Product Attention\n",
        "        # scores = Q @ K^T / sqrt(d_k)\n",
        "        scores = torch.matmul(query, key.transpose(-2, -1)) / math.sqrt(self.head_dim)\n",
        "\n",
        "        # ステップ5: マスク処理（オプション）\n",
        "        if mask is not None:\n",
        "            # mask形状: (batch, 1, 1, seq_len) または (batch, 1, seq_len, seq_len) など、scores形状にブロードキャスト可能な形状\n",
        "            # scores形状: (batch, num_heads, seq_len, seq_len)\n",
        "            # 0を-1e9に変換（Softmaxで0になるように）→ 加算によるマスキングに変更\n",
        "            # scores = scores.masked_fill(mask == 0, -1e9) # 元のコード\n",
        "            scores = scores + mask # 加算によるマスキングに変更\n",
        "\n",
        "        # ステップ6: Softmax + Dropout\n",
        "        weights = F.softmax(scores, dim=-1)  # (batch, num_heads, seq_len, seq_len)\n",
        "        weights = self.dropout(weights)\n",
        "        # ステップ7: Value との積\n",
        "        context = torch.matmul(weights, value)\n",
        "        # ステップ8: ヘッドを結合して元の形状に戻す\n",
        "        context = context.permute(0, 2, 1, 3)\n",
        "        # → (batch, seq_len, d_model)\n",
        "        context = context.contiguous().view(batch_size, seq_len, self.num_heads * self.head_dim)\n",
        "\n",
        "        # ステップ9: 最終的な線形変換\n",
        "        return self.out_proj(context)  # 修正: output_linear → out_proj\n",
        "\n",
        "class PositionwiseFeedForward(nn.Module):\n",
        "    \"\"\"\n",
        "    ヒント:\n",
        "    - 2層のフィードフォワードネットワーク\n",
        "    - 中間層では次元を拡張（通常4倍）\n",
        "    - GELU活性化関数を使用\n",
        "    - ドロップアウトも忘れずに\n",
        "    \"\"\"\n",
        "    def __init__(self, d_model, d_ff, dropout=0.1):\n",
        "        super().__init__()\n",
        "        self.linear1 = nn.Linear(d_model, d_ff)  # 入力次元 → 中間次元\n",
        "        self.linear2 = nn.Linear(d_ff, d_model)  # 中間次元\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "        self.gelu = nn.GELU()\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.linear1(x)\n",
        "        x = self.gelu(x)\n",
        "        x = self.dropout(x)\n",
        "        x = self.linear2(x)\n",
        "        x = self.dropout(x)\n",
        "        return x\n",
        "\n",
        "class EncoderBlock(nn.Module):\n",
        "    \"\"\"\n",
        "    ヒント:\n",
        "    - Multi-Head Attention + Residual Connection + Layer Norm\n",
        "    - Feed Forward + Residual Connection + Layer Norm\n",
        "    - Which is better??: Pre-LN vs Post-LN\n",
        "    \"\"\"\n",
        "    def __init__(self, d_model, num_heads, d_ff, dropout=0.1):\n",
        "        super().__init__()\n",
        "        self.attention = MultiHeadAttention(d_model,num_heads)\n",
        "        self.ffn = PositionwiseFeedForward(d_model,d_ff)\n",
        "\n",
        "        self.layer_norm1 = nn.LayerNorm(normalized_shape=d_model, eps=1e-6)\n",
        "        self.layer_norm2 = nn.LayerNorm(normalized_shape=d_model, eps=1e-6)\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "    def forward(self, x, mask=None):\n",
        "        #Attention block\n",
        "        #TODO implement transformer block\n",
        "        residual = x\n",
        "        #print(\"Took Residual...\",x.shape)\n",
        "        x = self.layer_norm1(x)\n",
        "        #print(\"calculating layer norm...\",x.shape)\n",
        "        x = self.dropout(self.attention(x,mask))\n",
        "        #print(\"calculating Attention...\",x.shape)\n",
        "        x = x + residual\n",
        "        #print(\"calculating Residual Connection...\",x.shape)\n",
        "        #ffnn\n",
        "        residual = x\n",
        "        x = self.layer_norm2(x)\n",
        "        #print(\"calculating layer norm...\",x.shape)\n",
        "        x = self.dropout(self.ffn(x))\n",
        "        #print(\"calculating ffn...\",x.shape)\n",
        "        x = x + residual\n",
        "        return x\n",
        "\n",
        "\n",
        "class BertEmbeddings(nn.Module):\n",
        "    \"\"\"\n",
        "    - Token Embeddings (語彙サイズ × d_model)\n",
        "    - Position Embeddings (最大系列長 × d_model)\n",
        "    - Segment Embeddings (2 × d_model, NSPタスク用)\n",
        "    - 3つを足し合わせてLayerNormとDropout\n",
        "    \"\"\"\n",
        "    def __init__(self, vocab_size, d_model, max_seq_len=512, dropout=0.1):\n",
        "        super().__init__()\n",
        "        # TODO: 3種類の埋め込みを実装\n",
        "        self.d_model = d_model\n",
        "        self.token = torch.nn.Embedding(vocab_size, d_model, padding_idx=0)\n",
        "        self.position = torch.nn.Embedding(max_seq_len, d_model)\n",
        "        self.segment = torch.nn.Embedding(2, d_model)  # 2つのセグメント（0と1）\n",
        "        self.layer_norm = nn.LayerNorm(d_model)\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "        #Embedding: Lookup table that keep meaning vector of words\n",
        "    def forward(self, input_ids, token_type_ids=None):\n",
        "        # TODO: 埋め込みの計算を実装\n",
        "        batch_size, seq_len = input_ids.shape\n",
        "        # Step 1: Token Embeddings\n",
        "        token_embeddings = self.token(input_ids)\n",
        "        # Step 2: Position Embeddings\n",
        "        position_ids = torch.arange(seq_len, device=input_ids.device).unsqueeze(0)\n",
        "        position_ids = position_ids.expand(batch_size, -1)  # 🔧 バッチ次元を拡張\n",
        "        position_embeddings = self.position(position_ids)\n",
        "        # Step 3: Segment Embeddings\n",
        "        if token_type_ids is None:\n",
        "            token_type_ids = torch.zeros_like(input_ids)  # 全て0（単一文）\n",
        "        segment_embeddings = self.segment(token_type_ids)  # (batch, seq_len, d_model)\n",
        "        embeddings = token_embeddings + position_embeddings + segment_embeddings\n",
        "        embeddings = self.dropout(self.layer_norm(embeddings))\n",
        "\n",
        "        return embeddings\n",
        "\n",
        "class Bert(nn.Module):\n",
        "    \"\"\"\n",
        "    BERT実装の最終形\n",
        "\n",
        "    学習のヒント:\n",
        "    1. 論文を読んで全体像を理解\n",
        "    2. 小さな部品から実装（Attention → FFN → Block → Full Model）\n",
        "    3. 各層で print(tensor.shape) してサイズを確認\n",
        "    4. 簡単なダミーデータでテスト\n",
        "    5. 事前学習は計算量が大きいので、小さいモデルから開始\n",
        "\n",
        "    重要な概念:\n",
        "    - Bidirectional: 左右両方向の文脈を見る\n",
        "    - Masked Language Model: ランダムにマスクした単語を予測\n",
        "    - Next Sentence Prediction: 2つの文が連続するかを予測\n",
        "    - Attention Weights: どの単語に注目しているかの可視化\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, vocab_size, d_model=768, num_layers=12, num_heads=12, d_ff=3072, max_seq_len=512, dropout=0.1):\n",
        "        super().__init__()\n",
        "        self.d_model = d_model\n",
        "        self.num_layers = num_layers\n",
        "        self.heads = num_heads\n",
        "        # paper noted 4*d_model size for ff\n",
        "        self.feed_forward_hidden = d_model * 4\n",
        "        # embedding for BERT, sum of positional, segment, token embeddings\n",
        "        self.embedding = BertEmbeddings(vocab_size, d_model, max_seq_len, dropout)\n",
        "\n",
        "        self.encoder_blocks = torch.nn.ModuleList(\n",
        "            [EncoderBlock(d_model, num_heads, d_model * 4, dropout) for _ in range(num_layers)])\n",
        "\n",
        "    def forward(self, input_ids, attention_mask=None, token_type_ids=None):\n",
        "        # TODO: BERT全体のforward passを実装\n",
        "        if attention_mask is None:\n",
        "            attention_mask = (input_ids != 0).float()\n",
        "        if attention_mask.dim() == 2:\n",
        "            # (batch, seq_len) → (batch, 1, 1, seq_len)\n",
        "            extended_attention_mask = attention_mask.unsqueeze(1).unsqueeze(2)\n",
        "            # print(\"squeeze is required\") # デバッグプリントを削除\n",
        "        elif attention_mask.dim() == 4:\n",
        "            # 既に正しい形状の場合はそのまま使用\n",
        "            extended_attention_mask = attention_mask\n",
        "            # print(\"squeeze is not required\") # デバッグプリントを削除\n",
        "        else:\n",
        "             raise ValueError(f\"Attention mask should be 2D or 4D, but got {attention_mask.dim()}D\")\n",
        "\n",
        "        # 0を-1e9に変換（Softmaxで0になるように） - 加算によるマスキングのために値を調整\n",
        "        extended_attention_mask = (1.0 - extended_attention_mask) * -1e9\n",
        "\n",
        "\n",
        "        # embedding the indexed sequence to sequence of vectors\n",
        "        x = self.embedding(input_ids, token_type_ids)\n",
        "        # running over multiple transformer blocks\n",
        "        for encoder in self.encoder_blocks:\n",
        "            x = encoder.forward(x, extended_attention_mask) # 修正後のMultiHeadAttentionは加算マスクを期待\n",
        "        return x"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "dfc507b7",
      "metadata": {
        "id": "dfc507b7"
      },
      "source": [
        "### Decoder part\n",
        "This part, I implemented these functions:\n",
        "- `CrossAttention`(English Queue, Italian Key, Italian Value)\n",
        "- `DecoderBlock`\n",
        "- `BertTranslationModel`(Bert + Decoder Embedding + DecoderBlock*`num_layers`)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "_pie-kLFt9PO",
      "metadata": {
        "id": "_pie-kLFt9PO"
      },
      "outputs": [],
      "source": [
        "class CrossAttention(nn.Module):\n",
        "    \"\"\"\n",
        "    this module is implemented with modifying MultiHeadAttention.\n",
        "    Query: English\n",
        "    Key, Value: Italian\n",
        "    You can see the difference in forward input\n",
        "    \"\"\"\n",
        "    def __init__(self, d_model, num_heads, dropout=0.1):\n",
        "        super().__init__() # initialization\n",
        "        assert d_model % num_heads == 0, \"d_model must be divisible by num_heads\"\n",
        "\n",
        "        self.d_model = d_model\n",
        "        self.num_heads = num_heads\n",
        "        self.head_dim = d_model // num_heads  # dimention of each head\n",
        "        self.dropout = torch.nn.Dropout(dropout)\n",
        "\n",
        "        # Q, K, V の線形変換（修正：torch.nn.linear → torch.nn.Linear）\n",
        "        self.query = torch.nn.Linear(d_model, d_model)\n",
        "        self.key = torch.nn.Linear(d_model, d_model)\n",
        "        self.value = torch.nn.Linear(d_model, d_model)\n",
        "\n",
        "        # 最終的な出力変換\n",
        "        self.out_proj = torch.nn.Linear(d_model, d_model)\n",
        "\n",
        "    def forward(self, query_input, key_value_input, mask=None): # here is the difference\n",
        "        batch_size, q_len, _ = query_input.shape\n",
        "        _, kv_len, _ = key_value_input.shape\n",
        "        # ステップ1: Q, K, V を線形変換で生成\n",
        "        query = self.query(query_input)  # (batch, seq_len, d_model)\n",
        "        key = self.key(key_value_input)      # (batch, seq_len, d_model)\n",
        "        value = self.value(key_value_input)  # (batch, seq_len, d_model)\n",
        "\n",
        "        # ステップ2: Multi-Head用に次元を変形\n",
        "        query = query.view(batch_size, q_len, self.num_heads, self.head_dim)\n",
        "        key = key.view(batch_size, kv_len, self.num_heads, self.head_dim)  # 修正: query.shape → batch_size\n",
        "        value = value.view(batch_size, kv_len, self.num_heads, self.head_dim)\n",
        "\n",
        "        query = query.permute(0, 2, 1, 3)  # (batch, num_heads, seq_len, head_dim)\n",
        "        key = key.permute(0, 2, 1, 3)\n",
        "        value = value.permute(0, 2, 1, 3)\n",
        "\n",
        "        # ステップ4: Scaled Dot-Product Attention\n",
        "        # scores = Q @ K^T / sqrt(d_k)\n",
        "        scores = torch.matmul(query, key.transpose(-2, -1)) / math.sqrt(self.head_dim)\n",
        "\n",
        "        # ステップ5: マスク処理（オプション）\n",
        "        if mask is not None:\n",
        "            # mask形状: (batch, 1, 1, seq_len) → scores形状: (batch, num_heads, seq_len, seq_len)\n",
        "            scores = scores + mask  # ブロードキャストで加算\n",
        "\n",
        "        # ステップ6: Softmax + Dropout\n",
        "        weights = F.softmax(scores, dim=-1)  # (batch, num_heads, seq_len, seq_len)\n",
        "        weights = self.dropout(weights)\n",
        "        # ステップ7: Value との積\n",
        "        context = torch.matmul(weights, value)\n",
        "        # ステップ8: ヘッドを結合して元の形状に戻す\n",
        "        context = context.permute(0, 2, 1, 3)\n",
        "        # → (batch, seq_len, d_model)\n",
        "        context = context.contiguous().view(batch_size, q_len, self.num_heads * self.head_dim)\n",
        "\n",
        "        # ステップ9: 最終的な線形変換\n",
        "        return self.out_proj(context)  # 修正: output_linear → out_proj\n",
        "\n",
        "class DecoderBlock(nn.Module):\n",
        "    \"\"\"\n",
        "    Basically similar to EncoderBlock, but refer to the infomation of Input(English context)\n",
        "    \"\"\"\n",
        "    def __init__(self, d_model, num_heads, d_ff, dropout=0.1):\n",
        "        super().__init__()\n",
        "        #First, implement Self Attention\n",
        "        self.self_attention = MultiHeadAttention(d_model,num_heads)\n",
        "        #Second, implement Cross Attention\n",
        "        self.cross_attention = CrossAttention(d_model, num_heads)\n",
        "        #Third, FFNN\n",
        "        self.ffn = PositionwiseFeedForward(d_model,d_ff)\n",
        "\n",
        "        self.layer_norm1 = nn.LayerNorm(normalized_shape=d_model, eps=1e-6)\n",
        "        self.layer_norm2 = nn.LayerNorm(normalized_shape=d_model, eps=1e-6)\n",
        "        self.layer_norm3 = nn.LayerNorm(normalized_shape=d_model, eps=1e-6)\n",
        "\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "    def forward(self, x, encoder_output, self_mask=None, cross_mask=None):\n",
        "        #Self Attention\n",
        "        residual = x\n",
        "        x = self.layer_norm1(x)\n",
        "        x = self.self_attention(x,mask=self_mask)\n",
        "        x = self.dropout(x) + residual\n",
        "\n",
        "        #Cross Attention\n",
        "        residual = x\n",
        "        x = self.layer_norm2(x)\n",
        "        x = self.cross_attention(\n",
        "            query_input=x,\n",
        "            key_value_input=encoder_output,\n",
        "            mask=cross_mask\n",
        "        )\n",
        "        x = self.dropout(x) + residual\n",
        "\n",
        "        residual = x\n",
        "        x = self.layer_norm3(x)\n",
        "        x = self.ffn(x)\n",
        "        x = self.dropout(x) + residual\n",
        "        return x\n",
        "\n",
        "class BertTranslationModel(nn.Module):\n",
        "    \"\"\"\n",
        "    Ita2Eng Translation Model\n",
        "    Encoder: Bert\n",
        "    Decoder: BertEmbedding, DecoderBlock*N, FFN\n",
        "    \"\"\"\n",
        "    def __init__(self,\n",
        "                 ita_vocab_size,  # イタリア語語彙サイズ\n",
        "                 eng_vocab_size,  # 英語語彙サイズ\n",
        "                 max_seq_len,\n",
        "                 d_model=512,\n",
        "                 num_layers=6,\n",
        "                 num_heads=8,\n",
        "                 dropout=0.1):\n",
        "        super().__init__()\n",
        "\n",
        "        self.encoder = Bert(\n",
        "            vocab_size=eng_vocab_size,\n",
        "            d_model=d_model,\n",
        "            num_layers=num_layers,\n",
        "            num_heads=num_heads,\n",
        "            max_seq_len=max_seq_len,\n",
        "            dropout=dropout\n",
        "        )\n",
        "\n",
        "        self.decoder_embeddings = BertEmbeddings(\n",
        "            vocab_size=ita_vocab_size,\n",
        "            d_model=d_model,\n",
        "            max_seq_len=max_seq_len,\n",
        "            dropout=dropout\n",
        "        )\n",
        "\n",
        "        self.decoder_blocks = nn.ModuleList([\n",
        "            DecoderBlock(\n",
        "                d_model=d_model,\n",
        "                num_heads=num_heads,\n",
        "                d_ff=d_model * 4, #based on the paper of Bert\n",
        "                dropout=dropout)\n",
        "            for _ in range(num_layers)\n",
        "        ])\n",
        "\n",
        "        self.output_proj = nn.Linear(d_model, ita_vocab_size)\n",
        "\n",
        "    def forward(self,\n",
        "                eng_ids,\n",
        "                ita_ids,\n",
        "                eng_mask=None,\n",
        "                ita_mask=None,\n",
        "                eng_token_type_ids=None,\n",
        "                ita_token_type_ids=None):\n",
        "        # understand english\n",
        "        encoder_output = self.encoder(input_ids=eng_ids, attention_mask=eng_mask, token_type_ids=eng_token_type_ids)\n",
        "        # produce Italian\n",
        "        decoder_input = self.decoder_embeddings(input_ids=ita_ids, token_type_ids=ita_token_type_ids)\n",
        "\n",
        "        for decoder_block in self.decoder_blocks:\n",
        "            decoder_input = decoder_block(\n",
        "                x=decoder_input,\n",
        "                encoder_output=encoder_output,\n",
        "                self_mask=ita_mask,               # 英語のCausal mask\n",
        "                cross_mask=eng_mask\n",
        "                )\n",
        "        logits = self.output_proj(decoder_input)\n",
        "        return logits"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d02d832e",
      "metadata": {
        "id": "d02d832e"
      },
      "source": [
        "## Use model\n",
        "In this part, I followed the configuration of [2]`English_to_italian_automatic_translation.ipynb`.\n",
        "\n",
        "---\n",
        "### Prepare Dataset\n",
        "for Bert, `<sos>`and `<eos>` are not required. Hence, ignore these token."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "EZbXW_bCx1Ef",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EZbXW_bCx1Ef",
        "outputId": "9dc8849c-499c-43a5-b91b-160744fdbc8e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1_npGYZk13fs5hE0kAggiSrmKkqW3OrLT\n",
            "To: <_io.BufferedWriter name='<stdout>'>\n",
            "\r  0% 0.00/3.92M [00:00<?, ?B/s]\r 53% 2.10M/3.92M [00:00<00:00, 18.9MB/s]\r100% 3.92M/3.92M [00:00<00:00, 21.4MB/s]\n"
          ]
        }
      ],
      "source": [
        "# Download the files\n",
        "URL = \"https://drive.google.com/file/d/1_npGYZk13fs5hE0kAggiSrmKkqW3OrLT/view?usp=sharing\"\n",
        "!gdown --fuzzy $URL -O- | tar -xz"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "7uYUnrAouYf1",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7uYUnrAouYf1",
        "outputId": "dbfe051a-e190-43c4-e665-f65e1ddfbe0f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['hi .', 'hi .', 'run !', 'run !', 'run !', 'who ?', 'wow !', 'duck !', 'duck !', 'jump !', 'jump !', 'jump !', 'jump .', 'jump .', 'jump .', 'stay .', 'stay .', 'stay .', 'stay .', 'stay .', 'stay .', 'stay .', 'stay .', 'stay .', 'stop !', 'stop !', 'stop !', 'wait !', 'wait !', 'wait !', 'wait .', 'wait .', 'wait .', 'do it .', 'do it .', 'do it .', 'do it .', 'do it .', 'do it .', 'go on .', 'go on .', 'go on .', 'go on .', 'go on .', 'go on .', 'hello !', 'hello !', 'hello !', 'hello .', 'i hid .']\n",
            "['ciao !', 'ciao .', 'corri !', 'corra !', 'correte !', 'chi ?', 'wow !', 'amore !', 'tesoro !', 'salta !', 'salti !', 'saltate !', 'salta .', 'salti .', 'saltate .', 'resta .', 'stai .', 'stia .', 'state .', 'resti .', 'restate .', 'rimani .', 'rimanga .', 'rimanete .', 'fermati !', 'fermatevi !', 'si fermi !', 'aspetta !', 'aspettate !', 'aspetti !', 'aspetta .', 'aspetti .', 'aspettate .', 'fallo .', 'falla .', 'lo faccia .', 'la faccia .', 'fatelo .', 'fatela .', 'vai avanti .', 'continua .', 'continui .', 'continuate .', 'vada avanti .', 'andate avanti .', 'buongiorno !', 'ciao !', 'salve .', 'ciao .', 'mi sono nascosto .']\n",
            "333112 333112\n"
          ]
        }
      ],
      "source": [
        "# for Bert, <sos> and <eos> are not required\n",
        "#SPECIAL = [\"<sos>\", \"<eos>\", \"<pad>\"]\n",
        "SPECIAL = [\"<pad>\"]\n",
        "MAXLEN = 20\n",
        "\n",
        "f = open(\"text-eng.txt\")\n",
        "# Define the list of all tokens in the English set ...\n",
        "ENG_VOCABULARY = []\n",
        "for line in f:\n",
        "    line = line.strip()\n",
        "    # Remove <sos> and <eos>\n",
        "    line = line.replace('<sos>', '').replace('<eos>', '').strip()\n",
        "    if line == \"\":\n",
        "        continue\n",
        "\n",
        "    ENG_VOCABULARY.append(line)\n",
        "f.close()\n",
        "print(ENG_VOCABULARY[:50])\n",
        "\n",
        "f = open(\"text-ita.txt\")\n",
        "# Define the list of all tokens in the Italian set ...\n",
        "ITA_VOCABULARY = []\n",
        "for line in f:\n",
        "    line = line.strip()\n",
        "    # Remove <sos> and <eos>\n",
        "    line = line.replace('<sos>', '').replace('<eos>', '').strip()\n",
        "    if line == \"\":\n",
        "        continue\n",
        "    ITA_VOCABULARY.append(line)\n",
        "f.close()\n",
        "print(ITA_VOCABULARY[:50])\n",
        "# Make sure that the three special tokens have the same indices in the two vocabularies.\n",
        "# Assign here the three indices...\n",
        "\n",
        "PAD = SPECIAL[0]\n",
        "\n",
        "# Inverse mappings.\n",
        "ENG_INVERSE = {w: n for n, w in enumerate(ENG_VOCABULARY)}\n",
        "ITA_INVERSE = {w: n for n, w in enumerate(ITA_VOCABULARY)}\n",
        "#print(ENG_INVERSE)\n",
        "print(len(ENG_VOCABULARY), len(ITA_VOCABULARY))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5I5NmJq4yeec",
      "metadata": {
        "id": "5I5NmJq4yeec"
      },
      "source": [
        "### Incremental approach to token vocabulary building\n",
        "In the lesson of Deep Learning, I learned the sophisticated way of tokenizing words called WordPiece tokenization.\n",
        "\n",
        "The WordPiece tokenization algorithm builds its vocabulary incrementally, starting from a basic alphabet and iteratively merging subword units based on their frequency and co-occurrence patterns. (cited from [1]`06_Attention_and_Transformers_in_Bert.ipynb`)\n",
        "\n",
        "---\n",
        "\n",
        "#### The demonstration of pretrained tokenizer\n",
        "\n",
        "In [1], Tokenizer `bert-base-cased` was used for English(For tokenization of English, it's used in this project as well). In this project, Tokenizier [3]`dbmdz/bert-base-italian-cased` for italian is used.\n",
        "[3]https://huggingface.co/dbmdz/bert-base-italian-cased  \n",
        "\\\n",
        "In this section, With using small scentence, The procedure will be explained.\n",
        "\n",
        "These procedure will be iterated:\n",
        "- Compute word frequencies\n",
        "- Split Words into Alphabet\n",
        "- Compute score of each pair\n",
        "- Merge the pair"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "TOiqXhYIus4m",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 623,
          "referenced_widgets": [
            "2e9d8d46c6ec48fe951721b4e76f592b",
            "3da62fc5a64d4c3ea2542ac9b113fd24",
            "1032c9e61e95402db775aff9cce1ca18",
            "4637b5195f3d420d814e08e4e398b5ce",
            "a3c52bfb52bb4fa7a27296a046cb1c4b",
            "869b8aa9f87f487fb80063f33a5e91bd",
            "d5a1679eb2904216ada827d92dff94da",
            "53dfb4d533874d11896e037c124fd534",
            "4115a5649cbf4cb4a4278f8f1666895d",
            "a6b04c4f79614f35bc25fc04582d3c8b",
            "d2e1e1d7dd904fbda1e3601fc0bbc569",
            "1dd7ef8c6c1640ba8645856555ca069f",
            "ef18ccda0fad4776a9b280f6bdbeaad2",
            "ec89de72cc574e30baa5d23963de7996",
            "6cc43f882a0f4c5e81b90a4dbb38f3dd",
            "1f144e67d8554224afc01425aba8ab23",
            "05811f120a8143168f61486b3613ea9b",
            "9d93f62bcf8741078d20a997bb9960b4",
            "7c6e5b1fac4f43aa877b74a13fccf32f",
            "434efc6dbf30423a93225cad1c6a9d81",
            "f3a14bc781f7481e8ee57515c1ba2c2c",
            "d96c988619c64eb8b84ae86e47336c78",
            "14b5c26f453d41de9a763cdbafbea0b5",
            "d1f5e0bdd1fb4d66bf1e8d4e7e321d6b",
            "0fb942d9f220454ea91f998cb698c36c",
            "dee916fdc3454c6d9dcb216fb674c174",
            "24382378281a46439757c89ad2f5caa4",
            "63d18be3e3e743f6abe6a6edd9f524ce",
            "f421de23a9264527af1d48bbd6ceef6c",
            "92a82591177643298bf2749fbccb01cd",
            "a2d1335d033e47249a57daa6d21b0bc1",
            "a513ba199499462593887b6693680b22",
            "a6e757a66e9e4078bdb81b17de443a29",
            "30b0db048345441fb21a06879a12df68",
            "11596ee1464047b28f7909e235d91b65",
            "a4fae2793d6f47edaca03a5cb381782c",
            "c67a9eda068b411ab97d123d961bb2fb",
            "2c6ced42184e4d36a5eae4a8808524c2",
            "efc43f4241da488b92471d3cceaeebad",
            "9c4b075f281a42f9b1e79ca50d958be5",
            "a4536c407a52425a9b926651a3546cdf",
            "288524b46f9d475ca11d0f4da252e4b4",
            "92b925803a2e4d599c51028f0cbc76b4",
            "c409bcd4f3774ab0a4d9cabfbf2992aa",
            "c7f076da6a9e490eb63feedf5937e13f",
            "ef0890f9392b48a1a1151dca46a3a195",
            "27634f8ccf224222acdee6d7a831d7cb",
            "6311e9773ad64bba91cbaeb3b0d7d596",
            "0ac53d7c93bc4ccf9de87bd02849bf14",
            "fbed29969e284d2e8d36b633c76a9d70",
            "051470dcfb93499c81c7514aa4ae4ed1",
            "9ce0fa0c1ae34d7e9b84b92004827d71",
            "fc4d1938624b456f98b28bd9ddee74bb",
            "708916a877894259a168cdecc240341f",
            "ce7e8343b7764cdda8664e40800d7196",
            "eec4cbb450e840d8a115758411b07746",
            "e66e76e8a52949f6977312d839da1d36",
            "229e51afde92482db9a22440cf07400f",
            "84f7358915714122ae601e96dfb129ca",
            "887be0e4aa454499a64b81fdc2dd51fd",
            "3a57cc5c45be4af9a74e6b46c9b4570b",
            "8a527d535a1c47ecb3bf2f1b84ee1563",
            "4ddf9edce7684defa88710dbcb0e3160",
            "26f72e6872004344acb5d09e76e33634",
            "bfd48d618cba46ee873ade9ad27c6e01",
            "daebbfd2f5ea43e2be0b951e46cbd6fe",
            "cf1166c1b400437a8484fd25e067709e",
            "2e438105059a4c4089f3ac7d54ae9f49",
            "5f9067a6eee940a9b33b67412596b5f9",
            "2dd6050915e94f5387ffad343b815776",
            "0f48b91d54104e999362ffa469db207c",
            "a53b8a3858e84e6189f64bfab4c648d2",
            "2038d092d9f74dd793996990564aea25",
            "cb4f496cd1744d1cb9b55d095dc4afdd",
            "53f7beacfb5e471db3a74591fd28f366",
            "a282ef9705744483871fad88e915fb2c",
            "0861ed936e004ea0903ddfd32a0a0fe5"
          ]
        },
        "id": "TOiqXhYIus4m",
        "outputId": "811d5cdd-9045-4e9b-9464-335572bdf96b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/49.0 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "2e9d8d46c6ec48fe951721b4e76f592b"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config.json:   0%|          | 0.00/570 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "1dd7ef8c6c1640ba8645856555ca069f"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "vocab.txt:   0%|          | 0.00/213k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "14b5c26f453d41de9a763cdbafbea0b5"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer.json:   0%|          | 0.00/436k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "30b0db048345441fb21a06879a12df68"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/59.0 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "c7f076da6a9e490eb63feedf5937e13f"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config.json:   0%|          | 0.00/433 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "eec4cbb450e840d8a115758411b07746"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "vocab.txt: 0.00B [00:00, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "cf1166c1b400437a8484fd25e067709e"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "English: ['This', 'is', 'the', 'Hugging', 'Face', 'Course', '.']\n",
            "English: ['This', 'chapter', 'is', 'about', 'tokenization', '.']\n",
            "English: ['This', 'section', 'shows', 'several', 'tokenizer', 'algorithms', '.']\n",
            "English: ['Hopefully', ',', 'you', 'will', 'be', 'able', 'to', 'understand', 'how', 'they', 'are', 'trained', 'and', 'generate', 'tokens', '.']\n",
            "Italian: ['Questo', 'è', 'il', 'corso', 'di', 'Hugging', 'Face', '.']\n",
            "Italian: ['Questo', 'capitolo', 'riguarda', 'la', 'tokenizzazione', '.']\n",
            "Italian: ['Questa', 'sezione', 'mostra', 'diversi', 'algoritmi', 'di', 'tokenizzazione', '.']\n",
            "Italian: ['Speriamo', 'che', 'tu', 'sia', 'in', 'grado', 'di', 'capire', 'come', 'vengono', 'addestrati', 'e', 'generano', 'token', '.']\n",
            "\n",
            "English Word Frequency: defaultdict(<class 'int'>, {'This': 3, 'is': 2, 'the': 1, 'Hugging': 1, 'Face': 1, 'Course': 1, '.': 4, 'chapter': 1, 'about': 1, 'tokenization': 1, 'section': 1, 'shows': 1, 'several': 1, 'tokenizer': 1, 'algorithms': 1, 'Hopefully': 1, ',': 1, 'you': 1, 'will': 1, 'be': 1, 'able': 1, 'to': 1, 'understand': 1, 'how': 1, 'they': 1, 'are': 1, 'trained': 1, 'and': 1, 'generate': 1, 'tokens': 1})\n",
            "Italian Word Frequency: defaultdict(<class 'int'>, {'Questo': 2, 'è': 1, 'il': 1, 'corso': 1, 'di': 3, 'Hugging': 1, 'Face': 1, '.': 4, 'capitolo': 1, 'riguarda': 1, 'la': 1, 'tokenizzazione': 2, 'Questa': 1, 'sezione': 1, 'mostra': 1, 'diversi': 1, 'algoritmi': 1, 'Speriamo': 1, 'che': 1, 'tu': 1, 'sia': 1, 'in': 1, 'grado': 1, 'capire': 1, 'come': 1, 'vengono': 1, 'addestrati': 1, 'e': 1, 'generano': 1, 'token': 1})\n",
            "\n",
            "English vocab size: 28996\n",
            "Italian vocab size: 31102\n"
          ]
        }
      ],
      "source": [
        "eng_tokenizer = AutoTokenizer.from_pretrained(\"bert-base-cased\")  # English\n",
        "ita_tokenizer = AutoTokenizer.from_pretrained(\"dbmdz/bert-base-italian-cased\")  # Italian\n",
        "\n",
        "### Example bilingual corpus\n",
        "eng_corpus = [\n",
        "    \"This is the Hugging Face Course.\",\n",
        "    \"This chapter is about tokenization.\",\n",
        "    \"This section shows several tokenizer algorithms.\",\n",
        "    \"Hopefully, you will be able to understand how they are trained and generate tokens.\",\n",
        "]\n",
        "\n",
        "ita_corpus = [\n",
        "    \"Questo è il corso di Hugging Face.\",\n",
        "    \"Questo capitolo riguarda la tokenizzazione.\",\n",
        "    \"Questa sezione mostra diversi algoritmi di tokenizzazione.\",\n",
        "    \"Speriamo che tu sia in grado di capire come vengono addestrati e generano token.\",\n",
        "]\n",
        "\n",
        "### Get frequency for English\n",
        "eng_word_freqs = defaultdict(int)\n",
        "for text in eng_corpus:\n",
        "    words_with_offsets = eng_tokenizer.backend_tokenizer.pre_tokenizer.pre_tokenize_str(text)\n",
        "    new_words = [word for word, offset in words_with_offsets]\n",
        "    print(f\"English: {new_words}\")\n",
        "    for word in new_words:\n",
        "        eng_word_freqs[word] += 1\n",
        "\n",
        "### Get frequency for Italian\n",
        "ita_word_freqs = defaultdict(int)\n",
        "for text in ita_corpus:\n",
        "    words_with_offsets = ita_tokenizer.backend_tokenizer.pre_tokenizer.pre_tokenize_str(text)\n",
        "    new_words = [word for word, offset in words_with_offsets]\n",
        "    print(f\"Italian: {new_words}\")\n",
        "    for word in new_words:\n",
        "        ita_word_freqs[word] += 1\n",
        "\n",
        "print(f\"\\nEnglish Word Frequency: {eng_word_freqs}\")\n",
        "print(f\"Italian Word Frequency: {ita_word_freqs}\")\n",
        "\n",
        "# Get vocabulary sizes for model initialization\n",
        "eng_vocab_size = eng_tokenizer.vocab_size\n",
        "ita_vocab_size = ita_tokenizer.vocab_size\n",
        "print(f\"\\nEnglish vocab size: {eng_vocab_size}\")\n",
        "print(f\"Italian vocab size: {ita_vocab_size}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "fbd93b11",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fbd93b11",
        "outputId": "e8d2e8d5-3d60-46a7-f788-fe7295774062"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "All alphabets: ['##a', '##c', '##d', '##e', '##g', '##h', '##i', '##k', '##l', '##m', '##n', '##o', '##p', '##r', '##s', '##t', '##u', '##v', '##z', '.', 'F', 'H', 'Q', 'S', 'a', 'c', 'd', 'e', 'g', 'i', 'l', 'm', 'r', 's', 't', 'v', 'è']\n",
            "\n",
            "Splitted Words: {'Questo': ['Q', '##u', '##e', '##s', '##t', '##o'], 'è': ['è'], 'il': ['i', '##l'], 'corso': ['c', '##o', '##r', '##s', '##o'], 'di': ['d', '##i'], 'Hugging': ['H', '##u', '##g', '##g', '##i', '##n', '##g'], 'Face': ['F', '##a', '##c', '##e'], '.': ['.'], 'capitolo': ['c', '##a', '##p', '##i', '##t', '##o', '##l', '##o'], 'riguarda': ['r', '##i', '##g', '##u', '##a', '##r', '##d', '##a'], 'la': ['l', '##a'], 'tokenizzazione': ['t', '##o', '##k', '##e', '##n', '##i', '##z', '##z', '##a', '##z', '##i', '##o', '##n', '##e'], 'Questa': ['Q', '##u', '##e', '##s', '##t', '##a'], 'sezione': ['s', '##e', '##z', '##i', '##o', '##n', '##e'], 'mostra': ['m', '##o', '##s', '##t', '##r', '##a'], 'diversi': ['d', '##i', '##v', '##e', '##r', '##s', '##i'], 'algoritmi': ['a', '##l', '##g', '##o', '##r', '##i', '##t', '##m', '##i'], 'Speriamo': ['S', '##p', '##e', '##r', '##i', '##a', '##m', '##o'], 'che': ['c', '##h', '##e'], 'tu': ['t', '##u'], 'sia': ['s', '##i', '##a'], 'in': ['i', '##n'], 'grado': ['g', '##r', '##a', '##d', '##o'], 'capire': ['c', '##a', '##p', '##i', '##r', '##e'], 'come': ['c', '##o', '##m', '##e'], 'vengono': ['v', '##e', '##n', '##g', '##o', '##n', '##o'], 'addestrati': ['a', '##d', '##d', '##e', '##s', '##t', '##r', '##a', '##t', '##i'], 'e': ['e'], 'generano': ['g', '##e', '##n', '##e', '##r', '##a', '##n', '##o'], 'token': ['t', '##o', '##k', '##e', '##n']}\n"
          ]
        }
      ],
      "source": [
        "### split all word into alphabet\n",
        "alphabet = []\n",
        "for word in ita_word_freqs.keys():\n",
        "    if word[0] not in alphabet:\n",
        "        alphabet.append(word[0])\n",
        "    for letter in word[1:]:\n",
        "        if f\"##{letter}\" not in alphabet:\n",
        "            alphabet.append(f\"##{letter}\")\n",
        "\n",
        "alphabet.sort()\n",
        "print(f'All alphabets: {alphabet}')\n",
        "\n",
        "### insert special token and subword\n",
        "vocab = [\"[PAD]\", \"[UNK]\", \"[CLS]\", \"[SEP]\", \"[MASK]\"] + alphabet.copy()\n",
        "splits = {word: [c if i == 0 else f\"##{c}\" for i, c in enumerate(word)] for word in ita_word_freqs.keys()}\n",
        "print(f'\\nSplitted Words: {splits}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "75de80da",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "75de80da",
        "outputId": "255c7cf1-caf4-49e2-89b8-cc547e54c084"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Scores for each Pair: {('Q', '##u'): 0.16666666666666666, ('##u', '##e'): 0.025, ('##e', '##s'): 0.02857142857142857, ('##s', '##t'): 0.08928571428571429, ('##t', '##o'): 0.01875, ('i', '##l'): 0.16666666666666666, ('c', '##o'): 0.02, ('##o', '##r'): 0.01, ('##r', '##s'): 0.02857142857142857, ('##s', '##o'): 0.007142857142857143, ('d', '##i'): 0.05263157894736842, ('H', '##u'): 0.16666666666666666, ('##u', '##g'): 0.027777777777777776, ('##g', '##g'): 0.027777777777777776, ('##g', '##i'): 0.008771929824561403, ('##i', '##n'): 0.0043859649122807015, ('##n', '##g'): 0.027777777777777776, ('F', '##a'): 0.06666666666666667, ('##a', '##c'): 0.06666666666666667, ('##c', '##e'): 0.05, ('c', '##a'): 0.02666666666666667, ('##a', '##p'): 0.044444444444444446, ('##p', '##i'): 0.03508771929824561, ('##i', '##t'): 0.013157894736842105, ('##o', '##l'): 0.016666666666666666, ('##l', '##o'): 0.016666666666666666, ('r', '##i'): 0.05263157894736842, ('##i', '##g'): 0.008771929824561403, ('##g', '##u'): 0.027777777777777776, ('##u', '##a'): 0.011111111111111112, ('##a', '##r'): 0.006666666666666667, ('##r', '##d'): 0.025, ('##d', '##a'): 0.016666666666666666, ('l', '##a'): 0.06666666666666667, ('t', '##o'): 0.0375, ('##o', '##k'): 0.05, ('##k', '##e'): 0.05, ('##e', '##n'): 0.020833333333333332, ('##n', '##i'): 0.008771929824561403, ('##i', '##z'): 0.015037593984962405, ('##z', '##z'): 0.04081632653061224, ('##z', '##a'): 0.01904761904761905, ('##a', '##z'): 0.01904761904761905, ('##z', '##i'): 0.022556390977443608, ('##i', '##o'): 0.007894736842105263, ('##o', '##n'): 0.016666666666666666, ('##n', '##e'): 0.016666666666666666, ('##t', '##a'): 0.008333333333333333, ('s', '##e'): 0.025, ('##e', '##z'): 0.007142857142857143, ('m', '##o'): 0.05, ('##o', '##s'): 0.007142857142857143, ('##t', '##r'): 0.025, ('##r', '##a'): 0.02666666666666667, ('##i', '##v'): 0.05263157894736842, ('##v', '##e'): 0.05, ('##e', '##r'): 0.015, ('##s', '##i'): 0.007518796992481203, ('a', '##l'): 0.16666666666666666, ('##l', '##g'): 0.05555555555555555, ('##g', '##o'): 0.016666666666666666, ('##r', '##i'): 0.010526315789473684, ('##t', '##m'): 0.041666666666666664, ('##m', '##i'): 0.017543859649122806, ('S', '##p'): 0.3333333333333333, ('##p', '##e'): 0.016666666666666666, ('##i', '##a'): 0.007017543859649123, ('##a', '##m'): 0.022222222222222223, ('##m', '##o'): 0.016666666666666666, ('c', '##h'): 0.2, ('##h', '##e'): 0.05, ('t', '##u'): 0.041666666666666664, ('s', '##i'): 0.02631578947368421, ('i', '##n'): 0.041666666666666664, ('g', '##r'): 0.05, ('##a', '##d'): 0.016666666666666666, ('##d', '##o'): 0.0125, ('##i', '##r'): 0.005263157894736842, ('##r', '##e'): 0.005, ('##o', '##m'): 0.016666666666666666, ('##m', '##e'): 0.016666666666666666, ('v', '##e'): 0.05, ('##n', '##o'): 0.008333333333333333, ('a', '##d'): 0.125, ('##d', '##d'): 0.0625, ('##d', '##e'): 0.0125, ('##a', '##t'): 0.008333333333333333, ('##t', '##i'): 0.006578947368421052, ('g', '##e'): 0.025, ('##a', '##n'): 0.005555555555555556}\n"
          ]
        }
      ],
      "source": [
        " ### compute score for merging\n",
        "\n",
        "def compute_pair_scores(splits):\n",
        "    letter_freqs = defaultdict(int)\n",
        "    pair_freqs = defaultdict(int)\n",
        "\n",
        "    for word, freq in ita_word_freqs.items():\n",
        "        split = splits[word]\n",
        "        if len(split) == 1:\n",
        "            letter_freqs[split[0]] += freq\n",
        "            continue\n",
        "        for i in range(len(split) - 1):\n",
        "            pair = (split[i], split[i + 1])\n",
        "            letter_freqs[split[i]] += freq\n",
        "            pair_freqs[pair] += freq\n",
        "        letter_freqs[split[-1]] += freq\n",
        "\n",
        "    scores = {\n",
        "        pair: freq / (letter_freqs[pair[0]] * letter_freqs[pair[1]])\n",
        "        for pair, freq in pair_freqs.items()\n",
        "    }\n",
        "    return scores\n",
        "\n",
        "pair_scores = compute_pair_scores(splits)\n",
        "print(f'Scores for each Pair: {pair_scores}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "6adc0481",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6adc0481",
        "outputId": "751127d9-a1b9-4ce3-b1ce-08f7c8e270ae"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "('S', '##p') 0.3333333333333333\n",
            "['Qu', '##e', '##s', '##t', '##o']\n"
          ]
        }
      ],
      "source": [
        "### finding pair with best score\n",
        "\n",
        "best_pair = \"\"\n",
        "max_score = None\n",
        "for pair, score in pair_scores.items():\n",
        "    if max_score is None or max_score < score:\n",
        "        best_pair = pair\n",
        "        max_score = score\n",
        "\n",
        "print(best_pair, max_score)\n",
        "vocab.append(\"ab\")\n",
        "\n",
        "### merge pair ###\n",
        "def merge_pair(a, b, splits):\n",
        "    for word in ita_word_freqs:\n",
        "        split = splits[word]\n",
        "        if len(split) == 1:\n",
        "            continue\n",
        "        i = 0\n",
        "        while i < len(split) - 1:\n",
        "            if split[i] == a and split[i + 1] == b:\n",
        "                merge = a + b[2:] if b.startswith(\"##\") else a + b\n",
        "                split = split[:i] + [merge] + split[i + 2 :]\n",
        "            else:\n",
        "                i += 1\n",
        "        splits[word] = split\n",
        "    return splits\n",
        "\n",
        "splits = merge_pair(\"Q\", \"##u\", splits)\n",
        "print(splits[\"Questo\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "7943860a",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7943860a",
        "outputId": "53358ec2-11f2-415f-fdbc-ece55961334a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Final Vocab: ['[PAD]', '[UNK]', '[CLS]', '[SEP]', '[MASK]', '##a', '##c', '##d', '##e', '##g', '##h', '##i', '##k', '##l', '##m', '##n', '##o', '##p', '##r', '##s', '##t', '##u', '##v', '##z', '.', 'F', 'H', 'Q', 'S', 'a', 'c', 'd', 'e', 'g', 'i', 'l', 'm', 'r', 's', 't', 'v', 'è', 'ab', 'Hu', 'Sp', 'ch', 'il', 'al', 'ad', 'add', 'Hug', 'Hugg', 'alg', '##gu', 'tu', '##st', '##tm', '##rs', '##ng', 'in', 'Fa', 'Fac', '##ap', 'cap', '##gua', '##guar', '##guard', '##guarda', 'la', '##ad', '##rad', 'grad', '##str', '##stra', '##strat', '##am', '##sta', '##za', '##zza', '##zzaz', '##ra', '##ran', 'di', 'div', 'Huggi', 'Hugging', 'capi', 'capit', 'capir', 'ri', 'riguarda', '##izzaz', '##nizzaz', '##nizzazi', '##zi', '##ri', '##ritm', '##riam', '##ritmi', '##ia']\n"
          ]
        }
      ],
      "source": [
        "### keep looping to merge more pair\n",
        "\n",
        "vocab_size = 100\n",
        "while len(vocab) < vocab_size:\n",
        "    scores = compute_pair_scores(splits)\n",
        "    best_pair, max_score = \"\", None\n",
        "    for pair, score in scores.items():\n",
        "        if max_score is None or max_score < score:\n",
        "            best_pair = pair\n",
        "            max_score = score\n",
        "    splits = merge_pair(*best_pair, splits)\n",
        "    new_token = (\n",
        "        best_pair[0] + best_pair[1][2:]\n",
        "        if best_pair[1].startswith(\"##\")\n",
        "        else best_pair[0] + best_pair[1]\n",
        "    )\n",
        "    vocab.append(new_token)\n",
        "\n",
        "print(f'Final Vocab: {vocab}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "1afe6c8b",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1afe6c8b",
        "outputId": "f831f43f-7c3b-409d-c02c-3124cd9d30c7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['Q', '##u', '##e', '##st', '##o']\n",
            "['Q', '##a', '##e', '##st', '##o']\n"
          ]
        }
      ],
      "source": [
        "### encode a word ###\n",
        "def encode_word(word):\n",
        "    tokens = []\n",
        "    while len(word) > 0:\n",
        "        i = len(word)\n",
        "        while i > 0 and word[:i] not in vocab:\n",
        "            i -= 1\n",
        "        if i == 0:\n",
        "            return [\"[UNK]\"]\n",
        "        tokens.append(word[:i])\n",
        "        word = word[i:]\n",
        "        if len(word) > 0:\n",
        "            word = f\"##{word}\"\n",
        "    return tokens\n",
        "\n",
        "print(encode_word(\"Questo\"))\n",
        "# This one should be unknown (within this corpus)\n",
        "print(encode_word(\"Qaesto\"))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "jeHBuC79RMHm",
      "metadata": {
        "id": "jeHBuC79RMHm"
      },
      "source": [
        "## BERTDataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "id": "VCCMqd7JRKf6",
      "metadata": {
        "id": "VCCMqd7JRKf6"
      },
      "outputs": [],
      "source": [
        "class BERTDataset(Dataset):\n",
        "    def __init__(self, data_pair, tokenizer, seq_len=64):\n",
        "\n",
        "        self.tokenizer = tokenizer\n",
        "        self.seq_len = seq_len\n",
        "        self.corpus_lines = len(data_pair)\n",
        "        self.lines = data_pair\n",
        "\n",
        "    def __len__(self):\n",
        "        return self.corpus_lines\n",
        "\n",
        "    def __getitem__(self, item):\n",
        "\n",
        "        # Step 1: get random sentence pair, either negative or positive (saved as is_next_label)\n",
        "        t1, t2, is_next_label = self.get_sent(item)\n",
        "\n",
        "        # Step 2: replace random words in sentence with mask / random words\n",
        "        t1_random, t1_label = self.random_word(t1)\n",
        "        t2_random, t2_label = self.random_word(t2)\n",
        "\n",
        "        # Step 3: Adding CLS and SEP tokens to the start and end of sentences\n",
        "        # Adding PAD token for labels\n",
        "        t1 = [self.tokenizer.vocab['[CLS]']] + t1_random + [self.tokenizer.vocab['[SEP]']]\n",
        "        t2 = t2_random + [self.tokenizer.vocab['[SEP]']]\n",
        "        t1_label = [self.tokenizer.vocab['[PAD]']] + t1_label + [self.tokenizer.vocab['[PAD]']]\n",
        "        t2_label = t2_label + [self.tokenizer.vocab['[PAD]']]\n",
        "\n",
        "        # Step 4: combine sentence 1 and 2 as one input\n",
        "        # adding PAD tokens to make the sentence same length as seq_len\n",
        "        segment_label = ([1 for _ in range(len(t1))] + [2 for _ in range(len(t2))])[:self.seq_len]\n",
        "        bert_input = (t1 + t2)[:self.seq_len]\n",
        "        bert_label = (t1_label + t2_label)[:self.seq_len]\n",
        "        padding = [self.tokenizer.vocab['[PAD]'] for _ in range(self.seq_len - len(bert_input))]\n",
        "        bert_input.extend(padding), bert_label.extend(padding), segment_label.extend(padding)\n",
        "\n",
        "        output = {\"bert_input\": bert_input,\n",
        "                  \"bert_label\": bert_label,\n",
        "                  \"segment_label\": segment_label,\n",
        "                  \"is_next\": is_next_label}\n",
        "\n",
        "        return {key: torch.tensor(value) for key, value in output.items()}\n",
        "\n",
        "    def random_word(self, sentence):\n",
        "        tokens = sentence.split()\n",
        "        output_label = []\n",
        "        output = []\n",
        "\n",
        "        # 15% of the tokens would be replaced\n",
        "        for i, token in enumerate(tokens):\n",
        "            prob = random.random()\n",
        "\n",
        "            # remove cls and sep token\n",
        "            token_id = self.tokenizer(token)['input_ids'][1:-1]\n",
        "\n",
        "            # 15% chance of altering token\n",
        "            if prob < 0.15:\n",
        "                prob /= 0.15\n",
        "\n",
        "                # 80% chance change token to mask token\n",
        "                if prob < 0.8:\n",
        "                    for i in range(len(token_id)):\n",
        "                        output.append(self.tokenizer.vocab['[MASK]'])\n",
        "\n",
        "                # 10% chance change token to random token\n",
        "                elif prob < 0.9:\n",
        "                    for i in range(len(token_id)):\n",
        "                        output.append(random.randrange(len(self.tokenizer.vocab)))\n",
        "\n",
        "                # 10% chance change token to current token\n",
        "                else:\n",
        "                    output.append(token_id)\n",
        "\n",
        "                output_label.append(token_id)\n",
        "\n",
        "            else:\n",
        "                output.append(token_id)\n",
        "                for i in range(len(token_id)):\n",
        "                    output_label.append(0)\n",
        "\n",
        "        # flattening\n",
        "        output = list(itertools.chain(*[[x] if not isinstance(x, list) else x for x in output]))\n",
        "        output_label = list(itertools.chain(*[[x] if not isinstance(x, list) else x for x in output_label]))\n",
        "        assert len(output) == len(output_label)\n",
        "        return output, output_label\n",
        "\n",
        "    def get_sent(self, index):\n",
        "        '''return random sentence pair'''\n",
        "        t1, t2 = self.get_corpus_line(index)\n",
        "\n",
        "        # negative or positive pair, for next sentence prediction\n",
        "        if random.random() > 0.5:\n",
        "            return t1, t2, 1\n",
        "        else:\n",
        "            return t1, self.get_random_line(), 0\n",
        "\n",
        "    def get_corpus_line(self, item):\n",
        "        '''return sentence pair'''\n",
        "        return self.lines[item][0], self.lines[item][1]\n",
        "\n",
        "    def get_random_line(self):\n",
        "        '''return random single sentence'''\n",
        "        return self.lines[random.randrange(len(self.lines))][1]"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "baf44a70",
      "metadata": {
        "id": "baf44a70"
      },
      "source": [
        "# Task\n",
        "Create a translation model using `BertTranslationModel` based on loaded text data. The model should translate from English to Italian. Outline the steps for Tokenization, Word Embedding, and training."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "510b5e99",
      "metadata": {
        "id": "510b5e99"
      },
      "source": [
        "## Prepare Dataset\n",
        "\n",
        "### BertDataset\n",
        "- Tokenization\n",
        "- Padding\n",
        "- Convert Tensor\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "id": "87909343",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "87909343",
        "outputId": "23584111-6dd5-4faa-f5e5-6fd35741c587"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total pairs: 333112\n",
            "Training pairs: 266489\n",
            "Validation pairs: 66623\n"
          ]
        }
      ],
      "source": [
        "eng_sentences = []\n",
        "with open(\"text-eng.txt\", \"r\") as f:\n",
        "    for line in f:\n",
        "        line = line.strip().replace('<sos>', '').replace('<eos>', '').strip()\n",
        "        if line:\n",
        "            eng_sentences.append(line)\n",
        "\n",
        "ita_sentences = []\n",
        "with open(\"text-ita.txt\", \"r\") as f:\n",
        "    for line in f:\n",
        "        line = line.strip().replace('<sos>', '').replace('<eos>', '').strip()\n",
        "        if line:\n",
        "            ita_sentences.append(line)\n",
        "\n",
        "data_pair = list(zip(eng_sentences, ita_sentences))\n",
        "\n",
        "# Split data into training and validation sets\n",
        "# Using a simple split for now, can use train_test_split later if needed\n",
        "train_size = int(0.8 * len(data_pair))\n",
        "train_data = data_pair[:train_size]\n",
        "val_data = data_pair[train_size:]\n",
        "\n",
        "print(f\"Total pairs: {len(data_pair)}\")\n",
        "print(f\"Training pairs: {len(train_data)}\")\n",
        "print(f\"Validation pairs: {len(val_data)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "id": "ec81bb96",
      "metadata": {
        "id": "ec81bb96"
      },
      "outputs": [],
      "source": [
        "class TranslationDataset(Dataset):\n",
        "    def __init__(self, data_pair, eng_tokenizer, ita_tokenizer, seq_len=64):\n",
        "        self.data_pair = data_pair\n",
        "        self.eng_tokenizer = eng_tokenizer\n",
        "        self.ita_tokenizer = ita_tokenizer\n",
        "        self.seq_len = seq_len\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data_pair)\n",
        "\n",
        "    def __getitem__(self, item):\n",
        "        eng_sentence, ita_sentence = self.data_pair[item]\n",
        "\n",
        "        # Tokenize English sentence\n",
        "        eng_tokens = self.eng_tokenizer(\n",
        "            eng_sentence,\n",
        "            padding='max_length',\n",
        "            truncation=True,\n",
        "            max_length=self.seq_len,\n",
        "            return_attention_mask=True,\n",
        "            return_token_type_ids=True,\n",
        "            return_tensors='pt'\n",
        "        )\n",
        "\n",
        "        # Tokenize Italian sentence for decoder input and target\n",
        "        # Need to add [CLS] and [SEP] for decoder input, and [SEP] for target\n",
        "        # The target is the input shifted by one token, effectively predicting the next token\n",
        "        ita_input_tokens = self.ita_tokenizer(\n",
        "            ita_sentence,\n",
        "            padding='max_length',\n",
        "            truncation=True,\n",
        "            max_length=self.seq_len,\n",
        "            return_attention_mask=True, # This mask is for cross-attention from encoder\n",
        "            return_token_type_ids=True,\n",
        "            return_tensors='pt'\n",
        "        )\n",
        "\n",
        "        # Create decoder input by adding [CLS] and shifting\n",
        "        ita_input_ids = ita_input_tokens['input_ids'].squeeze(0)\n",
        "        ita_attention_mask = ita_input_tokens['attention_mask'].squeeze(0)\n",
        "        ita_token_type_ids = ita_input_tokens['token_type_ids'].squeeze(0)\n",
        "\n",
        "        # Create the causal mask for the decoder self-attention\n",
        "        # This ensures the decoder at a given position only attends to previous positions\n",
        "        seq_len = ita_input_ids.size(0)\n",
        "        casual_mask = torch.triu(torch.ones(seq_len, seq_len), diagonal=1).bool()\n",
        "        casual_mask = casual_mask.masked_fill(casual_mask, float('-inf'))\n",
        "        casual_mask = casual_mask.masked_fill(~casual_mask, 0.0)\n",
        "\n",
        "\n",
        "        # Create the target labels for Italian (shifted input)\n",
        "        # The target is the input sequence shifted by one position, with the first token ([CLS]) removed.\n",
        "        # The padding token at the end of the input sequence will correspond to the last real token in the target.\n",
        "        ita_target_ids = ita_input_ids.clone()\n",
        "        # Shift target sequence by one position\n",
        "        ita_target_ids = torch.cat([ita_target_ids[1:], torch.tensor([self.ita_tokenizer.pad_token_id])])\n",
        "\n",
        "        output = {\n",
        "            \"eng_ids\": eng_tokens['input_ids'].squeeze(0),\n",
        "            \"eng_mask\": eng_tokens['attention_mask'].squeeze(0),\n",
        "            \"eng_token_type_ids\": eng_tokens['token_type_ids'].squeeze(0),\n",
        "            \"ita_ids\": ita_input_ids,\n",
        "            \"ita_mask\": ita_attention_mask, # This will be used for cross attention.\n",
        "            \"ita_token_type_ids\": ita_token_type_ids,\n",
        "            \"ita_casual_mask\": casual_mask, # This will be used for self attention in decoder.\n",
        "            \"ita_target_ids\": ita_target_ids,\n",
        "        }\n",
        "\n",
        "        return output\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ad36cc19",
      "metadata": {
        "id": "ad36cc19"
      },
      "source": [
        "**Reasoning**:\n",
        "Create Dataset objects for the training and validation sets using the defined `TranslationDataset` class and then create DataLoaders for both datasets to handle batching and shuffling during training and evaluation.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "id": "2ddad872",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2ddad872",
        "outputId": "d330c846-b61e-4994-be85-60db66ef8262"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of batches in training DataLoader: 8328\n",
            "Number of batches in validation DataLoader: 2082\n"
          ]
        }
      ],
      "source": [
        "train_dataset = TranslationDataset(train_data, eng_tokenizer, ita_tokenizer, seq_len=MAXLEN)\n",
        "val_dataset = TranslationDataset(val_data, eng_tokenizer, ita_tokenizer, seq_len=MAXLEN)\n",
        "\n",
        "BATCH_SIZE = 32\n",
        "\n",
        "train_dataloader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
        "val_dataloader = DataLoader(val_dataset, batch_size=BATCH_SIZE)\n",
        "\n",
        "print(f\"Number of batches in training DataLoader: {len(train_dataloader)}\")\n",
        "print(f\"Number of batches in validation DataLoader: {len(val_dataloader)}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a0a7819a",
      "metadata": {
        "id": "a0a7819a"
      },
      "source": [
        "## Definition of Model\n",
        "\n",
        "### Subtask:\n",
        "`BertTranslationModel` is instanced here.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d1ff30a3",
      "metadata": {
        "id": "d1ff30a3"
      },
      "source": [
        "**Reasoning**:\n",
        "BertTranslationModel クラスを適切な引数でインスタンス化し、その構造を確認します。\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "id": "f8232374",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f8232374",
        "outputId": "a0c78896-4b71-4505-c349-699d4f5d9ff2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "BertTranslationModel(\n",
            "  (encoder): Bert(\n",
            "    (embedding): BertEmbeddings(\n",
            "      (token): Embedding(28996, 768, padding_idx=0)\n",
            "      (position): Embedding(20, 768)\n",
            "      (segment): Embedding(2, 768)\n",
            "      (layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "      (dropout): Dropout(p=0.1, inplace=False)\n",
            "    )\n",
            "    (encoder_blocks): ModuleList(\n",
            "      (0-5): 6 x EncoderBlock(\n",
            "        (attention): MultiHeadAttention(\n",
            "          (dropout): Dropout(p=0.1, inplace=False)\n",
            "          (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "          (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "          (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "          (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
            "        )\n",
            "        (ffn): PositionwiseFeedForward(\n",
            "          (linear1): Linear(in_features=768, out_features=3072, bias=True)\n",
            "          (linear2): Linear(in_features=3072, out_features=768, bias=True)\n",
            "          (dropout): Dropout(p=0.1, inplace=False)\n",
            "          (gelu): GELU(approximate='none')\n",
            "        )\n",
            "        (layer_norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
            "        (layer_norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
            "        (dropout): Dropout(p=0.1, inplace=False)\n",
            "      )\n",
            "    )\n",
            "  )\n",
            "  (decoder_embeddings): BertEmbeddings(\n",
            "    (token): Embedding(31102, 768, padding_idx=0)\n",
            "    (position): Embedding(20, 768)\n",
            "    (segment): Embedding(2, 768)\n",
            "    (layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "    (dropout): Dropout(p=0.1, inplace=False)\n",
            "  )\n",
            "  (decoder_blocks): ModuleList(\n",
            "    (0-5): 6 x DecoderBlock(\n",
            "      (self_attention): MultiHeadAttention(\n",
            "        (dropout): Dropout(p=0.1, inplace=False)\n",
            "        (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
            "      )\n",
            "      (cross_attention): CrossAttention(\n",
            "        (dropout): Dropout(p=0.1, inplace=False)\n",
            "        (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
            "      )\n",
            "      (ffn): PositionwiseFeedForward(\n",
            "        (linear1): Linear(in_features=768, out_features=3072, bias=True)\n",
            "        (linear2): Linear(in_features=3072, out_features=768, bias=True)\n",
            "        (dropout): Dropout(p=0.1, inplace=False)\n",
            "        (gelu): GELU(approximate='none')\n",
            "      )\n",
            "      (layer_norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
            "      (layer_norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
            "      (layer_norm3): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
            "      (dropout): Dropout(p=0.1, inplace=False)\n",
            "    )\n",
            "  )\n",
            "  (output_proj): Linear(in_features=768, out_features=31102, bias=True)\n",
            ")\n"
          ]
        }
      ],
      "source": [
        "model = BertTranslationModel(\n",
        "    ita_vocab_size=ita_tokenizer.vocab_size,\n",
        "    eng_vocab_size=eng_tokenizer.vocab_size,\n",
        "    max_seq_len=MAXLEN,\n",
        "    d_model=768, # 使用するBERTモデルの一般的な次元\n",
        "    num_layers=6, # レイヤー数は適宜設定\n",
        "    num_heads=12, # ヘッド数は適宜設定 (d_modelで割り切れるように)\n",
        "    dropout=0.1\n",
        ")\n",
        "\n",
        "print(model)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4749b305",
      "metadata": {
        "id": "4749b305"
      },
      "source": [
        "## Lossfunction and Optimizer\n",
        "\n",
        "### Subtask:\n",
        "翻訳タスクに適した損失関数（例: `CrossEntropyLoss`）とオプティマイザ（例: `Adam`）を定義します。\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "id": "107bb02a",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "107bb02a",
        "outputId": "ed29a2af-26d7-42ab-9202-08abc6d11bc3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss function (criterion): CrossEntropyLoss()\n",
            "Optimizer: Adam (\n",
            "Parameter Group 0\n",
            "    amsgrad: False\n",
            "    betas: (0.9, 0.999)\n",
            "    capturable: False\n",
            "    differentiable: False\n",
            "    eps: 1e-08\n",
            "    foreach: None\n",
            "    fused: None\n",
            "    lr: 0.0001\n",
            "    maximize: False\n",
            "    weight_decay: 0\n",
            ")\n"
          ]
        }
      ],
      "source": [
        "criterion = nn.CrossEntropyLoss(ignore_index=ita_tokenizer.pad_token_id)\n",
        "optimizer = Adam(model.parameters(), lr=1e-4)\n",
        "\n",
        "print(\"Loss function (criterion):\", criterion)\n",
        "print(\"Optimizer:\", optimizer)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "02fbb8a9",
      "metadata": {
        "id": "02fbb8a9"
      },
      "source": [
        "## 訓練ループの実装\n",
        "\n",
        "### Subtask:\n",
        "モデルを訓練するためのループを作成します。これには、データのバッチ処理、モデルのフォワードパス、損失の計算、バックプロパゲーション、パラメータの更新などが含まれます。\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "id": "4WtUNtA_tdxn",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4WtUNtA_tdxn",
        "outputId": "59c88205-1279-412f-bd19-17f0c5253d4f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "import os\n",
        "\n",
        "# Mount Google Drive\n",
        "drive.mount('/content/drive')\n",
        "model_save_dir = \"/content/drive/MyDrive/bert_translation_models\"\n",
        "os.makedirs(model_save_dir, exist_ok=True) # Create directory if it doesn't exist\n",
        "\n",
        "model_save_path = os.path.join(model_save_dir, \"bert_translation_model.pth\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1c57b767",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1c57b767",
        "outputId": "edf4ffaa-8f25-41ff-8820-599edc324cc6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Using device: cuda\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 1: 100%|██████████| 8328/8328 [29:46<00:00,  4.66it/s, loss=0.000413]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1 finished. Average training loss: 0.0763\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 2: 100%|██████████| 8328/8328 [29:38<00:00,  4.68it/s, loss=0.0136]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 2 finished. Average training loss: 0.0094\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 3: 100%|██████████| 8328/8328 [29:39<00:00,  4.68it/s, loss=1.63e-6]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 3 finished. Average training loss: 0.0107\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 4: 100%|██████████| 8328/8328 [29:37<00:00,  4.69it/s, loss=0.000191]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 4 finished. Average training loss: 0.0133\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 5: 100%|██████████| 8328/8328 [29:39<00:00,  4.68it/s, loss=0.103]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 5 finished. Average training loss: 0.0196\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(f\"Using device: {device}\")\n",
        "model.to(device)\n",
        "\n",
        "EPOCHS = 1 # Define the number of training epochs\n",
        "\n",
        "for epoch in range(EPOCHS):\n",
        "    model.train()\n",
        "    total_loss = 0\n",
        "    train_iterator = tqdm.tqdm(train_dataloader, desc=f\"Epoch {epoch+1}\")\n",
        "\n",
        "    for i, batch in enumerate(train_iterator):\n",
        "        # Move batch to device\n",
        "        eng_ids = batch['eng_ids'].to(device)\n",
        "        eng_mask = batch['eng_mask'].to(device)\n",
        "        eng_token_type_ids = batch['eng_token_type_ids'].to(device)\n",
        "        ita_ids = batch['ita_ids'].to(device)\n",
        "        # ita_mask from dataset is for cross-attention, shape (batch_size, seq_len)\n",
        "        ita_mask = batch['ita_mask'].to(device)\n",
        "        ita_target_ids = batch['ita_target_ids'].to(device)\n",
        "        ita_token_type_ids = batch['ita_token_type_ids'].to(device)\n",
        "        # ita_casual_mask from dataset is for self-attention, shape (seq_len, seq_len)\n",
        "        ita_casual_mask = batch['ita_casual_mask'].to(device)\n",
        "\n",
        "\n",
        "        # Prepare masks for the model forward pass\n",
        "        # Eng mask for encoder self-attention and decoder cross-attention\n",
        "        # Needs to be broadcastable to (batch, num_heads, q_len/seq_len, kv_len/seq_len)\n",
        "        batch_size, ita_seq_len = ita_ids.shape\n",
        "        _, eng_seq_len = eng_ids.shape\n",
        "        num_heads = model.decoder_blocks[0].cross_attention.num_heads # Assuming same number of heads for self and cross attention\n",
        "\n",
        "        # Eng mask for encoder self-attention\n",
        "        # Reshape to (batch, 1, 1, eng_seq_len) for broadcasting\n",
        "        eng_encoder_mask = eng_mask.unsqueeze(1).unsqueeze(2)\n",
        "        # Convert to additive mask format (0.0 and -1e9)\n",
        "        eng_encoder_mask = (1.0 - eng_encoder_mask.float()) * -1e9 # Ensure float for calculation\n",
        "\n",
        "\n",
        "        # Eng mask for decoder cross-attention\n",
        "        # Needs shape (batch, num_heads, ita_seq_len, eng_seq_len) for addition\n",
        "        # Start with (batch, 1, 1, eng_seq_len) and expand\n",
        "        eng_cross_mask = eng_mask.unsqueeze(1).unsqueeze(2)\n",
        "        eng_cross_mask = eng_cross_mask.expand(batch_size, num_heads, ita_seq_len, eng_seq_len)\n",
        "        # Convert to additive mask format (0.0 and -1e9)\n",
        "        eng_cross_mask = (1.0 - eng_cross_mask.float()) * -1e9 # Ensure float for calculation\n",
        "\n",
        "\n",
        "        # Ita causal mask for decoder self-attention\n",
        "        # Dataset provides (seq_len, seq_len) mask. After DataLoader, it's (batch_size, seq_len, seq_len).\n",
        "        # Needs shape (batch_size, num_heads, seq_len, seq_len) for addition.\n",
        "        # Add head dimension and expand.\n",
        "        ita_casual_mask = ita_casual_mask.unsqueeze(1) # shape (batch_size, 1, seq_len, seq_len)\n",
        "        ita_casual_mask = ita_casual_mask.expand(batch_size, num_heads, ita_seq_len, ita_seq_len)\n",
        "        # The mask from dataset is already in additive format (-inf and 0.0)\n",
        "\n",
        "\n",
        "        # Forward pass\n",
        "        # Pass appropriate masks to the model\n",
        "        # The model expects eng_mask to be the cross-attention mask and ita_mask to be the self-attention mask for the decoder\n",
        "        logits = model(\n",
        "            eng_ids=eng_ids,\n",
        "            ita_ids=ita_ids,\n",
        "            eng_mask=eng_cross_mask, # Use eng_cross_mask for cross-attention in the model\n",
        "            ita_mask=ita_casual_mask, # Use ita_casual_mask for self-attention in the model\n",
        "            eng_token_type_ids=eng_token_type_ids,\n",
        "            ita_token_type_ids=ita_token_type_ids\n",
        "            )\n",
        "\n",
        "        # Calculate loss, ignoring padding tokens\n",
        "        # Reshape logits and target for CrossEntropyLoss\n",
        "        loss = criterion(logits.view(-1, logits.size(-1)), ita_target_ids.view(-1))\n",
        "\n",
        "        # Backpropagation\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        total_loss += loss.item()\n",
        "        train_iterator.set_postfix({'loss': loss.item()})\n",
        "\n",
        "    avg_train_loss = total_loss / len(train_dataloader)\n",
        "    print(f\"Epoch {epoch+1} finished. Average training loss: {avg_train_loss:.4f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b1391fe7",
      "metadata": {
        "id": "b1391fe7"
      },
      "source": [
        "Save the state dictionary of the trained model to a file so it can be loaded later for inference or further training."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f0898e35",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f0898e35",
        "outputId": "def5b736-c7f2-4199-963c-af59d3c4fcf3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model parameters saved to /content/drive/MyDrive/bert_translation_models/bert_translation_model.pth\n"
          ]
        }
      ],
      "source": [
        "model_save_path = os.path.join(model_save_dir, \"bert_translation_model.pth\")\n",
        "\n",
        "# Save the model's state dictionary\n",
        "torch.save(model.state_dict(), model_save_path)\n",
        "\n",
        "print(f\"Model parameters saved to {model_save_path}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "id": "UPiG23c3pzv1",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 218
        },
        "id": "UPiG23c3pzv1",
        "outputId": "32cb9060-fe6f-492d-ff3f-afbe913ccd43"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'eng_ids' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-19-2179642081.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m   \u001b[0;32mfor\u001b[0m \u001b[0mbatch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mval_dataloader\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m       logits = model(\n\u001b[0;32m----> 6\u001b[0;31m         \u001b[0meng_ids\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0meng_ids\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m         \u001b[0mita_ids\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mita_ids\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m         \u001b[0meng_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0meng_cross_mask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;31m# Use eng_cross_mask for cross-attention in the model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'eng_ids' is not defined"
          ]
        }
      ],
      "source": [
        "model.eval()\n",
        "with torch.no_grad():\n",
        "  total_val_loss = 0\n",
        "  for batch in val_dataloader:\n",
        "      logits = model(\n",
        "        eng_ids=eng_ids,\n",
        "        ita_ids=ita_ids,\n",
        "        eng_mask=eng_cross_mask, # Use eng_cross_mask for cross-attention in the model\n",
        "        ita_mask=ita_casual_mask, # Use ita_casual_mask for self-attention in the model\n",
        "        eng_token_type_ids=eng_token_type_ids,\n",
        "        ita_token_type_ids=ita_token_type_ids\n",
        "      )\n",
        "  # Calculate loss, ignoring padding tokens\n",
        "  # Reshape logits and target for CrossEntropyLoss\n",
        "  loss = criterion(logits.view(-1, logits.size(-1)), ita_target_ids.view(-1))\n",
        "  avg_val_loss = total_val_loss / len(val_dataloader)\n",
        "  print(f\"Epoch {epoch+1} validation loss: {avg_val_loss:.4f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7173a42d",
      "metadata": {
        "id": "7173a42d"
      },
      "source": [
        "Load the saved model parameters and implement a function to translate an English sentence into Italian using the trained `BertTranslationModel`. This will involve tokenizing the input English sentence, feeding it to the encoder, and then using the decoder to generate the Italian translation token by token."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "id": "3d46fd4c",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3d46fd4c",
        "outputId": "a813ab53-7b40-4318-f057-a00b5b240802"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n",
            "Using device: cuda\n",
            "Model loaded successfully.\n",
            "English: Hello.\n",
            "Italian (Translated): b etichette etichette etichette etichette b b b b b b etichette etichette etichette b b b etichette b\n"
          ]
        }
      ],
      "source": [
        "# Load the saved model parameters\n",
        "model_save_path = \"/content/drive/MyDrive/bert_translation_models/bert_translation_model.pth\"\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount=True)\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(f\"Using device: {device}\")\n",
        "model.to(device)\n",
        "# Instantiate the model with the same architecture as the trained model\n",
        "loaded_model = BertTranslationModel(\n",
        "    ita_vocab_size=ita_tokenizer.vocab_size,\n",
        "    eng_vocab_size=eng_tokenizer.vocab_size,\n",
        "    max_seq_len=MAXLEN,\n",
        "    d_model=768,\n",
        "    num_layers=6,\n",
        "    num_heads=12,\n",
        "    dropout=0.1 # Use the same dropout as during training\n",
        ")\n",
        "\n",
        "# Load the state dictionary\n",
        "loaded_model.load_state_dict(torch.load(model_save_path))\n",
        "\n",
        "# Set the model to evaluation mode\n",
        "loaded_model.eval()\n",
        "\n",
        "print(\"Model loaded successfully.\")\n",
        "\n",
        "def translate_sentence(model, sentence, eng_tokenizer, ita_tokenizer, max_len=MAXLEN, device=\"cuda\"):\n",
        "    model.to(device)\n",
        "    model.eval()\n",
        "\n",
        "    # Tokenize the input English sentence\n",
        "    eng_tokens = eng_tokenizer(\n",
        "        sentence,\n",
        "        padding='max_length',\n",
        "        truncation=True,\n",
        "        max_length=max_len,\n",
        "        return_attention_mask=True,\n",
        "        return_token_type_ids=True,\n",
        "        return_tensors='pt'\n",
        "    )\n",
        "\n",
        "    eng_ids = eng_tokens['input_ids'].to(device)\n",
        "    eng_mask = eng_tokens['attention_mask'].to(device)\n",
        "    eng_token_type_ids = eng_tokens['token_type_ids'].to(device)\n",
        "\n",
        "    # Prepare the encoder output (run the encoder once)\n",
        "    with torch.no_grad():\n",
        "        encoder_output = model.encoder(\n",
        "            input_ids=eng_ids,\n",
        "            attention_mask=eng_mask,\n",
        "            token_type_ids=eng_token_type_ids\n",
        "        )\n",
        "\n",
        "    # Start with the Italian start token (assuming [CLS] serves this purpose for BERT)\n",
        "    # And the corresponding token type id and mask\n",
        "    ita_input_ids = torch.tensor([[ita_tokenizer.cls_token_id]], device=device) # Start with [CLS]\n",
        "    ita_token_type_ids = torch.tensor([[0]], device=device) # Assuming segment 0 for the generated sequence\n",
        "    # Initial casual mask will be for a single token\n",
        "    ita_casual_mask = torch.zeros((1, 1, 1, 1), device=device) # shape (batch_size, num_heads, q_len, kv_len)\n",
        "\n",
        "    # Decode token by token\n",
        "    translated_tokens = []\n",
        "\n",
        "    for _ in range(max_len - 1): # Generate up to max_len-1 tokens (excluding CLS)\n",
        "        # Get the current sequence length of the generated Italian tokens\n",
        "        current_ita_len = ita_input_ids.size(1)\n",
        "\n",
        "        # Update the casual mask for the current sequence length\n",
        "        casual_mask = torch.triu(torch.ones(current_ita_len, current_ita_len), diagonal=1).bool().to(device)\n",
        "        casual_mask = casual_mask.masked_fill(casual_mask, float('-inf'))\n",
        "        casual_mask = casual_mask.masked_fill(~casual_mask, 0.0)\n",
        "        # Add batch and head dimensions for broadcasting\n",
        "        num_heads = model.decoder_blocks[0].self_attention.num_heads\n",
        "        ita_casual_mask = casual_mask.unsqueeze(0).unsqueeze(0).expand(1, num_heads, current_ita_len, current_ita_len)\n",
        "\n",
        "\n",
        "        # Update the Italian attention mask for cross-attention\n",
        "        # This mask is based on the *generated* Italian sequence length for the query\n",
        "        # and the English sequence length for key/value.\n",
        "        # The mask from the dataset was for the target, which is not available during inference.\n",
        "        # For inference, the cross-attention mask should allow attending to all non-padded English tokens.\n",
        "        # We need a mask of shape (batch_size, num_heads, ita_seq_len, eng_seq_len)\n",
        "        # Use the original eng_mask (batch_size, eng_seq_len) and expand it.\n",
        "        eng_seq_len = eng_ids.size(1)\n",
        "        eng_cross_mask = eng_mask.unsqueeze(1).unsqueeze(2).expand(1, num_heads, current_ita_len, eng_seq_len)\n",
        "        eng_cross_mask = (1.0 - eng_cross_mask.float()) * -1e9 # Convert to additive mask\n",
        "\n",
        "\n",
        "        # Forward pass through the decoder\n",
        "        with torch.no_grad():\n",
        "            logits = model.decoder_embeddings(ita_input_ids, ita_token_type_ids)\n",
        "            for decoder_block in model.decoder_blocks:\n",
        "                 logits = decoder_block(\n",
        "                    x=logits,\n",
        "                    encoder_output=encoder_output,\n",
        "                    self_mask=ita_casual_mask,\n",
        "                    cross_mask=eng_cross_mask\n",
        "                 )\n",
        "            output_logits = model.output_proj(logits) # Get logits for the next token\n",
        "\n",
        "\n",
        "        # Get the logits for the last generated token\n",
        "        next_token_logits = output_logits[:, -1, :]\n",
        "\n",
        "        # Predict the next token (greedy approach)\n",
        "        next_token_id = torch.argmax(next_token_logits, dim=-1).unsqueeze(0)\n",
        "\n",
        "        # Append the predicted token to the input sequence\n",
        "        ita_input_ids = torch.cat([ita_input_ids, next_token_id], dim=1)\n",
        "        ita_token_type_ids = torch.cat([ita_token_type_ids, torch.tensor([[0]], device=device)], dim=1) # Assuming segment 0\n",
        "\n",
        "        # Stop if the predicted token is the SEP token\n",
        "        if next_token_id.squeeze().item() == ita_tokenizer.sep_token_id:\n",
        "            break\n",
        "\n",
        "        # Append the predicted token ID to the translated tokens list (excluding CLS and SEP)\n",
        "        if next_token_id.squeeze().item() not in [ita_tokenizer.cls_token_id, ita_tokenizer.sep_token_id, ita_tokenizer.pad_token_id]:\n",
        "             translated_tokens.append(next_token_id.squeeze().item())\n",
        "\n",
        "\n",
        "    # Decode the translated token IDs back to a string\n",
        "    # Need to handle potential UNK tokens and subwords from the tokenizer\n",
        "    # The BertTokenizer's decode method should handle this\n",
        "    translated_sentence = ita_tokenizer.decode(translated_tokens, skip_special_tokens=True)\n",
        "\n",
        "    return translated_sentence\n",
        "\n",
        "# Example usage\n",
        "english_sentence = \"Hello.\"\n",
        "italian_translation = translate_sentence(loaded_model, english_sentence, eng_tokenizer, ita_tokenizer, max_len=MAXLEN, device=device)\n",
        "\n",
        "print(f\"English: {english_sentence}\")\n",
        "print(f\"Italian (Translated): {italian_translation}\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HUiKYhkv7D2H",
        "outputId": "c4810bfc-de41-473b-ff76-6b28dc8117df"
      },
      "id": "HUiKYhkv7D2H",
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "2e9d8d46c6ec48fe951721b4e76f592b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_3da62fc5a64d4c3ea2542ac9b113fd24",
              "IPY_MODEL_1032c9e61e95402db775aff9cce1ca18",
              "IPY_MODEL_4637b5195f3d420d814e08e4e398b5ce"
            ],
            "layout": "IPY_MODEL_a3c52bfb52bb4fa7a27296a046cb1c4b"
          }
        },
        "3da62fc5a64d4c3ea2542ac9b113fd24": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_869b8aa9f87f487fb80063f33a5e91bd",
            "placeholder": "​",
            "style": "IPY_MODEL_d5a1679eb2904216ada827d92dff94da",
            "value": "tokenizer_config.json: 100%"
          }
        },
        "1032c9e61e95402db775aff9cce1ca18": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_53dfb4d533874d11896e037c124fd534",
            "max": 49,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_4115a5649cbf4cb4a4278f8f1666895d",
            "value": 49
          }
        },
        "4637b5195f3d420d814e08e4e398b5ce": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a6b04c4f79614f35bc25fc04582d3c8b",
            "placeholder": "​",
            "style": "IPY_MODEL_d2e1e1d7dd904fbda1e3601fc0bbc569",
            "value": " 49.0/49.0 [00:00&lt;00:00, 4.46kB/s]"
          }
        },
        "a3c52bfb52bb4fa7a27296a046cb1c4b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "869b8aa9f87f487fb80063f33a5e91bd": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d5a1679eb2904216ada827d92dff94da": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "53dfb4d533874d11896e037c124fd534": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4115a5649cbf4cb4a4278f8f1666895d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "a6b04c4f79614f35bc25fc04582d3c8b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d2e1e1d7dd904fbda1e3601fc0bbc569": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "1dd7ef8c6c1640ba8645856555ca069f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_ef18ccda0fad4776a9b280f6bdbeaad2",
              "IPY_MODEL_ec89de72cc574e30baa5d23963de7996",
              "IPY_MODEL_6cc43f882a0f4c5e81b90a4dbb38f3dd"
            ],
            "layout": "IPY_MODEL_1f144e67d8554224afc01425aba8ab23"
          }
        },
        "ef18ccda0fad4776a9b280f6bdbeaad2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_05811f120a8143168f61486b3613ea9b",
            "placeholder": "​",
            "style": "IPY_MODEL_9d93f62bcf8741078d20a997bb9960b4",
            "value": "config.json: 100%"
          }
        },
        "ec89de72cc574e30baa5d23963de7996": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7c6e5b1fac4f43aa877b74a13fccf32f",
            "max": 570,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_434efc6dbf30423a93225cad1c6a9d81",
            "value": 570
          }
        },
        "6cc43f882a0f4c5e81b90a4dbb38f3dd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f3a14bc781f7481e8ee57515c1ba2c2c",
            "placeholder": "​",
            "style": "IPY_MODEL_d96c988619c64eb8b84ae86e47336c78",
            "value": " 570/570 [00:00&lt;00:00, 56.3kB/s]"
          }
        },
        "1f144e67d8554224afc01425aba8ab23": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "05811f120a8143168f61486b3613ea9b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9d93f62bcf8741078d20a997bb9960b4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "7c6e5b1fac4f43aa877b74a13fccf32f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "434efc6dbf30423a93225cad1c6a9d81": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "f3a14bc781f7481e8ee57515c1ba2c2c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d96c988619c64eb8b84ae86e47336c78": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "14b5c26f453d41de9a763cdbafbea0b5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_d1f5e0bdd1fb4d66bf1e8d4e7e321d6b",
              "IPY_MODEL_0fb942d9f220454ea91f998cb698c36c",
              "IPY_MODEL_dee916fdc3454c6d9dcb216fb674c174"
            ],
            "layout": "IPY_MODEL_24382378281a46439757c89ad2f5caa4"
          }
        },
        "d1f5e0bdd1fb4d66bf1e8d4e7e321d6b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_63d18be3e3e743f6abe6a6edd9f524ce",
            "placeholder": "​",
            "style": "IPY_MODEL_f421de23a9264527af1d48bbd6ceef6c",
            "value": "vocab.txt: 100%"
          }
        },
        "0fb942d9f220454ea91f998cb698c36c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_92a82591177643298bf2749fbccb01cd",
            "max": 213450,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_a2d1335d033e47249a57daa6d21b0bc1",
            "value": 213450
          }
        },
        "dee916fdc3454c6d9dcb216fb674c174": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a513ba199499462593887b6693680b22",
            "placeholder": "​",
            "style": "IPY_MODEL_a6e757a66e9e4078bdb81b17de443a29",
            "value": " 213k/213k [00:00&lt;00:00, 10.6MB/s]"
          }
        },
        "24382378281a46439757c89ad2f5caa4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "63d18be3e3e743f6abe6a6edd9f524ce": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f421de23a9264527af1d48bbd6ceef6c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "92a82591177643298bf2749fbccb01cd": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a2d1335d033e47249a57daa6d21b0bc1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "a513ba199499462593887b6693680b22": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a6e757a66e9e4078bdb81b17de443a29": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "30b0db048345441fb21a06879a12df68": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_11596ee1464047b28f7909e235d91b65",
              "IPY_MODEL_a4fae2793d6f47edaca03a5cb381782c",
              "IPY_MODEL_c67a9eda068b411ab97d123d961bb2fb"
            ],
            "layout": "IPY_MODEL_2c6ced42184e4d36a5eae4a8808524c2"
          }
        },
        "11596ee1464047b28f7909e235d91b65": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_efc43f4241da488b92471d3cceaeebad",
            "placeholder": "​",
            "style": "IPY_MODEL_9c4b075f281a42f9b1e79ca50d958be5",
            "value": "tokenizer.json: 100%"
          }
        },
        "a4fae2793d6f47edaca03a5cb381782c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a4536c407a52425a9b926651a3546cdf",
            "max": 435797,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_288524b46f9d475ca11d0f4da252e4b4",
            "value": 435797
          }
        },
        "c67a9eda068b411ab97d123d961bb2fb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_92b925803a2e4d599c51028f0cbc76b4",
            "placeholder": "​",
            "style": "IPY_MODEL_c409bcd4f3774ab0a4d9cabfbf2992aa",
            "value": " 436k/436k [00:00&lt;00:00, 42.5MB/s]"
          }
        },
        "2c6ced42184e4d36a5eae4a8808524c2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "efc43f4241da488b92471d3cceaeebad": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9c4b075f281a42f9b1e79ca50d958be5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a4536c407a52425a9b926651a3546cdf": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "288524b46f9d475ca11d0f4da252e4b4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "92b925803a2e4d599c51028f0cbc76b4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c409bcd4f3774ab0a4d9cabfbf2992aa": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c7f076da6a9e490eb63feedf5937e13f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_ef0890f9392b48a1a1151dca46a3a195",
              "IPY_MODEL_27634f8ccf224222acdee6d7a831d7cb",
              "IPY_MODEL_6311e9773ad64bba91cbaeb3b0d7d596"
            ],
            "layout": "IPY_MODEL_0ac53d7c93bc4ccf9de87bd02849bf14"
          }
        },
        "ef0890f9392b48a1a1151dca46a3a195": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_fbed29969e284d2e8d36b633c76a9d70",
            "placeholder": "​",
            "style": "IPY_MODEL_051470dcfb93499c81c7514aa4ae4ed1",
            "value": "tokenizer_config.json: 100%"
          }
        },
        "27634f8ccf224222acdee6d7a831d7cb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9ce0fa0c1ae34d7e9b84b92004827d71",
            "max": 59,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_fc4d1938624b456f98b28bd9ddee74bb",
            "value": 59
          }
        },
        "6311e9773ad64bba91cbaeb3b0d7d596": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_708916a877894259a168cdecc240341f",
            "placeholder": "​",
            "style": "IPY_MODEL_ce7e8343b7764cdda8664e40800d7196",
            "value": " 59.0/59.0 [00:00&lt;00:00, 4.35kB/s]"
          }
        },
        "0ac53d7c93bc4ccf9de87bd02849bf14": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fbed29969e284d2e8d36b633c76a9d70": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "051470dcfb93499c81c7514aa4ae4ed1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "9ce0fa0c1ae34d7e9b84b92004827d71": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fc4d1938624b456f98b28bd9ddee74bb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "708916a877894259a168cdecc240341f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ce7e8343b7764cdda8664e40800d7196": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "eec4cbb450e840d8a115758411b07746": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_e66e76e8a52949f6977312d839da1d36",
              "IPY_MODEL_229e51afde92482db9a22440cf07400f",
              "IPY_MODEL_84f7358915714122ae601e96dfb129ca"
            ],
            "layout": "IPY_MODEL_887be0e4aa454499a64b81fdc2dd51fd"
          }
        },
        "e66e76e8a52949f6977312d839da1d36": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3a57cc5c45be4af9a74e6b46c9b4570b",
            "placeholder": "​",
            "style": "IPY_MODEL_8a527d535a1c47ecb3bf2f1b84ee1563",
            "value": "config.json: 100%"
          }
        },
        "229e51afde92482db9a22440cf07400f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4ddf9edce7684defa88710dbcb0e3160",
            "max": 433,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_26f72e6872004344acb5d09e76e33634",
            "value": 433
          }
        },
        "84f7358915714122ae601e96dfb129ca": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_bfd48d618cba46ee873ade9ad27c6e01",
            "placeholder": "​",
            "style": "IPY_MODEL_daebbfd2f5ea43e2be0b951e46cbd6fe",
            "value": " 433/433 [00:00&lt;00:00, 15.6kB/s]"
          }
        },
        "887be0e4aa454499a64b81fdc2dd51fd": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3a57cc5c45be4af9a74e6b46c9b4570b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8a527d535a1c47ecb3bf2f1b84ee1563": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "4ddf9edce7684defa88710dbcb0e3160": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "26f72e6872004344acb5d09e76e33634": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "bfd48d618cba46ee873ade9ad27c6e01": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "daebbfd2f5ea43e2be0b951e46cbd6fe": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "cf1166c1b400437a8484fd25e067709e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_2e438105059a4c4089f3ac7d54ae9f49",
              "IPY_MODEL_5f9067a6eee940a9b33b67412596b5f9",
              "IPY_MODEL_2dd6050915e94f5387ffad343b815776"
            ],
            "layout": "IPY_MODEL_0f48b91d54104e999362ffa469db207c"
          }
        },
        "2e438105059a4c4089f3ac7d54ae9f49": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a53b8a3858e84e6189f64bfab4c648d2",
            "placeholder": "​",
            "style": "IPY_MODEL_2038d092d9f74dd793996990564aea25",
            "value": "vocab.txt: "
          }
        },
        "5f9067a6eee940a9b33b67412596b5f9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_cb4f496cd1744d1cb9b55d095dc4afdd",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_53f7beacfb5e471db3a74591fd28f366",
            "value": 1
          }
        },
        "2dd6050915e94f5387ffad343b815776": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a282ef9705744483871fad88e915fb2c",
            "placeholder": "​",
            "style": "IPY_MODEL_0861ed936e004ea0903ddfd32a0a0fe5",
            "value": " 235k/? [00:00&lt;00:00, 10.0MB/s]"
          }
        },
        "0f48b91d54104e999362ffa469db207c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a53b8a3858e84e6189f64bfab4c648d2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2038d092d9f74dd793996990564aea25": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "cb4f496cd1744d1cb9b55d095dc4afdd": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "20px"
          }
        },
        "53f7beacfb5e471db3a74591fd28f366": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "a282ef9705744483871fad88e915fb2c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0861ed936e004ea0903ddfd32a0a0fe5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}