{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/naoya526/jpn2ita/blob/main/Bert_Translation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b42af237",
      "metadata": {
        "id": "b42af237"
      },
      "source": [
        "## Import Module"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5f189bde",
      "metadata": {
        "id": "5f189bde"
      },
      "source": [
        "I used materials below:\n",
        "[1]`06_Attention_and_Transformers_in_BERT.ipynb`\n",
        "[2]`English_to_italian_automatic_translation.ipynb`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "61e92cdc",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "61e92cdc",
        "outputId": "963eb131-783c-4523-ef05-d97d5a671342"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2.0.2\n",
            "2.6.0+cu124\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import re\n",
        "import random\n",
        "import itertools\n",
        "import math\n",
        "from pathlib import Path\n",
        "\n",
        "import tqdm\n",
        "\n",
        "import numpy as np\n",
        "print(np.__version__)\n",
        "\n",
        "import torch\n",
        "print(torch.__version__)\n",
        "\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.optim import Adam\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "\n",
        "import transformers\n",
        "from tokenizers import BertWordPieceTokenizer\n",
        "from transformers import BertTokenizer, BertConfig\n",
        "\n",
        "### Suppress useless warnings\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\", message=\"The secret `HF_TOKEN` does not exist\")\n",
        "\n",
        "from collections import defaultdict\n",
        "from transformers import AutoTokenizer"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6151fdbd",
      "metadata": {
        "id": "6151fdbd"
      },
      "source": [
        "## Define Model\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "C06d3zDIDp9k",
      "metadata": {
        "id": "C06d3zDIDp9k"
      },
      "source": [
        "\n",
        "### Encoder (Bert) part\n",
        "Here, There's the function for implementing Encoder(Bert). I implemented with refering to [1]`06_Attention_and_Transformers_in_BERT.ipynb` and the paper.\n",
        "- `MultiHeadAttention`\n",
        "- `PositionwiseFeedForward`\n",
        "- `Encoder Block`\n",
        "- `BertEmbeddings` (Embedding for words)\n",
        "- `Bert`\n",
        "Bert is highly possible to understand meaning, but it is not enough for produce translation.\n",
        "Hence, In the next part, I implement Decoder. It is quite similar to Bert."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "b9f946b7",
      "metadata": {
        "id": "b9f946b7"
      },
      "outputs": [],
      "source": [
        "class MultiHeadAttention(nn.Module):\n",
        "    \"\"\"\n",
        "    - Query, Key, Value\n",
        "    - Scaled Dot Product Attention: softmax(QK^T / sqrt(d_k))V\n",
        "    \"\"\"\n",
        "    def __init__(self, d_model, num_heads, dropout=0.1):\n",
        "        super().__init__()\n",
        "        assert d_model % num_heads == 0, \"d_model must be divisible by num_heads\"\n",
        "\n",
        "        self.d_model = d_model\n",
        "        self.num_heads = num_heads\n",
        "        self.head_dim = d_model // num_heads\n",
        "        self.dropout = torch.nn.Dropout(dropout)\n",
        "\n",
        "        # Q, K, V linear Conversion\n",
        "        self.query = torch.nn.Linear(d_model, d_model)\n",
        "        self.key = torch.nn.Linear(d_model, d_model)\n",
        "        self.value = torch.nn.Linear(d_model, d_model)\n",
        "\n",
        "        self.out_proj = torch.nn.Linear(d_model, d_model)\n",
        "\n",
        "    def forward(self, x, mask=None):\n",
        "        batch_size, seq_len, d_model = x.shape\n",
        "\n",
        "        # step1: Q, K, V\n",
        "        query = self.query(x)  # (batch, seq_len, d_model)\n",
        "        key = self.key(x)      # (batch, seq_len, d_model)\n",
        "        value = self.value(x)  # (batch, seq_len, d_model)\n",
        "\n",
        "        # step2: Multi-Head\n",
        "        query = query.view(batch_size, seq_len, self.num_heads, self.head_dim)\n",
        "        key = key.view(batch_size, seq_len, self.num_heads, self.head_dim)  # ‰øÆÊ≠£: query.shape ‚Üí batch_size\n",
        "        value = value.view(batch_size, seq_len, self.num_heads, self.head_dim)\n",
        "\n",
        "        # step3: Change Dimention for Calclate Efficiently\n",
        "        query = query.permute(0, 2, 1, 3)  # (batch, num_heads, seq_len, head_dim)\n",
        "        key = key.permute(0, 2, 1, 3)\n",
        "        value = value.permute(0, 2, 1, 3)\n",
        "\n",
        "        # „Çπ„ÉÜ„ÉÉ„Éó4: Scaled Dot-Product Attention\n",
        "        # scores = Q @ K^T / sqrt(d_k)\n",
        "        scores = torch.matmul(query, key.transpose(-2, -1)) / math.sqrt(self.head_dim)\n",
        "\n",
        "        # „Çπ„ÉÜ„ÉÉ„Éó5: „Éû„Çπ„ÇØÂá¶ÁêÜÔºà„Ç™„Éó„Ç∑„Éß„É≥Ôºâ\n",
        "        if mask is not None:\n",
        "            # maskÂΩ¢Áä∂: (batch, 1, 1, seq_len) „Åæ„Åü„ÅØ (batch, 1, seq_len, seq_len) „Å™„Å©„ÄÅscoresÂΩ¢Áä∂„Å´„Éñ„É≠„Éº„Éâ„Ç≠„É£„Çπ„ÉàÂèØËÉΩ„Å™ÂΩ¢Áä∂\n",
        "            # scoresÂΩ¢Áä∂: (batch, num_heads, seq_len, seq_len)\n",
        "            # 0„Çí-1e9„Å´Â§âÊèõÔºàSoftmax„Åß0„Å´„Å™„Çã„Çà„ÅÜ„Å´Ôºâ‚Üí Âä†ÁÆó„Å´„Çà„Çã„Éû„Çπ„Ç≠„É≥„Ç∞„Å´Â§âÊõ¥\n",
        "            # scores = scores.masked_fill(mask == 0, -1e9) # ÂÖÉ„ÅÆ„Ç≥„Éº„Éâ\n",
        "            scores = scores + mask # Âä†ÁÆó„Å´„Çà„Çã„Éû„Çπ„Ç≠„É≥„Ç∞„Å´Â§âÊõ¥\n",
        "\n",
        "        # „Çπ„ÉÜ„ÉÉ„Éó6: Softmax + Dropout\n",
        "        weights = F.softmax(scores, dim=-1)  # (batch, num_heads, seq_len, seq_len)\n",
        "        weights = self.dropout(weights)\n",
        "        # „Çπ„ÉÜ„ÉÉ„Éó7: Value „Å®„ÅÆÁ©ç\n",
        "        context = torch.matmul(weights, value)\n",
        "        # „Çπ„ÉÜ„ÉÉ„Éó8: „Éò„ÉÉ„Éâ„ÇíÁµêÂêà„Åó„Å¶ÂÖÉ„ÅÆÂΩ¢Áä∂„Å´Êàª„Åô\n",
        "        context = context.permute(0, 2, 1, 3)\n",
        "        # ‚Üí (batch, seq_len, d_model)\n",
        "        context = context.contiguous().view(batch_size, seq_len, self.num_heads * self.head_dim)\n",
        "\n",
        "        # „Çπ„ÉÜ„ÉÉ„Éó9: ÊúÄÁµÇÁöÑ„Å™Á∑öÂΩ¢Â§âÊèõ\n",
        "        return self.out_proj(context)  # ‰øÆÊ≠£: output_linear ‚Üí out_proj\n",
        "\n",
        "class PositionwiseFeedForward(nn.Module):\n",
        "    \"\"\"\n",
        "    „Éí„É≥„Éà:\n",
        "    - 2Â±§„ÅÆ„Éï„Ç£„Éº„Éâ„Éï„Ç©„ÉØ„Éº„Éâ„Éç„ÉÉ„Éà„ÉØ„Éº„ÇØ\n",
        "    - ‰∏≠ÈñìÂ±§„Åß„ÅØÊ¨°ÂÖÉ„ÇíÊã°ÂºµÔºàÈÄöÂ∏∏4ÂÄçÔºâ\n",
        "    - GELUÊ¥ªÊÄßÂåñÈñ¢Êï∞„Çí‰ΩøÁî®\n",
        "    - „Éâ„É≠„ÉÉ„Éó„Ç¢„Ç¶„Éà„ÇÇÂøò„Çå„Åö„Å´\n",
        "    \"\"\"\n",
        "    def __init__(self, d_model, d_ff, dropout=0.1):\n",
        "        super().__init__()\n",
        "        self.linear1 = nn.Linear(d_model, d_ff)  # ÂÖ•ÂäõÊ¨°ÂÖÉ ‚Üí ‰∏≠ÈñìÊ¨°ÂÖÉ\n",
        "        self.linear2 = nn.Linear(d_ff, d_model)  # ‰∏≠ÈñìÊ¨°ÂÖÉ\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "        self.gelu = nn.GELU()\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.linear1(x)\n",
        "        x = self.gelu(x)\n",
        "        x = self.dropout(x)\n",
        "        x = self.linear2(x)\n",
        "        x = self.dropout(x)\n",
        "        return x\n",
        "\n",
        "class EncoderBlock(nn.Module):\n",
        "    \"\"\"\n",
        "    „Éí„É≥„Éà:\n",
        "    - Multi-Head Attention + Residual Connection + Layer Norm\n",
        "    - Feed Forward + Residual Connection + Layer Norm\n",
        "    - Which is better??: Pre-LN vs Post-LN\n",
        "    \"\"\"\n",
        "    def __init__(self, d_model, num_heads, d_ff, dropout=0.1):\n",
        "        super().__init__()\n",
        "        self.attention = MultiHeadAttention(d_model,num_heads)\n",
        "        self.ffn = PositionwiseFeedForward(d_model,d_ff)\n",
        "\n",
        "        self.layer_norm1 = nn.LayerNorm(normalized_shape=d_model, eps=1e-6)\n",
        "        self.layer_norm2 = nn.LayerNorm(normalized_shape=d_model, eps=1e-6)\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "    def forward(self, x, mask=None):\n",
        "        #Attention block\n",
        "        #TODO implement transformer block\n",
        "        residual = x\n",
        "        #print(\"Took Residual...\",x.shape)\n",
        "        x = self.layer_norm1(x)\n",
        "        #print(\"calculating layer norm...\",x.shape)\n",
        "        x = self.dropout(self.attention(x,mask))\n",
        "        #print(\"calculating Attention...\",x.shape)\n",
        "        x = x + residual\n",
        "        #print(\"calculating Residual Connection...\",x.shape)\n",
        "        #ffnn\n",
        "        residual = x\n",
        "        x = self.layer_norm2(x)\n",
        "        #print(\"calculating layer norm...\",x.shape)\n",
        "        x = self.dropout(self.ffn(x))\n",
        "        #print(\"calculating ffn...\",x.shape)\n",
        "        x = x + residual\n",
        "        return x\n",
        "\n",
        "\n",
        "class BertEmbeddings(nn.Module):\n",
        "    \"\"\"\n",
        "    - Token Embeddings (Ë™ûÂΩô„Çµ„Ç§„Ç∫ √ó d_model)\n",
        "    - Position Embeddings (ÊúÄÂ§ßÁ≥ªÂàóÈï∑ √ó d_model)\n",
        "    - Segment Embeddings (2 √ó d_model, NSP„Çø„Çπ„ÇØÁî®)\n",
        "    - 3„Å§„ÇíË∂≥„ÅóÂêà„Çè„Åõ„Å¶LayerNorm„Å®Dropout\n",
        "    \"\"\"\n",
        "    def __init__(self, vocab_size, d_model, max_seq_len=512, dropout=0.1):\n",
        "        super().__init__()\n",
        "        # TODO: 3Á®ÆÈ°û„ÅÆÂüã„ÇÅËæº„Åø„ÇíÂÆüË£Ö\n",
        "        self.d_model = d_model\n",
        "        self.token = torch.nn.Embedding(vocab_size, d_model, padding_idx=0)\n",
        "        self.position = torch.nn.Embedding(max_seq_len, d_model)\n",
        "        self.segment = torch.nn.Embedding(2, d_model)  # 2„Å§„ÅÆ„Çª„Ç∞„É°„É≥„ÉàÔºà0„Å®1Ôºâ\n",
        "        self.layer_norm = nn.LayerNorm(d_model)\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "        #Embedding: Lookup table that keep meaning vector of words\n",
        "    def forward(self, input_ids, token_type_ids=None):\n",
        "        # TODO: Âüã„ÇÅËæº„Åø„ÅÆË®àÁÆó„ÇíÂÆüË£Ö\n",
        "        batch_size, seq_len = input_ids.shape\n",
        "        # Step 1: Token Embeddings\n",
        "        token_embeddings = self.token(input_ids)\n",
        "        # Step 2: Position Embeddings\n",
        "        position_ids = torch.arange(seq_len, device=input_ids.device).unsqueeze(0)\n",
        "        position_ids = position_ids.expand(batch_size, -1)  # üîß „Éê„ÉÉ„ÉÅÊ¨°ÂÖÉ„ÇíÊã°Âºµ\n",
        "        position_embeddings = self.position(position_ids)\n",
        "        # Step 3: Segment Embeddings\n",
        "        if token_type_ids is None:\n",
        "            token_type_ids = torch.zeros_like(input_ids)  # ÂÖ®„Å¶0ÔºàÂçò‰∏ÄÊñáÔºâ\n",
        "        segment_embeddings = self.segment(token_type_ids)  # (batch, seq_len, d_model)\n",
        "        embeddings = token_embeddings + position_embeddings + segment_embeddings\n",
        "        embeddings = self.dropout(self.layer_norm(embeddings))\n",
        "\n",
        "        return embeddings\n",
        "\n",
        "class Bert(nn.Module):\n",
        "    \"\"\"\n",
        "    BERTÂÆüË£Ö„ÅÆÊúÄÁµÇÂΩ¢\n",
        "\n",
        "    Â≠¶Áøí„ÅÆ„Éí„É≥„Éà:\n",
        "    1. Ë´ñÊñá„ÇíË™≠„Çì„ÅßÂÖ®‰ΩìÂÉè„ÇíÁêÜËß£\n",
        "    2. Â∞è„Åï„Å™ÈÉ®ÂìÅ„Åã„ÇâÂÆüË£ÖÔºàAttention ‚Üí FFN ‚Üí Block ‚Üí Full ModelÔºâ\n",
        "    3. ÂêÑÂ±§„Åß print(tensor.shape) „Åó„Å¶„Çµ„Ç§„Ç∫„ÇíÁ¢∫Ë™ç\n",
        "    4. Á∞°Âçò„Å™„ÉÄ„Éü„Éº„Éá„Éº„Çø„Åß„ÉÜ„Çπ„Éà\n",
        "    5. ‰∫ãÂâçÂ≠¶Áøí„ÅØË®àÁÆóÈáè„ÅåÂ§ß„Åç„ÅÑ„ÅÆ„Åß„ÄÅÂ∞è„Åï„ÅÑ„É¢„Éá„É´„Åã„ÇâÈñãÂßã\n",
        "\n",
        "    ÈáçË¶Å„Å™Ê¶ÇÂøµ:\n",
        "    - Bidirectional: Â∑¶Âè≥‰∏°ÊñπÂêë„ÅÆÊñáËÑà„ÇíË¶ã„Çã\n",
        "    - Masked Language Model: „É©„É≥„ÉÄ„É†„Å´„Éû„Çπ„ÇØ„Åó„ÅüÂçòË™û„Çí‰∫àÊ∏¨\n",
        "    - Next Sentence Prediction: 2„Å§„ÅÆÊñá„ÅåÈÄ£Á∂ö„Åô„Çã„Åã„Çí‰∫àÊ∏¨\n",
        "    - Attention Weights: „Å©„ÅÆÂçòË™û„Å´Ê≥®ÁõÆ„Åó„Å¶„ÅÑ„Çã„Åã„ÅÆÂèØË¶ñÂåñ\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, vocab_size, d_model=768, num_layers=12, num_heads=12, d_ff=3072, max_seq_len=512, dropout=0.1):\n",
        "        super().__init__()\n",
        "        self.d_model = d_model\n",
        "        self.num_layers = num_layers\n",
        "        self.heads = num_heads\n",
        "        # paper noted 4*d_model size for ff\n",
        "        self.feed_forward_hidden = d_model * 4\n",
        "        # embedding for BERT, sum of positional, segment, token embeddings\n",
        "        self.embedding = BertEmbeddings(vocab_size, d_model, max_seq_len, dropout)\n",
        "\n",
        "        self.encoder_blocks = torch.nn.ModuleList(\n",
        "            [EncoderBlock(d_model, num_heads, d_model * 4, dropout) for _ in range(num_layers)])\n",
        "\n",
        "    def forward(self, input_ids, attention_mask=None, token_type_ids=None):\n",
        "        # TODO: BERTÂÖ®‰Ωì„ÅÆforward pass„ÇíÂÆüË£Ö\n",
        "        if attention_mask is None:\n",
        "            attention_mask = (input_ids != 0).float()\n",
        "        if attention_mask.dim() == 2:\n",
        "            # (batch, seq_len) ‚Üí (batch, 1, 1, seq_len)\n",
        "            extended_attention_mask = attention_mask.unsqueeze(1).unsqueeze(2)\n",
        "            # print(\"squeeze is required\") # „Éá„Éê„ÉÉ„Ç∞„Éó„É™„É≥„Éà„ÇíÂâäÈô§\n",
        "        elif attention_mask.dim() == 4:\n",
        "            # Êó¢„Å´Ê≠£„Åó„ÅÑÂΩ¢Áä∂„ÅÆÂ†¥Âêà„ÅØ„Åù„ÅÆ„Åæ„Åæ‰ΩøÁî®\n",
        "            extended_attention_mask = attention_mask\n",
        "            # print(\"squeeze is not required\") # „Éá„Éê„ÉÉ„Ç∞„Éó„É™„É≥„Éà„ÇíÂâäÈô§\n",
        "        else:\n",
        "             raise ValueError(f\"Attention mask should be 2D or 4D, but got {attention_mask.dim()}D\")\n",
        "\n",
        "        # 0„Çí-1e9„Å´Â§âÊèõÔºàSoftmax„Åß0„Å´„Å™„Çã„Çà„ÅÜ„Å´Ôºâ - Âä†ÁÆó„Å´„Çà„Çã„Éû„Çπ„Ç≠„É≥„Ç∞„ÅÆ„Åü„ÇÅ„Å´ÂÄ§„ÇíË™øÊï¥\n",
        "        extended_attention_mask = (1.0 - extended_attention_mask) * -1e9\n",
        "\n",
        "\n",
        "        # embedding the indexed sequence to sequence of vectors\n",
        "        x = self.embedding(input_ids, token_type_ids)\n",
        "        # running over multiple transformer blocks\n",
        "        for encoder in self.encoder_blocks:\n",
        "            x = encoder.forward(x, extended_attention_mask) # ‰øÆÊ≠£Âæå„ÅÆMultiHeadAttention„ÅØÂä†ÁÆó„Éû„Çπ„ÇØ„ÇíÊúüÂæÖ\n",
        "        return x"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "dfc507b7",
      "metadata": {
        "id": "dfc507b7"
      },
      "source": [
        "### Decoder part\n",
        "This part, I implemented these functions:\n",
        "- `CrossAttention`(English Queue, Italian Key, Italian Value)\n",
        "- `DecoderBlock`\n",
        "- `BertTranslationModel`(Bert + Decoder Embedding + DecoderBlock*`num_layers`)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "_pie-kLFt9PO",
      "metadata": {
        "id": "_pie-kLFt9PO"
      },
      "outputs": [],
      "source": [
        "class CrossAttention(nn.Module):\n",
        "    \"\"\"\n",
        "    this module is implemented with modifying MultiHeadAttention.\n",
        "    Query: English\n",
        "    Key, Value: Italian\n",
        "    You can see the difference in forward input\n",
        "    \"\"\"\n",
        "    def __init__(self, d_model, num_heads, dropout=0.1):\n",
        "        super().__init__() # initialization\n",
        "        assert d_model % num_heads == 0, \"d_model must be divisible by num_heads\"\n",
        "\n",
        "        self.d_model = d_model\n",
        "        self.num_heads = num_heads\n",
        "        self.head_dim = d_model // num_heads  # dimention of each head\n",
        "        self.dropout = torch.nn.Dropout(dropout)\n",
        "\n",
        "        # Q, K, V „ÅÆÁ∑öÂΩ¢Â§âÊèõÔºà‰øÆÊ≠£Ôºötorch.nn.linear ‚Üí torch.nn.LinearÔºâ\n",
        "        self.query = torch.nn.Linear(d_model, d_model)\n",
        "        self.key = torch.nn.Linear(d_model, d_model)\n",
        "        self.value = torch.nn.Linear(d_model, d_model)\n",
        "\n",
        "        # ÊúÄÁµÇÁöÑ„Å™Âá∫ÂäõÂ§âÊèõ\n",
        "        self.out_proj = torch.nn.Linear(d_model, d_model)\n",
        "\n",
        "    def forward(self, query_input, key_value_input, mask=None): # here is the difference\n",
        "        batch_size, q_len, _ = query_input.shape\n",
        "        _, kv_len, _ = key_value_input.shape\n",
        "        # „Çπ„ÉÜ„ÉÉ„Éó1: Q, K, V „ÇíÁ∑öÂΩ¢Â§âÊèõ„ÅßÁîüÊàê\n",
        "        query = self.query(query_input)  # (batch, seq_len, d_model)\n",
        "        key = self.key(key_value_input)      # (batch, seq_len, d_model)\n",
        "        value = self.value(key_value_input)  # (batch, seq_len, d_model)\n",
        "\n",
        "        # „Çπ„ÉÜ„ÉÉ„Éó2: Multi-HeadÁî®„Å´Ê¨°ÂÖÉ„ÇíÂ§âÂΩ¢\n",
        "        query = query.view(batch_size, q_len, self.num_heads, self.head_dim)\n",
        "        key = key.view(batch_size, kv_len, self.num_heads, self.head_dim)  # ‰øÆÊ≠£: query.shape ‚Üí batch_size\n",
        "        value = value.view(batch_size, kv_len, self.num_heads, self.head_dim)\n",
        "\n",
        "        query = query.permute(0, 2, 1, 3)  # (batch, num_heads, seq_len, head_dim)\n",
        "        key = key.permute(0, 2, 1, 3)\n",
        "        value = value.permute(0, 2, 1, 3)\n",
        "\n",
        "        # „Çπ„ÉÜ„ÉÉ„Éó4: Scaled Dot-Product Attention\n",
        "        # scores = Q @ K^T / sqrt(d_k)\n",
        "        scores = torch.matmul(query, key.transpose(-2, -1)) / math.sqrt(self.head_dim)\n",
        "\n",
        "        # „Çπ„ÉÜ„ÉÉ„Éó5: „Éû„Çπ„ÇØÂá¶ÁêÜÔºà„Ç™„Éó„Ç∑„Éß„É≥Ôºâ\n",
        "        if mask is not None:\n",
        "            # maskÂΩ¢Áä∂: (batch, 1, 1, seq_len) ‚Üí scoresÂΩ¢Áä∂: (batch, num_heads, seq_len, seq_len)\n",
        "            scores = scores + mask  # „Éñ„É≠„Éº„Éâ„Ç≠„É£„Çπ„Éà„ÅßÂä†ÁÆó\n",
        "\n",
        "        # „Çπ„ÉÜ„ÉÉ„Éó6: Softmax + Dropout\n",
        "        weights = F.softmax(scores, dim=-1)  # (batch, num_heads, seq_len, seq_len)\n",
        "        weights = self.dropout(weights)\n",
        "        # „Çπ„ÉÜ„ÉÉ„Éó7: Value „Å®„ÅÆÁ©ç\n",
        "        context = torch.matmul(weights, value)\n",
        "        # „Çπ„ÉÜ„ÉÉ„Éó8: „Éò„ÉÉ„Éâ„ÇíÁµêÂêà„Åó„Å¶ÂÖÉ„ÅÆÂΩ¢Áä∂„Å´Êàª„Åô\n",
        "        context = context.permute(0, 2, 1, 3)\n",
        "        # ‚Üí (batch, seq_len, d_model)\n",
        "        context = context.contiguous().view(batch_size, q_len, self.num_heads * self.head_dim)\n",
        "\n",
        "        # „Çπ„ÉÜ„ÉÉ„Éó9: ÊúÄÁµÇÁöÑ„Å™Á∑öÂΩ¢Â§âÊèõ\n",
        "        return self.out_proj(context)  # ‰øÆÊ≠£: output_linear ‚Üí out_proj\n",
        "\n",
        "class DecoderBlock(nn.Module):\n",
        "    \"\"\"\n",
        "    Basically similar to EncoderBlock, but refer to the infomation of Input(English context)\n",
        "    \"\"\"\n",
        "    def __init__(self, d_model, num_heads, d_ff, dropout=0.1):\n",
        "        super().__init__()\n",
        "        #First, implement Self Attention\n",
        "        self.self_attention = MultiHeadAttention(d_model,num_heads)\n",
        "        #Second, implement Cross Attention\n",
        "        self.cross_attention = CrossAttention(d_model, num_heads)\n",
        "        #Third, FFNN\n",
        "        self.ffn = PositionwiseFeedForward(d_model,d_ff)\n",
        "\n",
        "        self.layer_norm1 = nn.LayerNorm(normalized_shape=d_model, eps=1e-6)\n",
        "        self.layer_norm2 = nn.LayerNorm(normalized_shape=d_model, eps=1e-6)\n",
        "        self.layer_norm3 = nn.LayerNorm(normalized_shape=d_model, eps=1e-6)\n",
        "\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "    def forward(self, x, encoder_output, self_mask=None, cross_mask=None):\n",
        "        #Self Attention\n",
        "        residual = x\n",
        "        x = self.layer_norm1(x)\n",
        "        x = self.self_attention(x,mask=self_mask)\n",
        "        x = self.dropout(x) + residual\n",
        "\n",
        "        #Cross Attention\n",
        "        residual = x\n",
        "        x = self.layer_norm2(x)\n",
        "        x = self.cross_attention(\n",
        "            query_input=x,\n",
        "            key_value_input=encoder_output,\n",
        "            mask=cross_mask\n",
        "        )\n",
        "        x = self.dropout(x) + residual\n",
        "\n",
        "        residual = x\n",
        "        x = self.layer_norm3(x)\n",
        "        x = self.ffn(x)\n",
        "        x = self.dropout(x) + residual\n",
        "        return x\n",
        "\n",
        "class BertTranslationModel(nn.Module):\n",
        "    \"\"\"\n",
        "    Ita2Eng Translation Model\n",
        "    Encoder: Bert\n",
        "    Decoder: BertEmbedding, DecoderBlock*N, FFN\n",
        "    \"\"\"\n",
        "    def __init__(self,\n",
        "                 ita_vocab_size,  # „Ç§„Çø„É™„Ç¢Ë™ûË™ûÂΩô„Çµ„Ç§„Ç∫\n",
        "                 eng_vocab_size,  # Ëã±Ë™ûË™ûÂΩô„Çµ„Ç§„Ç∫\n",
        "                 max_seq_len,\n",
        "                 d_model=512,\n",
        "                 num_layers=6,\n",
        "                 num_heads=8,\n",
        "                 dropout=0.1):\n",
        "        super().__init__()\n",
        "\n",
        "        self.encoder = Bert(\n",
        "            vocab_size=eng_vocab_size,\n",
        "            d_model=d_model,\n",
        "            num_layers=num_layers,\n",
        "            num_heads=num_heads,\n",
        "            max_seq_len=max_seq_len,\n",
        "            dropout=dropout\n",
        "        )\n",
        "\n",
        "        self.decoder_embeddings = BertEmbeddings(\n",
        "            vocab_size=ita_vocab_size,\n",
        "            d_model=d_model,\n",
        "            max_seq_len=max_seq_len,\n",
        "            dropout=dropout\n",
        "        )\n",
        "\n",
        "        self.decoder_blocks = nn.ModuleList([\n",
        "            DecoderBlock(\n",
        "                d_model=d_model,\n",
        "                num_heads=num_heads,\n",
        "                d_ff=d_model * 4, #based on the paper of Bert\n",
        "                dropout=dropout)\n",
        "            for _ in range(num_layers)\n",
        "        ])\n",
        "\n",
        "        self.output_proj = nn.Linear(d_model, ita_vocab_size)\n",
        "\n",
        "    def forward(self,\n",
        "                eng_ids,\n",
        "                ita_ids,\n",
        "                eng_mask=None,\n",
        "                ita_mask=None,\n",
        "                eng_token_type_ids=None,\n",
        "                ita_token_type_ids=None):\n",
        "        # understand english\n",
        "        encoder_output = self.encoder(input_ids=eng_ids, attention_mask=eng_mask, token_type_ids=eng_token_type_ids)\n",
        "        # produce Italian\n",
        "        decoder_input = self.decoder_embeddings(input_ids=ita_ids, token_type_ids=ita_token_type_ids)\n",
        "\n",
        "        for decoder_block in self.decoder_blocks:\n",
        "            decoder_input = decoder_block(\n",
        "                x=decoder_input,\n",
        "                encoder_output=encoder_output,\n",
        "                self_mask=ita_mask,               # Ëã±Ë™û„ÅÆCausal mask\n",
        "                cross_mask=eng_mask\n",
        "                )\n",
        "        logits = self.output_proj(decoder_input)\n",
        "        return logits"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d02d832e",
      "metadata": {
        "id": "d02d832e"
      },
      "source": [
        "## Use model\n",
        "In this part, I followed the configuration of [2]`English_to_italian_automatic_translation.ipynb`.\n",
        "\n",
        "---\n",
        "### Prepare Dataset\n",
        "for Bert, `<sos>`and `<eos>` are not required. Hence, ignore these token."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "EZbXW_bCx1Ef",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EZbXW_bCx1Ef",
        "outputId": "30b00fee-db84-44a6-affe-f61ae60f9b59"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1_npGYZk13fs5hE0kAggiSrmKkqW3OrLT\n",
            "To: <_io.BufferedWriter name='<stdout>'>\n",
            "100% 3.92M/3.92M [00:00<00:00, 11.2MB/s]\n"
          ]
        }
      ],
      "source": [
        "# Download the files\n",
        "URL = \"https://drive.google.com/file/d/1_npGYZk13fs5hE0kAggiSrmKkqW3OrLT/view?usp=sharing\"\n",
        "!gdown --fuzzy $URL -O- | tar -xz"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "7uYUnrAouYf1",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7uYUnrAouYf1",
        "outputId": "05bc55d3-ae17-453c-8435-8676f3036da6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['hi .', 'hi .', 'run !', 'run !', 'run !', 'who ?', 'wow !', 'duck !', 'duck !', 'jump !', 'jump !', 'jump !', 'jump .', 'jump .', 'jump .', 'stay .', 'stay .', 'stay .', 'stay .', 'stay .', 'stay .', 'stay .', 'stay .', 'stay .', 'stop !', 'stop !', 'stop !', 'wait !', 'wait !', 'wait !', 'wait .', 'wait .', 'wait .', 'do it .', 'do it .', 'do it .', 'do it .', 'do it .', 'do it .', 'go on .', 'go on .', 'go on .', 'go on .', 'go on .', 'go on .', 'hello !', 'hello !', 'hello !', 'hello .', 'i hid .']\n",
            "['ciao !', 'ciao .', 'corri !', 'corra !', 'correte !', 'chi ?', 'wow !', 'amore !', 'tesoro !', 'salta !', 'salti !', 'saltate !', 'salta .', 'salti .', 'saltate .', 'resta .', 'stai .', 'stia .', 'state .', 'resti .', 'restate .', 'rimani .', 'rimanga .', 'rimanete .', 'fermati !', 'fermatevi !', 'si fermi !', 'aspetta !', 'aspettate !', 'aspetti !', 'aspetta .', 'aspetti .', 'aspettate .', 'fallo .', 'falla .', 'lo faccia .', 'la faccia .', 'fatelo .', 'fatela .', 'vai avanti .', 'continua .', 'continui .', 'continuate .', 'vada avanti .', 'andate avanti .', 'buongiorno !', 'ciao !', 'salve .', 'ciao .', 'mi sono nascosto .']\n",
            "333112 333112\n"
          ]
        }
      ],
      "source": [
        "# for Bert, <sos> and <eos> are not required\n",
        "#SPECIAL = [\"<sos>\", \"<eos>\", \"<pad>\"]\n",
        "SPECIAL = [\"<pad>\"]\n",
        "MAXLEN = 20\n",
        "\n",
        "f = open(\"text-eng.txt\")\n",
        "# Define the list of all tokens in the English set ...\n",
        "ENG_VOCABULARY = []\n",
        "for line in f:\n",
        "    line = line.strip()\n",
        "    # Remove <sos> and <eos>\n",
        "    line = line.replace('<sos>', '').replace('<eos>', '').strip()\n",
        "    if line == \"\":\n",
        "        continue\n",
        "\n",
        "    ENG_VOCABULARY.append(line)\n",
        "f.close()\n",
        "print(ENG_VOCABULARY[:50])\n",
        "\n",
        "f = open(\"text-ita.txt\")\n",
        "# Define the list of all tokens in the Italian set ...\n",
        "ITA_VOCABULARY = []\n",
        "for line in f:\n",
        "    line = line.strip()\n",
        "    # Remove <sos> and <eos>\n",
        "    line = line.replace('<sos>', '').replace('<eos>', '').strip()\n",
        "    if line == \"\":\n",
        "        continue\n",
        "    ITA_VOCABULARY.append(line)\n",
        "f.close()\n",
        "print(ITA_VOCABULARY[:50])\n",
        "# Make sure that the three special tokens have the same indices in the two vocabularies.\n",
        "# Assign here the three indices...\n",
        "\n",
        "PAD = SPECIAL[0]\n",
        "\n",
        "# Inverse mappings.\n",
        "ENG_INVERSE = {w: n for n, w in enumerate(ENG_VOCABULARY)}\n",
        "ITA_INVERSE = {w: n for n, w in enumerate(ITA_VOCABULARY)}\n",
        "#print(ENG_INVERSE)\n",
        "print(len(ENG_VOCABULARY), len(ITA_VOCABULARY))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5I5NmJq4yeec",
      "metadata": {
        "id": "5I5NmJq4yeec"
      },
      "source": [
        "### Incremental approach to token vocabulary building\n",
        "In the lesson of Deep Learning, I learned the sophisticated way of tokenizing words called WordPiece tokenization.\n",
        "\n",
        "The WordPiece tokenization algorithm builds its vocabulary incrementally, starting from a basic alphabet and iteratively merging subword units based on their frequency and co-occurrence patterns. (cited from [1]`06_Attention_and_Transformers_in_Bert.ipynb`)\n",
        "\n",
        "---\n",
        "\n",
        "#### The demonstration of pretrained tokenizer\n",
        "\n",
        "In [1], Tokenizer `bert-base-cased` was used for English(For tokenization of English, it's used in this project as well). In this project, Tokenizier [3]`dbmdz/bert-base-italian-cased` for italian is used.\n",
        "[3]https://huggingface.co/dbmdz/bert-base-italian-cased  \n",
        "\\\n",
        "In this section, With using small scentence, The procedure will be explained.\n",
        "\n",
        "These procedure will be iterated:\n",
        "- Compute word frequencies\n",
        "- Split Words into Alphabet\n",
        "- Compute score of each pair\n",
        "- Merge the pair"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "TOiqXhYIus4m",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 635,
          "referenced_widgets": [
            "f46c31e05f2e438f9ab5cccb12f31c58",
            "366d6f6fff93419381d99f158d5f2cc4",
            "64a9f52f113c48ea89f3466d38abeac4",
            "5812199c640244d5857e590ece65af68",
            "29a4d6a70f94463d9d6d6c56e9d552ad",
            "73a63a6aa8a347fc962af21cbdcd622b",
            "ba3b261121a247b4bad838168270c8a8",
            "13fa7e6bd7c54ed5a788065d44929db0",
            "dd5de324b8414fe0a090f9b2b0bc5e06",
            "811910f03610425885dc5418c938847b",
            "864e9484e9a1409bbcb7be3390283b15",
            "f4b3b22bb67049ee9b394b5057d3b87a",
            "50b5a34fe5e446e2a4102b1378eb0ff1",
            "51201d87be604c09a442651236ff1990",
            "79ca501aa275412ea8e8eb8654c0395c",
            "e2ec7cc8b545456f8eb1cada455af2ee",
            "6c0d2e8739d94aa3b3ea575e180649d8",
            "3c585773ac4e4130a43fd325924bedd6",
            "950e450b103e4035a2a6637a1c6997f2",
            "22eaccffa7b3406d9cad5b916ab08a58",
            "276621bda1fe42069da307f08d78c7cc",
            "7047eac3e3cc432391c9c1eea76cafdb",
            "91228710c0cd4f0ea7977cd5a40d1ba1",
            "17c53e21d0d1415ea6fb72061225fa42",
            "2378330ce89142dfba64c1f9ef73ca44",
            "9e7781f8f55b4c6a80090de0edd6e4c9",
            "7a50047618854ea187aa81ed833f265e",
            "a83d63d7ee664d0bbb88d0bb9d517c7d",
            "1852b675391d4a3c83dd44eab122e0b1",
            "bfa4dbe867a3451bace9e47189ae1dbe",
            "dfc9a511003c4a58b2ab3b3979f05702",
            "94efbd73c4de41e997cbd8efb87ca2c5",
            "c4c3e5a4861a453ab40d1a5a91fbbbcf",
            "06738242f3f14c26bd4e209b131c8895",
            "4a4f8e913b314771bf3e3d4de59d199c",
            "591619e0c87344db8ba642d5eca7bb48",
            "c1d2527f7bc14999a0ecc0758c45d013",
            "ed92b1ab8994424393ccbf865b2ccf72",
            "7f598711f6bb4ddca5e44d4784776bb2",
            "fb9d410f37e04d869769988e72d0d944",
            "5a7cc35ffd734d50b97441b592aa7234",
            "ea1fbd88c645493a813f7846f6772861",
            "35682dc8794e4b3d9624cc96a755b765",
            "950f3f5fb52e4df8b0c537e56810685a",
            "1aa46824aea54eed9e11e8d539ecf43f",
            "459891e1216c49e39a8374b3490055e5",
            "42a577a374664a678189949adbe974da",
            "359a067a4da24754967840e8662749b6",
            "d5f66633f6a341d187f22d6cc9561dd7",
            "a10b10e56e7b4fb09e75231aca3168d4",
            "4899cd7a681b44129724681c26b61f78",
            "7dc1e35a253646fa9dccc1fd08a55349",
            "ad2046f76d5049c585a82eaf87a23851",
            "c27205f76c5a449e9d51dada5c00080c",
            "cfa83458a9104476b4a075b167c05f67",
            "9f4f8fdededd40959f56f003ed08e473",
            "b107e1c202e94dd4bd8b67824c8decc5",
            "6dce994823b3415988f48a04d7ba282a",
            "71a9b6b4271842608928604d785e3074",
            "b2a5722782924366b943ffe6545a4c5d",
            "eb8eb096667543d8ba606f331b691835",
            "d52775c1aa674b89a882f01b7b43e877",
            "2717aaef635b40758efd091c9848fe4a",
            "c6a8644fe51b449aab1079cce7ea6dfe",
            "1b020b9cc5ed4cee9203d48c1e88e475",
            "074f1700383a422585d728722b3b49ca",
            "c22560089e74473798a947ffa18dfac7",
            "8b7c8cc0fb7844b4bce7442dfe428b83",
            "132ea0df557247d6bf7fb38cc96525e0",
            "adcff33dc6c5407fb8989bc8018a020e",
            "80586b518e97488ea24544f4f9be3cef",
            "4e6fd1f8c3914983a21046b7521fabfe",
            "8a4fa53cd5544e8b8384affad4a6d2eb",
            "2b723e689a3845c6ba7cd70e8fbac61e",
            "dd5359b211914b2bb1cf18bb57fa8e5f",
            "c35c7ff1c64346ce97b909614c7131c6",
            "7ac344f11b1143c99154cdec88ed030a"
          ]
        },
        "id": "TOiqXhYIus4m",
        "outputId": "4d702192-8cd5-4419-abff-27c8c15c88eb"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "f46c31e05f2e438f9ab5cccb12f31c58",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/49.0 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "f4b3b22bb67049ee9b394b5057d3b87a",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "config.json:   0%|          | 0.00/570 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "91228710c0cd4f0ea7977cd5a40d1ba1",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "vocab.txt:   0%|          | 0.00/213k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "06738242f3f14c26bd4e209b131c8895",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "tokenizer.json:   0%|          | 0.00/436k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "1aa46824aea54eed9e11e8d539ecf43f",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/59.0 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "9f4f8fdededd40959f56f003ed08e473",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "config.json:   0%|          | 0.00/433 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "c22560089e74473798a947ffa18dfac7",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "vocab.txt: 0.00B [00:00, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "English: ['This', 'is', 'the', 'Hugging', 'Face', 'Course', '.']\n",
            "English: ['This', 'chapter', 'is', 'about', 'tokenization', '.']\n",
            "English: ['This', 'section', 'shows', 'several', 'tokenizer', 'algorithms', '.']\n",
            "English: ['Hopefully', ',', 'you', 'will', 'be', 'able', 'to', 'understand', 'how', 'they', 'are', 'trained', 'and', 'generate', 'tokens', '.']\n",
            "Italian: ['Questo', '√®', 'il', 'corso', 'di', 'Hugging', 'Face', '.']\n",
            "Italian: ['Questo', 'capitolo', 'riguarda', 'la', 'tokenizzazione', '.']\n",
            "Italian: ['Questa', 'sezione', 'mostra', 'diversi', 'algoritmi', 'di', 'tokenizzazione', '.']\n",
            "Italian: ['Speriamo', 'che', 'tu', 'sia', 'in', 'grado', 'di', 'capire', 'come', 'vengono', 'addestrati', 'e', 'generano', 'token', '.']\n",
            "\n",
            "English Word Frequency: defaultdict(<class 'int'>, {'This': 3, 'is': 2, 'the': 1, 'Hugging': 1, 'Face': 1, 'Course': 1, '.': 4, 'chapter': 1, 'about': 1, 'tokenization': 1, 'section': 1, 'shows': 1, 'several': 1, 'tokenizer': 1, 'algorithms': 1, 'Hopefully': 1, ',': 1, 'you': 1, 'will': 1, 'be': 1, 'able': 1, 'to': 1, 'understand': 1, 'how': 1, 'they': 1, 'are': 1, 'trained': 1, 'and': 1, 'generate': 1, 'tokens': 1})\n",
            "Italian Word Frequency: defaultdict(<class 'int'>, {'Questo': 2, '√®': 1, 'il': 1, 'corso': 1, 'di': 3, 'Hugging': 1, 'Face': 1, '.': 4, 'capitolo': 1, 'riguarda': 1, 'la': 1, 'tokenizzazione': 2, 'Questa': 1, 'sezione': 1, 'mostra': 1, 'diversi': 1, 'algoritmi': 1, 'Speriamo': 1, 'che': 1, 'tu': 1, 'sia': 1, 'in': 1, 'grado': 1, 'capire': 1, 'come': 1, 'vengono': 1, 'addestrati': 1, 'e': 1, 'generano': 1, 'token': 1})\n",
            "\n",
            "English vocab size: 28996\n",
            "Italian vocab size: 31102\n"
          ]
        }
      ],
      "source": [
        "eng_tokenizer = AutoTokenizer.from_pretrained(\"bert-base-cased\")  # English\n",
        "ita_tokenizer = AutoTokenizer.from_pretrained(\"dbmdz/bert-base-italian-cased\")  # Italian\n",
        "\n",
        "### Example bilingual corpus\n",
        "eng_corpus = [\n",
        "    \"This is the Hugging Face Course.\",\n",
        "    \"This chapter is about tokenization.\",\n",
        "    \"This section shows several tokenizer algorithms.\",\n",
        "    \"Hopefully, you will be able to understand how they are trained and generate tokens.\",\n",
        "]\n",
        "\n",
        "ita_corpus = [\n",
        "    \"Questo √® il corso di Hugging Face.\",\n",
        "    \"Questo capitolo riguarda la tokenizzazione.\",\n",
        "    \"Questa sezione mostra diversi algoritmi di tokenizzazione.\",\n",
        "    \"Speriamo che tu sia in grado di capire come vengono addestrati e generano token.\",\n",
        "]\n",
        "\n",
        "### Get frequency for English\n",
        "eng_word_freqs = defaultdict(int)\n",
        "for text in eng_corpus:\n",
        "    words_with_offsets = eng_tokenizer.backend_tokenizer.pre_tokenizer.pre_tokenize_str(text)\n",
        "    new_words = [word for word, offset in words_with_offsets]\n",
        "    print(f\"English: {new_words}\")\n",
        "    for word in new_words:\n",
        "        eng_word_freqs[word] += 1\n",
        "\n",
        "### Get frequency for Italian\n",
        "ita_word_freqs = defaultdict(int)\n",
        "for text in ita_corpus:\n",
        "    words_with_offsets = ita_tokenizer.backend_tokenizer.pre_tokenizer.pre_tokenize_str(text)\n",
        "    new_words = [word for word, offset in words_with_offsets]\n",
        "    print(f\"Italian: {new_words}\")\n",
        "    for word in new_words:\n",
        "        ita_word_freqs[word] += 1\n",
        "\n",
        "print(f\"\\nEnglish Word Frequency: {eng_word_freqs}\")\n",
        "print(f\"Italian Word Frequency: {ita_word_freqs}\")\n",
        "\n",
        "# Get vocabulary sizes for model initialization\n",
        "eng_vocab_size = eng_tokenizer.vocab_size\n",
        "ita_vocab_size = ita_tokenizer.vocab_size\n",
        "print(f\"\\nEnglish vocab size: {eng_vocab_size}\")\n",
        "print(f\"Italian vocab size: {ita_vocab_size}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "fbd93b11",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fbd93b11",
        "outputId": "5be361f8-9fa2-46b8-a24a-57dfd09dfc1e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "All alphabets: ['##a', '##c', '##d', '##e', '##g', '##h', '##i', '##k', '##l', '##m', '##n', '##o', '##p', '##r', '##s', '##t', '##u', '##v', '##z', '.', 'F', 'H', 'Q', 'S', 'a', 'c', 'd', 'e', 'g', 'i', 'l', 'm', 'r', 's', 't', 'v', '√®']\n",
            "\n",
            "Splitted Words: {'Questo': ['Q', '##u', '##e', '##s', '##t', '##o'], '√®': ['√®'], 'il': ['i', '##l'], 'corso': ['c', '##o', '##r', '##s', '##o'], 'di': ['d', '##i'], 'Hugging': ['H', '##u', '##g', '##g', '##i', '##n', '##g'], 'Face': ['F', '##a', '##c', '##e'], '.': ['.'], 'capitolo': ['c', '##a', '##p', '##i', '##t', '##o', '##l', '##o'], 'riguarda': ['r', '##i', '##g', '##u', '##a', '##r', '##d', '##a'], 'la': ['l', '##a'], 'tokenizzazione': ['t', '##o', '##k', '##e', '##n', '##i', '##z', '##z', '##a', '##z', '##i', '##o', '##n', '##e'], 'Questa': ['Q', '##u', '##e', '##s', '##t', '##a'], 'sezione': ['s', '##e', '##z', '##i', '##o', '##n', '##e'], 'mostra': ['m', '##o', '##s', '##t', '##r', '##a'], 'diversi': ['d', '##i', '##v', '##e', '##r', '##s', '##i'], 'algoritmi': ['a', '##l', '##g', '##o', '##r', '##i', '##t', '##m', '##i'], 'Speriamo': ['S', '##p', '##e', '##r', '##i', '##a', '##m', '##o'], 'che': ['c', '##h', '##e'], 'tu': ['t', '##u'], 'sia': ['s', '##i', '##a'], 'in': ['i', '##n'], 'grado': ['g', '##r', '##a', '##d', '##o'], 'capire': ['c', '##a', '##p', '##i', '##r', '##e'], 'come': ['c', '##o', '##m', '##e'], 'vengono': ['v', '##e', '##n', '##g', '##o', '##n', '##o'], 'addestrati': ['a', '##d', '##d', '##e', '##s', '##t', '##r', '##a', '##t', '##i'], 'e': ['e'], 'generano': ['g', '##e', '##n', '##e', '##r', '##a', '##n', '##o'], 'token': ['t', '##o', '##k', '##e', '##n']}\n"
          ]
        }
      ],
      "source": [
        "### split all word into alphabet\n",
        "alphabet = []\n",
        "for word in ita_word_freqs.keys():\n",
        "    if word[0] not in alphabet:\n",
        "        alphabet.append(word[0])\n",
        "    for letter in word[1:]:\n",
        "        if f\"##{letter}\" not in alphabet:\n",
        "            alphabet.append(f\"##{letter}\")\n",
        "\n",
        "alphabet.sort()\n",
        "print(f'All alphabets: {alphabet}')\n",
        "\n",
        "### insert special token and subword\n",
        "vocab = [\"[PAD]\", \"[UNK]\", \"[CLS]\", \"[SEP]\", \"[MASK]\"] + alphabet.copy()\n",
        "splits = {word: [c if i == 0 else f\"##{c}\" for i, c in enumerate(word)] for word in ita_word_freqs.keys()}\n",
        "print(f'\\nSplitted Words: {splits}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "75de80da",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "75de80da",
        "outputId": "89d42ad7-832e-48f6-8ff6-3edf39128ffd"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Scores for each Pair: {('Q', '##u'): 0.16666666666666666, ('##u', '##e'): 0.025, ('##e', '##s'): 0.02857142857142857, ('##s', '##t'): 0.08928571428571429, ('##t', '##o'): 0.01875, ('i', '##l'): 0.16666666666666666, ('c', '##o'): 0.02, ('##o', '##r'): 0.01, ('##r', '##s'): 0.02857142857142857, ('##s', '##o'): 0.007142857142857143, ('d', '##i'): 0.05263157894736842, ('H', '##u'): 0.16666666666666666, ('##u', '##g'): 0.027777777777777776, ('##g', '##g'): 0.027777777777777776, ('##g', '##i'): 0.008771929824561403, ('##i', '##n'): 0.0043859649122807015, ('##n', '##g'): 0.027777777777777776, ('F', '##a'): 0.06666666666666667, ('##a', '##c'): 0.06666666666666667, ('##c', '##e'): 0.05, ('c', '##a'): 0.02666666666666667, ('##a', '##p'): 0.044444444444444446, ('##p', '##i'): 0.03508771929824561, ('##i', '##t'): 0.013157894736842105, ('##o', '##l'): 0.016666666666666666, ('##l', '##o'): 0.016666666666666666, ('r', '##i'): 0.05263157894736842, ('##i', '##g'): 0.008771929824561403, ('##g', '##u'): 0.027777777777777776, ('##u', '##a'): 0.011111111111111112, ('##a', '##r'): 0.006666666666666667, ('##r', '##d'): 0.025, ('##d', '##a'): 0.016666666666666666, ('l', '##a'): 0.06666666666666667, ('t', '##o'): 0.0375, ('##o', '##k'): 0.05, ('##k', '##e'): 0.05, ('##e', '##n'): 0.020833333333333332, ('##n', '##i'): 0.008771929824561403, ('##i', '##z'): 0.015037593984962405, ('##z', '##z'): 0.04081632653061224, ('##z', '##a'): 0.01904761904761905, ('##a', '##z'): 0.01904761904761905, ('##z', '##i'): 0.022556390977443608, ('##i', '##o'): 0.007894736842105263, ('##o', '##n'): 0.016666666666666666, ('##n', '##e'): 0.016666666666666666, ('##t', '##a'): 0.008333333333333333, ('s', '##e'): 0.025, ('##e', '##z'): 0.007142857142857143, ('m', '##o'): 0.05, ('##o', '##s'): 0.007142857142857143, ('##t', '##r'): 0.025, ('##r', '##a'): 0.02666666666666667, ('##i', '##v'): 0.05263157894736842, ('##v', '##e'): 0.05, ('##e', '##r'): 0.015, ('##s', '##i'): 0.007518796992481203, ('a', '##l'): 0.16666666666666666, ('##l', '##g'): 0.05555555555555555, ('##g', '##o'): 0.016666666666666666, ('##r', '##i'): 0.010526315789473684, ('##t', '##m'): 0.041666666666666664, ('##m', '##i'): 0.017543859649122806, ('S', '##p'): 0.3333333333333333, ('##p', '##e'): 0.016666666666666666, ('##i', '##a'): 0.007017543859649123, ('##a', '##m'): 0.022222222222222223, ('##m', '##o'): 0.016666666666666666, ('c', '##h'): 0.2, ('##h', '##e'): 0.05, ('t', '##u'): 0.041666666666666664, ('s', '##i'): 0.02631578947368421, ('i', '##n'): 0.041666666666666664, ('g', '##r'): 0.05, ('##a', '##d'): 0.016666666666666666, ('##d', '##o'): 0.0125, ('##i', '##r'): 0.005263157894736842, ('##r', '##e'): 0.005, ('##o', '##m'): 0.016666666666666666, ('##m', '##e'): 0.016666666666666666, ('v', '##e'): 0.05, ('##n', '##o'): 0.008333333333333333, ('a', '##d'): 0.125, ('##d', '##d'): 0.0625, ('##d', '##e'): 0.0125, ('##a', '##t'): 0.008333333333333333, ('##t', '##i'): 0.006578947368421052, ('g', '##e'): 0.025, ('##a', '##n'): 0.005555555555555556}\n"
          ]
        }
      ],
      "source": [
        " ### compute score for merging\n",
        "\n",
        "def compute_pair_scores(splits):\n",
        "    letter_freqs = defaultdict(int)\n",
        "    pair_freqs = defaultdict(int)\n",
        "\n",
        "    for word, freq in ita_word_freqs.items():\n",
        "        split = splits[word]\n",
        "        if len(split) == 1:\n",
        "            letter_freqs[split[0]] += freq\n",
        "            continue\n",
        "        for i in range(len(split) - 1):\n",
        "            pair = (split[i], split[i + 1])\n",
        "            letter_freqs[split[i]] += freq\n",
        "            pair_freqs[pair] += freq\n",
        "        letter_freqs[split[-1]] += freq\n",
        "\n",
        "    scores = {\n",
        "        pair: freq / (letter_freqs[pair[0]] * letter_freqs[pair[1]])\n",
        "        for pair, freq in pair_freqs.items()\n",
        "    }\n",
        "    return scores\n",
        "\n",
        "pair_scores = compute_pair_scores(splits)\n",
        "print(f'Scores for each Pair: {pair_scores}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "6adc0481",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6adc0481",
        "outputId": "ca16eb88-d3b6-4531-fa1f-37a378ddf0a9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "('S', '##p') 0.3333333333333333\n",
            "['Qu', '##e', '##s', '##t', '##o']\n"
          ]
        }
      ],
      "source": [
        "### finding pair with best score\n",
        "\n",
        "best_pair = \"\"\n",
        "max_score = None\n",
        "for pair, score in pair_scores.items():\n",
        "    if max_score is None or max_score < score:\n",
        "        best_pair = pair\n",
        "        max_score = score\n",
        "\n",
        "print(best_pair, max_score)\n",
        "vocab.append(\"ab\")\n",
        "\n",
        "### merge pair ###\n",
        "def merge_pair(a, b, splits):\n",
        "    for word in ita_word_freqs:\n",
        "        split = splits[word]\n",
        "        if len(split) == 1:\n",
        "            continue\n",
        "        i = 0\n",
        "        while i < len(split) - 1:\n",
        "            if split[i] == a and split[i + 1] == b:\n",
        "                merge = a + b[2:] if b.startswith(\"##\") else a + b\n",
        "                split = split[:i] + [merge] + split[i + 2 :]\n",
        "            else:\n",
        "                i += 1\n",
        "        splits[word] = split\n",
        "    return splits\n",
        "\n",
        "splits = merge_pair(\"Q\", \"##u\", splits)\n",
        "print(splits[\"Questo\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "7943860a",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7943860a",
        "outputId": "26499fdb-bbf1-4ede-c8fe-811ec36ccbfb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Final Vocab: ['[PAD]', '[UNK]', '[CLS]', '[SEP]', '[MASK]', '##a', '##c', '##d', '##e', '##g', '##h', '##i', '##k', '##l', '##m', '##n', '##o', '##p', '##r', '##s', '##t', '##u', '##v', '##z', '.', 'F', 'H', 'Q', 'S', 'a', 'c', 'd', 'e', 'g', 'i', 'l', 'm', 'r', 's', 't', 'v', '√®', 'ab', 'Hu', 'Sp', 'ch', 'il', 'al', 'ad', 'add', 'Hug', 'Hugg', 'alg', '##gu', 'tu', '##st', '##tm', '##rs', '##ng', 'in', 'Fa', 'Fac', '##ap', 'cap', '##gua', '##guar', '##guard', '##guarda', 'la', '##ad']\n"
          ]
        }
      ],
      "source": [
        "### keep looping to merge more pair\n",
        "\n",
        "vocab_size = 70\n",
        "while len(vocab) < vocab_size:\n",
        "    scores = compute_pair_scores(splits)\n",
        "    best_pair, max_score = \"\", None\n",
        "    for pair, score in scores.items():\n",
        "        if max_score is None or max_score < score:\n",
        "            best_pair = pair\n",
        "            max_score = score\n",
        "    splits = merge_pair(*best_pair, splits)\n",
        "    new_token = (\n",
        "        best_pair[0] + best_pair[1][2:]\n",
        "        if best_pair[1].startswith(\"##\")\n",
        "        else best_pair[0] + best_pair[1]\n",
        "    )\n",
        "    vocab.append(new_token)\n",
        "\n",
        "print(f'Final Vocab: {vocab}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "1afe6c8b",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1afe6c8b",
        "outputId": "e2d07371-a7f3-41f7-8864-707d800f9ff7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['Q', '##u', '##e', '##st', '##o']\n",
            "['Q', '##a', '##e', '##st', '##o']\n"
          ]
        }
      ],
      "source": [
        "### encode a word ###\n",
        "def encode_word(word):\n",
        "    tokens = []\n",
        "    while len(word) > 0:\n",
        "        i = len(word)\n",
        "        while i > 0 and word[:i] not in vocab:\n",
        "            i -= 1\n",
        "        if i == 0:\n",
        "            return [\"[UNK]\"]\n",
        "        tokens.append(word[:i])\n",
        "        word = word[i:]\n",
        "        if len(word) > 0:\n",
        "            word = f\"##{word}\"\n",
        "    return tokens\n",
        "\n",
        "print(encode_word(\"Questo\"))\n",
        "# This one should be unknown (within this corpus)\n",
        "print(encode_word(\"Qaesto\"))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "jeHBuC79RMHm",
      "metadata": {
        "id": "jeHBuC79RMHm"
      },
      "source": [
        "## BERTDataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "id": "VCCMqd7JRKf6",
      "metadata": {
        "id": "VCCMqd7JRKf6"
      },
      "outputs": [],
      "source": [
        "class BERTDataset(Dataset):\n",
        "    def __init__(self, data_pair, tokenizer, seq_len=64):\n",
        "\n",
        "        self.tokenizer = tokenizer\n",
        "        self.seq_len = seq_len\n",
        "        self.corpus_lines = len(data_pair)\n",
        "        self.lines = data_pair\n",
        "\n",
        "    def __len__(self):\n",
        "        return self.corpus_lines\n",
        "\n",
        "    def __getitem__(self, item):\n",
        "\n",
        "        # Step 1: get random sentence pair, either negative or positive (saved as is_next_label)\n",
        "        t1, t2, is_next_label = self.get_sent(item)\n",
        "\n",
        "        # Step 2: replace random words in sentence with mask / random words\n",
        "        t1_random, t1_label = self.random_word(t1)\n",
        "        t2_random, t2_label = self.random_word(t2)\n",
        "\n",
        "        # Step 3: Adding CLS and SEP tokens to the start and end of sentences\n",
        "        # Adding PAD token for labels\n",
        "        t1 = [self.tokenizer.vocab['[CLS]']] + t1_random + [self.tokenizer.vocab['[SEP]']]\n",
        "        t2 = t2_random + [self.tokenizer.vocab['[SEP]']]\n",
        "        t1_label = [self.tokenizer.vocab['[PAD]']] + t1_label + [self.tokenizer.vocab['[PAD]']]\n",
        "        t2_label = t2_label + [self.tokenizer.vocab['[PAD]']]\n",
        "\n",
        "        # Step 4: combine sentence 1 and 2 as one input\n",
        "        # adding PAD tokens to make the sentence same length as seq_len\n",
        "        segment_label = ([1 for _ in range(len(t1))] + [2 for _ in range(len(t2))])[:self.seq_len]\n",
        "        bert_input = (t1 + t2)[:self.seq_len]\n",
        "        bert_label = (t1_label + t2_label)[:self.seq_len]\n",
        "        padding = [self.tokenizer.vocab['[PAD]'] for _ in range(self.seq_len - len(bert_input))]\n",
        "        bert_input.extend(padding), bert_label.extend(padding), segment_label.extend(padding)\n",
        "\n",
        "        output = {\"bert_input\": bert_input,\n",
        "                  \"bert_label\": bert_label,\n",
        "                  \"segment_label\": segment_label,\n",
        "                  \"is_next\": is_next_label}\n",
        "\n",
        "        return {key: torch.tensor(value) for key, value in output.items()}\n",
        "\n",
        "    def random_word(self, sentence):\n",
        "        tokens = sentence.split()\n",
        "        output_label = []\n",
        "        output = []\n",
        "\n",
        "        # 15% of the tokens would be replaced\n",
        "        for i, token in enumerate(tokens):\n",
        "            prob = random.random()\n",
        "\n",
        "            # remove cls and sep token\n",
        "            token_id = self.tokenizer(token)['input_ids'][1:-1]\n",
        "\n",
        "            # 15% chance of altering token\n",
        "            if prob < 0.15:\n",
        "                prob /= 0.15\n",
        "\n",
        "                # 80% chance change token to mask token\n",
        "                if prob < 0.8:\n",
        "                    for i in range(len(token_id)):\n",
        "                        output.append(self.tokenizer.vocab['[MASK]'])\n",
        "\n",
        "                # 10% chance change token to random token\n",
        "                elif prob < 0.9:\n",
        "                    for i in range(len(token_id)):\n",
        "                        output.append(random.randrange(len(self.tokenizer.vocab)))\n",
        "\n",
        "                # 10% chance change token to current token\n",
        "                else:\n",
        "                    output.append(token_id)\n",
        "\n",
        "                output_label.append(token_id)\n",
        "\n",
        "            else:\n",
        "                output.append(token_id)\n",
        "                for i in range(len(token_id)):\n",
        "                    output_label.append(0)\n",
        "\n",
        "        # flattening\n",
        "        output = list(itertools.chain(*[[x] if not isinstance(x, list) else x for x in output]))\n",
        "        output_label = list(itertools.chain(*[[x] if not isinstance(x, list) else x for x in output_label]))\n",
        "        assert len(output) == len(output_label)\n",
        "        return output, output_label\n",
        "\n",
        "    def get_sent(self, index):\n",
        "        '''return random sentence pair'''\n",
        "        t1, t2 = self.get_corpus_line(index)\n",
        "\n",
        "        # negative or positive pair, for next sentence prediction\n",
        "        if random.random() > 0.5:\n",
        "            return t1, t2, 1\n",
        "        else:\n",
        "            return t1, self.get_random_line(), 0\n",
        "\n",
        "    def get_corpus_line(self, item):\n",
        "        '''return sentence pair'''\n",
        "        return self.lines[item][0], self.lines[item][1]\n",
        "\n",
        "    def get_random_line(self):\n",
        "        '''return random single sentence'''\n",
        "        return self.lines[random.randrange(len(self.lines))][1]"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "baf44a70",
      "metadata": {
        "id": "baf44a70"
      },
      "source": [
        "# Task\n",
        "Create a translation model using `BertTranslationModel` based on loaded text data. The model should translate from English to Italian. Outline the steps for Tokenization, Word Embedding, and training."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "510b5e99",
      "metadata": {
        "id": "510b5e99"
      },
      "source": [
        "## Prepare Dataset\n",
        "\n",
        "### BertDataset\n",
        "- Tokenization\n",
        "- Padding\n",
        "- Convert Tensor\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "id": "87909343",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "87909343",
        "outputId": "071a06bb-0185-4f59-b2a9-f2971cda00ce"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Total pairs: 333112\n",
            "Training pairs: 266489\n",
            "Validation pairs: 66623\n"
          ]
        }
      ],
      "source": [
        "eng_sentences = []\n",
        "with open(\"text-eng.txt\", \"r\") as f:\n",
        "    for line in f:\n",
        "        line = line.strip().replace('<sos>', '').replace('<eos>', '').strip()\n",
        "        if line:\n",
        "            eng_sentences.append(line)\n",
        "\n",
        "ita_sentences = []\n",
        "with open(\"text-ita.txt\", \"r\") as f:\n",
        "    for line in f:\n",
        "        line = line.strip().replace('<sos>', '').replace('<eos>', '').strip()\n",
        "        if line:\n",
        "            ita_sentences.append(line)\n",
        "\n",
        "data_pair = list(zip(eng_sentences, ita_sentences))\n",
        "\n",
        "# Split data into training and validation sets\n",
        "# Using a simple split for now, can use train_test_split later if needed\n",
        "train_size = int(0.8 * len(data_pair))\n",
        "train_data = data_pair[:train_size]\n",
        "val_data = data_pair[train_size:]\n",
        "\n",
        "print(f\"Total pairs: {len(data_pair)}\")\n",
        "print(f\"Training pairs: {len(train_data)}\")\n",
        "print(f\"Validation pairs: {len(val_data)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "id": "ec81bb96",
      "metadata": {
        "id": "ec81bb96"
      },
      "outputs": [],
      "source": [
        "class TranslationDataset(Dataset):\n",
        "    def __init__(self, data_pair, eng_tokenizer, ita_tokenizer, seq_len=64):\n",
        "        self.data_pair = data_pair\n",
        "        self.eng_tokenizer = eng_tokenizer\n",
        "        self.ita_tokenizer = ita_tokenizer\n",
        "        self.seq_len = seq_len\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data_pair)\n",
        "\n",
        "    def __getitem__(self, item):\n",
        "        eng_sentence, ita_sentence = self.data_pair[item]\n",
        "\n",
        "        # Tokenize English sentence\n",
        "        eng_tokens = self.eng_tokenizer(\n",
        "            eng_sentence,\n",
        "            padding='max_length',\n",
        "            truncation=True,\n",
        "            max_length=self.seq_len,\n",
        "            return_attention_mask=True,\n",
        "            return_token_type_ids=True,\n",
        "            return_tensors='pt'\n",
        "        )\n",
        "\n",
        "        # Tokenize Italian sentence for decoder input and target\n",
        "        # Need to add [CLS] and [SEP] for decoder input, and [SEP] for target\n",
        "        # The target is the input shifted by one token, effectively predicting the next token\n",
        "        ita_input_tokens = self.ita_tokenizer(\n",
        "            ita_sentence,\n",
        "            padding='max_length',\n",
        "            truncation=True,\n",
        "            max_length=self.seq_len,\n",
        "            return_attention_mask=True, # This mask is for cross-attention from encoder\n",
        "            return_token_type_ids=True,\n",
        "            return_tensors='pt'\n",
        "        )\n",
        "\n",
        "        # Create decoder input by adding [CLS] and shifting\n",
        "        ita_input_ids = ita_input_tokens['input_ids'].squeeze(0)\n",
        "        ita_attention_mask = ita_input_tokens['attention_mask'].squeeze(0)\n",
        "        ita_token_type_ids = ita_input_tokens['token_type_ids'].squeeze(0)\n",
        "\n",
        "        # Create the causal mask for the decoder self-attention\n",
        "        # This ensures the decoder at a given position only attends to previous positions\n",
        "        seq_len = ita_input_ids.size(0)\n",
        "        casual_mask = torch.triu(torch.ones(seq_len, seq_len), diagonal=1).bool()\n",
        "        casual_mask = casual_mask.masked_fill(casual_mask, float('-inf'))\n",
        "        casual_mask = casual_mask.masked_fill(~casual_mask, 0.0)\n",
        "\n",
        "\n",
        "        # Create the target labels for Italian (shifted input)\n",
        "        # The target is the input sequence shifted by one position, with the first token ([CLS]) removed.\n",
        "        # The padding token at the end of the input sequence will correspond to the last real token in the target.\n",
        "        ita_target_ids = ita_input_ids.clone()\n",
        "        # Shift target sequence by one position\n",
        "        ita_target_ids = torch.cat([ita_target_ids[1:], torch.tensor([self.ita_tokenizer.pad_token_id])])\n",
        "\n",
        "        output = {\n",
        "            \"eng_ids\": eng_tokens['input_ids'].squeeze(0),\n",
        "            \"eng_mask\": eng_tokens['attention_mask'].squeeze(0),\n",
        "            \"eng_token_type_ids\": eng_tokens['token_type_ids'].squeeze(0),\n",
        "            \"ita_ids\": ita_input_ids,\n",
        "            \"ita_mask\": ita_attention_mask, # This will be used for cross attention.\n",
        "            \"ita_token_type_ids\": ita_token_type_ids,\n",
        "            \"ita_casual_mask\": casual_mask, # This will be used for self attention in decoder.\n",
        "            \"ita_target_ids\": ita_target_ids,\n",
        "        }\n",
        "\n",
        "        return output\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ad36cc19",
      "metadata": {
        "id": "ad36cc19"
      },
      "source": [
        "**Reasoning**:\n",
        "Create Dataset objects for the training and validation sets using the defined `TranslationDataset` class and then create DataLoaders for both datasets to handle batching and shuffling during training and evaluation.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "id": "2ddad872",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2ddad872",
        "outputId": "ca4a97c2-99cd-41b1-f73d-e30e4b1ef446"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Number of batches in training DataLoader: 8328\n",
            "Number of batches in validation DataLoader: 2082\n"
          ]
        }
      ],
      "source": [
        "train_dataset = TranslationDataset(train_data, eng_tokenizer, ita_tokenizer, seq_len=MAXLEN)\n",
        "val_dataset = TranslationDataset(val_data, eng_tokenizer, ita_tokenizer, seq_len=MAXLEN)\n",
        "\n",
        "BATCH_SIZE = 32\n",
        "\n",
        "train_dataloader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
        "val_dataloader = DataLoader(val_dataset, batch_size=BATCH_SIZE)\n",
        "\n",
        "print(f\"Number of batches in training DataLoader: {len(train_dataloader)}\")\n",
        "print(f\"Number of batches in validation DataLoader: {len(val_dataloader)}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a0a7819a",
      "metadata": {
        "id": "a0a7819a"
      },
      "source": [
        "## Definition of Model\n",
        "\n",
        "### Subtask:\n",
        "`BertTranslationModel` is instanced here.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d1ff30a3",
      "metadata": {
        "id": "d1ff30a3"
      },
      "source": [
        "**Reasoning**:\n",
        "BertTranslationModel „ÇØ„É©„Çπ„ÇíÈÅ©Âàá„Å™ÂºïÊï∞„Åß„Ç§„É≥„Çπ„Çø„É≥„ÇπÂåñ„Åó„ÄÅ„Åù„ÅÆÊßãÈÄ†„ÇíÁ¢∫Ë™ç„Åó„Åæ„Åô„ÄÇ\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "id": "f8232374",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f8232374",
        "outputId": "6455d8e0-b150-4792-99b2-6b61e3bc64e1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "BertTranslationModel(\n",
            "  (encoder): Bert(\n",
            "    (embedding): BertEmbeddings(\n",
            "      (token): Embedding(28996, 768, padding_idx=0)\n",
            "      (position): Embedding(20, 768)\n",
            "      (segment): Embedding(2, 768)\n",
            "      (layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "      (dropout): Dropout(p=0.1, inplace=False)\n",
            "    )\n",
            "    (encoder_blocks): ModuleList(\n",
            "      (0-5): 6 x EncoderBlock(\n",
            "        (attention): MultiHeadAttention(\n",
            "          (dropout): Dropout(p=0.1, inplace=False)\n",
            "          (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "          (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "          (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "          (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
            "        )\n",
            "        (ffn): PositionwiseFeedForward(\n",
            "          (linear1): Linear(in_features=768, out_features=3072, bias=True)\n",
            "          (linear2): Linear(in_features=3072, out_features=768, bias=True)\n",
            "          (dropout): Dropout(p=0.1, inplace=False)\n",
            "          (gelu): GELU(approximate='none')\n",
            "        )\n",
            "        (layer_norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
            "        (layer_norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
            "        (dropout): Dropout(p=0.1, inplace=False)\n",
            "      )\n",
            "    )\n",
            "  )\n",
            "  (decoder_embeddings): BertEmbeddings(\n",
            "    (token): Embedding(31102, 768, padding_idx=0)\n",
            "    (position): Embedding(20, 768)\n",
            "    (segment): Embedding(2, 768)\n",
            "    (layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "    (dropout): Dropout(p=0.1, inplace=False)\n",
            "  )\n",
            "  (decoder_blocks): ModuleList(\n",
            "    (0-5): 6 x DecoderBlock(\n",
            "      (self_attention): MultiHeadAttention(\n",
            "        (dropout): Dropout(p=0.1, inplace=False)\n",
            "        (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
            "      )\n",
            "      (cross_attention): CrossAttention(\n",
            "        (dropout): Dropout(p=0.1, inplace=False)\n",
            "        (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
            "      )\n",
            "      (ffn): PositionwiseFeedForward(\n",
            "        (linear1): Linear(in_features=768, out_features=3072, bias=True)\n",
            "        (linear2): Linear(in_features=3072, out_features=768, bias=True)\n",
            "        (dropout): Dropout(p=0.1, inplace=False)\n",
            "        (gelu): GELU(approximate='none')\n",
            "      )\n",
            "      (layer_norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
            "      (layer_norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
            "      (layer_norm3): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
            "      (dropout): Dropout(p=0.1, inplace=False)\n",
            "    )\n",
            "  )\n",
            "  (output_proj): Linear(in_features=768, out_features=31102, bias=True)\n",
            ")\n"
          ]
        }
      ],
      "source": [
        "model = BertTranslationModel(\n",
        "    ita_vocab_size=ita_tokenizer.vocab_size,\n",
        "    eng_vocab_size=eng_tokenizer.vocab_size,\n",
        "    max_seq_len=MAXLEN,\n",
        "    d_model=768, # ‰ΩøÁî®„Åô„ÇãBERT„É¢„Éá„É´„ÅÆ‰∏ÄËà¨ÁöÑ„Å™Ê¨°ÂÖÉ\n",
        "    num_layers=6, # „É¨„Ç§„É§„ÉºÊï∞„ÅØÈÅ©ÂÆúË®≠ÂÆö\n",
        "    num_heads=12, # „Éò„ÉÉ„ÉâÊï∞„ÅØÈÅ©ÂÆúË®≠ÂÆö (d_model„ÅßÂâ≤„ÇäÂàá„Çå„Çã„Çà„ÅÜ„Å´)\n",
        "    dropout=0.1\n",
        ")\n",
        "\n",
        "print(model)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4749b305",
      "metadata": {
        "id": "4749b305"
      },
      "source": [
        "## Lossfunction and Optimizer\n",
        "\n",
        "### Subtask:\n",
        "ÁøªË®≥„Çø„Çπ„ÇØ„Å´ÈÅ©„Åó„ÅüÊêçÂ§±Èñ¢Êï∞Ôºà‰æã: `CrossEntropyLoss`Ôºâ„Å®„Ç™„Éó„ÉÜ„Ç£„Éû„Ç§„Ç∂Ôºà‰æã: `Adam`Ôºâ„ÇíÂÆöÁæ©„Åó„Åæ„Åô„ÄÇ\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "id": "107bb02a",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "107bb02a",
        "outputId": "288d2529-72f9-4b42-c917-e7ade03c2f9c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loss function (criterion): CrossEntropyLoss()\n",
            "Optimizer: Adam (\n",
            "Parameter Group 0\n",
            "    amsgrad: False\n",
            "    betas: (0.9, 0.999)\n",
            "    capturable: False\n",
            "    differentiable: False\n",
            "    eps: 1e-08\n",
            "    foreach: None\n",
            "    fused: None\n",
            "    lr: 0.0001\n",
            "    maximize: False\n",
            "    weight_decay: 0\n",
            ")\n"
          ]
        }
      ],
      "source": [
        "criterion = nn.CrossEntropyLoss(ignore_index=ita_tokenizer.pad_token_id)\n",
        "optimizer = Adam(model.parameters(), lr=1e-4)\n",
        "\n",
        "print(\"Loss function (criterion):\", criterion)\n",
        "print(\"Optimizer:\", optimizer)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "02fbb8a9",
      "metadata": {
        "id": "02fbb8a9"
      },
      "source": [
        "## Ë®ìÁ∑¥„É´„Éº„Éó„ÅÆÂÆüË£Ö\n",
        "\n",
        "### Subtask:\n",
        "„É¢„Éá„É´„ÇíË®ìÁ∑¥„Åô„Çã„Åü„ÇÅ„ÅÆ„É´„Éº„Éó„Çí‰ΩúÊàê„Åó„Åæ„Åô„ÄÇ„Åì„Çå„Å´„ÅØ„ÄÅ„Éá„Éº„Çø„ÅÆ„Éê„ÉÉ„ÉÅÂá¶ÁêÜ„ÄÅ„É¢„Éá„É´„ÅÆ„Éï„Ç©„ÉØ„Éº„Éâ„Éë„Çπ„ÄÅÊêçÂ§±„ÅÆË®àÁÆó„ÄÅ„Éê„ÉÉ„ÇØ„Éó„É≠„Éë„Ç≤„Éº„Ç∑„Éß„É≥„ÄÅ„Éë„É©„É°„Éº„Çø„ÅÆÊõ¥Êñ∞„Å™„Å©„ÅåÂê´„Åæ„Çå„Åæ„Åô„ÄÇ\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1c57b767",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 435
        },
        "id": "1c57b767",
        "outputId": "13fb33a4-fb47-4642-e739-c23a3e684331"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Using device: cpu\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 1:   0%|          | 11/8328 [03:29<43:58:25, 19.03s/it, loss=6.85]\n"
          ]
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-18-44033823.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     59\u001b[0m         \u001b[0;31m# Pass appropriate masks to the model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m         \u001b[0;31m# The model expects eng_mask to be the cross-attention mask and ita_mask to be the self-attention mask for the decoder\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 61\u001b[0;31m         logits = model(\n\u001b[0m\u001b[1;32m     62\u001b[0m             \u001b[0meng_ids\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0meng_ids\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m             \u001b[0mita_ids\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mita_ids\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1737\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1739\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1740\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1741\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1748\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1749\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1750\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1751\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1752\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tmp/ipython-input-3-695386054.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, eng_ids, ita_ids, eng_mask, ita_mask, eng_token_type_ids, ita_token_type_ids)\u001b[0m\n\u001b[1;32m    155\u001b[0m                 ita_token_type_ids=None):\n\u001b[1;32m    156\u001b[0m         \u001b[0;31m# understand english\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 157\u001b[0;31m         \u001b[0mencoder_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_ids\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0meng_ids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattention_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0meng_mask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtoken_type_ids\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0meng_token_type_ids\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    158\u001b[0m         \u001b[0;31m# produce Italian\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    159\u001b[0m         \u001b[0mdecoder_input\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecoder_embeddings\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_ids\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mita_ids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtoken_type_ids\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mita_token_type_ids\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1737\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1739\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1740\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1741\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1748\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1749\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1750\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1751\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1752\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tmp/ipython-input-2-3501824663.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, attention_mask, token_type_ids)\u001b[0m\n\u001b[1;32m    212\u001b[0m         \u001b[0;31m# running over multiple transformer blocks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    213\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mencoder\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoder_blocks\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 214\u001b[0;31m             \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mencoder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mextended_attention_mask\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# ‰øÆÊ≠£Âæå„ÅÆMultiHeadAttention„ÅØÂä†ÁÆó„Éû„Çπ„ÇØ„ÇíÊúüÂæÖ\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    215\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tmp/ipython-input-2-3501824663.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x, mask)\u001b[0m\n\u001b[1;32m    117\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayer_norm2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    118\u001b[0m         \u001b[0;31m#print(\"calculating layer norm...\",x.shape)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 119\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdropout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mffn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    120\u001b[0m         \u001b[0;31m#print(\"calculating ffn...\",x.shape)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    121\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mresidual\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1737\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1739\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1740\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1741\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1748\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1749\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1750\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1751\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1752\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tmp/ipython-input-2-3501824663.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     79\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     80\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 81\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     82\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     83\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdropout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1737\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1739\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1740\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1741\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1748\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1749\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1750\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1751\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1752\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/linear.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    123\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    124\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 125\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    126\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    127\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mextra_repr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(f\"Using device: {device}\")\n",
        "model.to(device)\n",
        "\n",
        "EPOCHS = 5 # Define the number of training epochs\n",
        "\n",
        "for epoch in range(EPOCHS):\n",
        "    model.train()\n",
        "    total_loss = 0\n",
        "    train_iterator = tqdm.tqdm(train_dataloader, desc=f\"Epoch {epoch+1}\")\n",
        "\n",
        "    for i, batch in enumerate(train_iterator):\n",
        "        # Move batch to device\n",
        "        eng_ids = batch['eng_ids'].to(device)\n",
        "        eng_mask = batch['eng_mask'].to(device)\n",
        "        eng_token_type_ids = batch['eng_token_type_ids'].to(device)\n",
        "        ita_ids = batch['ita_ids'].to(device)\n",
        "        # ita_mask from dataset is for cross-attention, shape (batch_size, seq_len)\n",
        "        ita_mask = batch['ita_mask'].to(device)\n",
        "        ita_target_ids = batch['ita_target_ids'].to(device)\n",
        "        ita_token_type_ids = batch['ita_token_type_ids'].to(device)\n",
        "        # ita_casual_mask from dataset is for self-attention, shape (seq_len, seq_len)\n",
        "        ita_casual_mask = batch['ita_casual_mask'].to(device)\n",
        "\n",
        "\n",
        "        # Prepare masks for the model forward pass\n",
        "        # Eng mask for encoder self-attention and decoder cross-attention\n",
        "        # Needs to be broadcastable to (batch, num_heads, q_len/seq_len, kv_len/seq_len)\n",
        "        batch_size, ita_seq_len = ita_ids.shape\n",
        "        _, eng_seq_len = eng_ids.shape\n",
        "        num_heads = model.decoder_blocks[0].cross_attention.num_heads # Assuming same number of heads for self and cross attention\n",
        "\n",
        "        # Eng mask for encoder self-attention\n",
        "        # Reshape to (batch, 1, 1, eng_seq_len) for broadcasting\n",
        "        eng_encoder_mask = eng_mask.unsqueeze(1).unsqueeze(2)\n",
        "        # Convert to additive mask format (0.0 and -1e9)\n",
        "        eng_encoder_mask = (1.0 - eng_encoder_mask.float()) * -1e9 # Ensure float for calculation\n",
        "\n",
        "\n",
        "        # Eng mask for decoder cross-attention\n",
        "        # Needs shape (batch, num_heads, ita_seq_len, eng_seq_len) for addition\n",
        "        # Start with (batch, 1, 1, eng_seq_len) and expand\n",
        "        eng_cross_mask = eng_mask.unsqueeze(1).unsqueeze(2)\n",
        "        eng_cross_mask = eng_cross_mask.expand(batch_size, num_heads, ita_seq_len, eng_seq_len)\n",
        "        # Convert to additive mask format (0.0 and -1e9)\n",
        "        eng_cross_mask = (1.0 - eng_cross_mask.float()) * -1e9 # Ensure float for calculation\n",
        "\n",
        "\n",
        "        # Ita causal mask for decoder self-attention\n",
        "        # Dataset provides (seq_len, seq_len) mask. After DataLoader, it's (batch_size, seq_len, seq_len).\n",
        "        # Needs shape (batch_size, num_heads, seq_len, seq_len) for addition.\n",
        "        # Add head dimension and expand.\n",
        "        ita_casual_mask = ita_casual_mask.unsqueeze(1) # shape (batch_size, 1, seq_len, seq_len)\n",
        "        ita_casual_mask = ita_casual_mask.expand(batch_size, num_heads, ita_seq_len, ita_seq_len)\n",
        "        # The mask from dataset is already in additive format (-inf and 0.0)\n",
        "\n",
        "\n",
        "        # Forward pass\n",
        "        # Pass appropriate masks to the model\n",
        "        # The model expects eng_mask to be the cross-attention mask and ita_mask to be the self-attention mask for the decoder\n",
        "        logits = model(\n",
        "            eng_ids=eng_ids,\n",
        "            ita_ids=ita_ids,\n",
        "            eng_mask=eng_cross_mask, # Use eng_cross_mask for cross-attention in the model\n",
        "            ita_mask=ita_casual_mask, # Use ita_casual_mask for self-attention in the model\n",
        "            eng_token_type_ids=eng_token_type_ids,\n",
        "            ita_token_type_ids=ita_token_type_ids\n",
        "            )\n",
        "\n",
        "        # Calculate loss, ignoring padding tokens\n",
        "        # Reshape logits and target for CrossEntropyLoss\n",
        "        loss = criterion(logits.view(-1, logits.size(-1)), ita_target_ids.view(-1))\n",
        "\n",
        "        # Backpropagation\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        total_loss += loss.item()\n",
        "        train_iterator.set_postfix({'loss': loss.item()})\n",
        "\n",
        "    avg_train_loss = total_loss / len(train_dataloader)\n",
        "    print(f\"Epoch {epoch+1} finished. Average training loss: {avg_train_loss:.4f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b1391fe7",
      "metadata": {
        "id": "b1391fe7"
      },
      "source": [
        "Save the state dictionary of the trained model to a file so it can be loaded later for inference or further training."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f0898e35",
      "metadata": {
        "id": "f0898e35"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "import os\n",
        "\n",
        "# Mount Google Drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Define the path to save the model in Google Drive\n",
        "# You might want to create a specific folder in your Drive, e.g., 'my_models'\n",
        "model_save_dir = \"/content/drive/MyDrive/bert_translation_models\"\n",
        "os.makedirs(model_save_dir, exist_ok=True) # Create directory if it doesn't exist\n",
        "\n",
        "model_save_path = os.path.join(model_save_dir, \"bert_translation_model.pth\")\n",
        "\n",
        "# Save the model's state dictionary\n",
        "torch.save(model.state_dict(), model_save_path)\n",
        "\n",
        "print(f\"Model parameters saved to {model_save_path}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "UPiG23c3pzv1",
      "metadata": {
        "id": "UPiG23c3pzv1"
      },
      "outputs": [],
      "source": [
        "model.eval()\n",
        "with torch.no_grad():\n",
        "  total_val_loss = 0\n",
        "  for batch in val_dataloader:\n",
        "      logits = model(\n",
        "        eng_ids=eng_ids,\n",
        "        ita_ids=ita_ids,\n",
        "        eng_mask=eng_cross_mask, # Use eng_cross_mask for cross-attention in the model\n",
        "        ita_mask=ita_casual_mask, # Use ita_casual_mask for self-attention in the model\n",
        "        eng_token_type_ids=eng_token_type_ids,\n",
        "        ita_token_type_ids=ita_token_type_ids\n",
        "      )\n",
        "  # Calculate loss, ignoring padding tokens       \n",
        "  # Reshape logits and target for CrossEntropyLoss\n",
        "  loss = criterion(logits.view(-1, logits.size(-1)), ita_target_ids.view(-1))\n",
        "  avg_val_loss = total_val_loss / len(val_dataloader)\n",
        "  print(f\"Epoch {epoch+1} validation loss: {avg_val_loss:.4f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "59YlBgZ3pMbN",
      "metadata": {
        "id": "59YlBgZ3pMbN"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "id": "7173a42d",
      "metadata": {
        "id": "7173a42d"
      },
      "source": [
        "Load the saved model parameters and implement a function to translate an English sentence into Italian using the trained `BertTranslationModel`. This will involve tokenizing the input English sentence, feeding it to the encoder, and then using the decoder to generate the Italian translation token by token."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3d46fd4c",
      "metadata": {
        "id": "3d46fd4c"
      },
      "outputs": [],
      "source": [
        "# Load the saved model parameters\n",
        "model_save_path = \"/content/drive/MyDrive/bert_translation_models/bert_translation_model.pth\"\n",
        "\n",
        "# Instantiate the model with the same architecture as the trained model\n",
        "loaded_model = BertTranslationModel(\n",
        "    ita_vocab_size=ita_tokenizer.vocab_size,\n",
        "    eng_vocab_size=eng_tokenizer.vocab_size,\n",
        "    max_seq_len=MAXLEN,\n",
        "    d_model=768,\n",
        "    num_layers=6,\n",
        "    num_heads=12,\n",
        "    dropout=0.1 # Use the same dropout as during training\n",
        ")\n",
        "\n",
        "# Load the state dictionary\n",
        "loaded_model.load_state_dict(torch.load(model_save_path))\n",
        "\n",
        "# Set the model to evaluation mode\n",
        "loaded_model.eval()\n",
        "\n",
        "print(\"Model loaded successfully.\")\n",
        "\n",
        "def translate_sentence(model, sentence, eng_tokenizer, ita_tokenizer, max_len=MAXLEN, device=\"cuda\"):\n",
        "    model.to(device)\n",
        "    model.eval()\n",
        "\n",
        "    # Tokenize the input English sentence\n",
        "    eng_tokens = eng_tokenizer(\n",
        "        sentence,\n",
        "        padding='max_length',\n",
        "        truncation=True,\n",
        "        max_length=max_len,\n",
        "        return_attention_mask=True,\n",
        "        return_token_type_ids=True,\n",
        "        return_tensors='pt'\n",
        "    )\n",
        "\n",
        "    eng_ids = eng_tokens['input_ids'].to(device)\n",
        "    eng_mask = eng_tokens['attention_mask'].to(device)\n",
        "    eng_token_type_ids = eng_tokens['token_type_ids'].to(device)\n",
        "\n",
        "    # Prepare the encoder output (run the encoder once)\n",
        "    with torch.no_grad():\n",
        "        encoder_output = model.encoder(\n",
        "            input_ids=eng_ids,\n",
        "            attention_mask=eng_mask,\n",
        "            token_type_ids=eng_token_type_ids\n",
        "        )\n",
        "\n",
        "    # Start with the Italian start token (assuming [CLS] serves this purpose for BERT)\n",
        "    # And the corresponding token type id and mask\n",
        "    ita_input_ids = torch.tensor([[ita_tokenizer.cls_token_id]], device=device) # Start with [CLS]\n",
        "    ita_token_type_ids = torch.tensor([[0]], device=device) # Assuming segment 0 for the generated sequence\n",
        "    # Initial casual mask will be for a single token\n",
        "    ita_casual_mask = torch.zeros((1, 1, 1, 1), device=device) # shape (batch_size, num_heads, q_len, kv_len)\n",
        "\n",
        "    # Decode token by token\n",
        "    translated_tokens = []\n",
        "\n",
        "    for _ in range(max_len - 1): # Generate up to max_len-1 tokens (excluding CLS)\n",
        "        # Get the current sequence length of the generated Italian tokens\n",
        "        current_ita_len = ita_input_ids.size(1)\n",
        "\n",
        "        # Update the casual mask for the current sequence length\n",
        "        casual_mask = torch.triu(torch.ones(current_ita_len, current_ita_len), diagonal=1).bool().to(device)\n",
        "        casual_mask = casual_mask.masked_fill(casual_mask, float('-inf'))\n",
        "        casual_mask = casual_mask.masked_fill(~casual_mask, 0.0)\n",
        "        # Add batch and head dimensions for broadcasting\n",
        "        num_heads = model.decoder_blocks[0].self_attention.num_heads\n",
        "        ita_casual_mask = casual_mask.unsqueeze(0).unsqueeze(0).expand(1, num_heads, current_ita_len, current_ita_len)\n",
        "\n",
        "\n",
        "        # Update the Italian attention mask for cross-attention\n",
        "        # This mask is based on the *generated* Italian sequence length for the query\n",
        "        # and the English sequence length for key/value.\n",
        "        # The mask from the dataset was for the target, which is not available during inference.\n",
        "        # For inference, the cross-attention mask should allow attending to all non-padded English tokens.\n",
        "        # We need a mask of shape (batch_size, num_heads, ita_seq_len, eng_seq_len)\n",
        "        # Use the original eng_mask (batch_size, eng_seq_len) and expand it.\n",
        "        eng_seq_len = eng_ids.size(1)\n",
        "        eng_cross_mask = eng_mask.unsqueeze(1).unsqueeze(2).expand(1, num_heads, current_ita_len, eng_seq_len)\n",
        "        eng_cross_mask = (1.0 - eng_cross_mask.float()) * -1e9 # Convert to additive mask\n",
        "\n",
        "\n",
        "        # Forward pass through the decoder\n",
        "        with torch.no_grad():\n",
        "            logits = model.decoder_embeddings(ita_input_ids, ita_token_type_ids)\n",
        "            for decoder_block in model.decoder_blocks:\n",
        "                 logits = decoder_block(\n",
        "                    x=logits,\n",
        "                    encoder_output=encoder_output,\n",
        "                    self_mask=ita_casual_mask,\n",
        "                    cross_mask=eng_cross_mask\n",
        "                 )\n",
        "            output_logits = model.output_proj(logits) # Get logits for the next token\n",
        "\n",
        "\n",
        "        # Get the logits for the last generated token\n",
        "        next_token_logits = output_logits[:, -1, :]\n",
        "\n",
        "        # Predict the next token (greedy approach)\n",
        "        next_token_id = torch.argmax(next_token_logits, dim=-1).unsqueeze(0)\n",
        "\n",
        "        # Append the predicted token to the input sequence\n",
        "        ita_input_ids = torch.cat([ita_input_ids, next_token_id], dim=1)\n",
        "        ita_token_type_ids = torch.cat([ita_token_type_ids, torch.tensor([[0]], device=device)], dim=1) # Assuming segment 0\n",
        "\n",
        "        # Stop if the predicted token is the SEP token\n",
        "        if next_token_id.squeeze().item() == ita_tokenizer.sep_token_id:\n",
        "            break\n",
        "\n",
        "        # Append the predicted token ID to the translated tokens list (excluding CLS and SEP)\n",
        "        if next_token_id.squeeze().item() not in [ita_tokenizer.cls_token_id, ita_tokenizer.sep_token_id, ita_tokenizer.pad_token_id]:\n",
        "             translated_tokens.append(next_token_id.squeeze().item())\n",
        "\n",
        "\n",
        "    # Decode the translated token IDs back to a string\n",
        "    # Need to handle potential UNK tokens and subwords from the tokenizer\n",
        "    # The BertTokenizer's decode method should handle this\n",
        "    translated_sentence = ita_tokenizer.decode(translated_tokens, skip_special_tokens=True)\n",
        "\n",
        "    return translated_sentence\n",
        "\n",
        "# Example usage\n",
        "english_sentence = \"This is a test sentence.\"\n",
        "italian_translation = translate_sentence(loaded_model, english_sentence, eng_tokenizer, ita_tokenizer, max_len=MAXLEN, device=device)\n",
        "\n",
        "print(f\"English: {english_sentence}\")\n",
        "print(f\"Italian (Translated): {italian_translation}\")"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "include_colab_link": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "06738242f3f14c26bd4e209b131c8895": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_4a4f8e913b314771bf3e3d4de59d199c",
              "IPY_MODEL_591619e0c87344db8ba642d5eca7bb48",
              "IPY_MODEL_c1d2527f7bc14999a0ecc0758c45d013"
            ],
            "layout": "IPY_MODEL_ed92b1ab8994424393ccbf865b2ccf72"
          }
        },
        "074f1700383a422585d728722b3b49ca": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "132ea0df557247d6bf7fb38cc96525e0": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2b723e689a3845c6ba7cd70e8fbac61e",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_dd5359b211914b2bb1cf18bb57fa8e5f",
            "value": 1
          }
        },
        "13fa7e6bd7c54ed5a788065d44929db0": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "17c53e21d0d1415ea6fb72061225fa42": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a83d63d7ee664d0bbb88d0bb9d517c7d",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_1852b675391d4a3c83dd44eab122e0b1",
            "value": "vocab.txt:‚Äá100%"
          }
        },
        "1852b675391d4a3c83dd44eab122e0b1": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "1aa46824aea54eed9e11e8d539ecf43f": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_459891e1216c49e39a8374b3490055e5",
              "IPY_MODEL_42a577a374664a678189949adbe974da",
              "IPY_MODEL_359a067a4da24754967840e8662749b6"
            ],
            "layout": "IPY_MODEL_d5f66633f6a341d187f22d6cc9561dd7"
          }
        },
        "1b020b9cc5ed4cee9203d48c1e88e475": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "22eaccffa7b3406d9cad5b916ab08a58": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "2378330ce89142dfba64c1f9ef73ca44": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_bfa4dbe867a3451bace9e47189ae1dbe",
            "max": 213450,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_dfc9a511003c4a58b2ab3b3979f05702",
            "value": 213450
          }
        },
        "2717aaef635b40758efd091c9848fe4a": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "276621bda1fe42069da307f08d78c7cc": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "29a4d6a70f94463d9d6d6c56e9d552ad": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2b723e689a3845c6ba7cd70e8fbac61e": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "20px"
          }
        },
        "35682dc8794e4b3d9624cc96a755b765": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "359a067a4da24754967840e8662749b6": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c27205f76c5a449e9d51dada5c00080c",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_cfa83458a9104476b4a075b167c05f67",
            "value": "‚Äá59.0/59.0‚Äá[00:00&lt;00:00,‚Äá1.39kB/s]"
          }
        },
        "366d6f6fff93419381d99f158d5f2cc4": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_73a63a6aa8a347fc962af21cbdcd622b",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_ba3b261121a247b4bad838168270c8a8",
            "value": "tokenizer_config.json:‚Äá100%"
          }
        },
        "3c585773ac4e4130a43fd325924bedd6": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "42a577a374664a678189949adbe974da": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7dc1e35a253646fa9dccc1fd08a55349",
            "max": 59,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_ad2046f76d5049c585a82eaf87a23851",
            "value": 59
          }
        },
        "459891e1216c49e39a8374b3490055e5": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a10b10e56e7b4fb09e75231aca3168d4",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_4899cd7a681b44129724681c26b61f78",
            "value": "tokenizer_config.json:‚Äá100%"
          }
        },
        "4899cd7a681b44129724681c26b61f78": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "4a4f8e913b314771bf3e3d4de59d199c": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7f598711f6bb4ddca5e44d4784776bb2",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_fb9d410f37e04d869769988e72d0d944",
            "value": "tokenizer.json:‚Äá100%"
          }
        },
        "4e6fd1f8c3914983a21046b7521fabfe": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "50b5a34fe5e446e2a4102b1378eb0ff1": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6c0d2e8739d94aa3b3ea575e180649d8",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_3c585773ac4e4130a43fd325924bedd6",
            "value": "config.json:‚Äá100%"
          }
        },
        "51201d87be604c09a442651236ff1990": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_950e450b103e4035a2a6637a1c6997f2",
            "max": 570,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_22eaccffa7b3406d9cad5b916ab08a58",
            "value": 570
          }
        },
        "5812199c640244d5857e590ece65af68": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_811910f03610425885dc5418c938847b",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_864e9484e9a1409bbcb7be3390283b15",
            "value": "‚Äá49.0/49.0‚Äá[00:00&lt;00:00,‚Äá899B/s]"
          }
        },
        "591619e0c87344db8ba642d5eca7bb48": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5a7cc35ffd734d50b97441b592aa7234",
            "max": 435797,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_ea1fbd88c645493a813f7846f6772861",
            "value": 435797
          }
        },
        "5a7cc35ffd734d50b97441b592aa7234": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "64a9f52f113c48ea89f3466d38abeac4": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_13fa7e6bd7c54ed5a788065d44929db0",
            "max": 49,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_dd5de324b8414fe0a090f9b2b0bc5e06",
            "value": 49
          }
        },
        "6c0d2e8739d94aa3b3ea575e180649d8": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6dce994823b3415988f48a04d7ba282a": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2717aaef635b40758efd091c9848fe4a",
            "max": 433,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_c6a8644fe51b449aab1079cce7ea6dfe",
            "value": 433
          }
        },
        "7047eac3e3cc432391c9c1eea76cafdb": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "71a9b6b4271842608928604d785e3074": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1b020b9cc5ed4cee9203d48c1e88e475",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_074f1700383a422585d728722b3b49ca",
            "value": "‚Äá433/433‚Äá[00:00&lt;00:00,‚Äá10.4kB/s]"
          }
        },
        "73a63a6aa8a347fc962af21cbdcd622b": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "79ca501aa275412ea8e8eb8654c0395c": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_276621bda1fe42069da307f08d78c7cc",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_7047eac3e3cc432391c9c1eea76cafdb",
            "value": "‚Äá570/570‚Äá[00:00&lt;00:00,‚Äá13.3kB/s]"
          }
        },
        "7a50047618854ea187aa81ed833f265e": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7ac344f11b1143c99154cdec88ed030a": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "7dc1e35a253646fa9dccc1fd08a55349": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7f598711f6bb4ddca5e44d4784776bb2": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "80586b518e97488ea24544f4f9be3cef": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "811910f03610425885dc5418c938847b": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "864e9484e9a1409bbcb7be3390283b15": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "8a4fa53cd5544e8b8384affad4a6d2eb": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "8b7c8cc0fb7844b4bce7442dfe428b83": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4e6fd1f8c3914983a21046b7521fabfe",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_8a4fa53cd5544e8b8384affad4a6d2eb",
            "value": "vocab.txt:‚Äá"
          }
        },
        "91228710c0cd4f0ea7977cd5a40d1ba1": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_17c53e21d0d1415ea6fb72061225fa42",
              "IPY_MODEL_2378330ce89142dfba64c1f9ef73ca44",
              "IPY_MODEL_9e7781f8f55b4c6a80090de0edd6e4c9"
            ],
            "layout": "IPY_MODEL_7a50047618854ea187aa81ed833f265e"
          }
        },
        "94efbd73c4de41e997cbd8efb87ca2c5": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "950e450b103e4035a2a6637a1c6997f2": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "950f3f5fb52e4df8b0c537e56810685a": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "9e7781f8f55b4c6a80090de0edd6e4c9": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_94efbd73c4de41e997cbd8efb87ca2c5",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_c4c3e5a4861a453ab40d1a5a91fbbbcf",
            "value": "‚Äá213k/213k‚Äá[00:00&lt;00:00,‚Äá2.67MB/s]"
          }
        },
        "9f4f8fdededd40959f56f003ed08e473": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_b107e1c202e94dd4bd8b67824c8decc5",
              "IPY_MODEL_6dce994823b3415988f48a04d7ba282a",
              "IPY_MODEL_71a9b6b4271842608928604d785e3074"
            ],
            "layout": "IPY_MODEL_b2a5722782924366b943ffe6545a4c5d"
          }
        },
        "a10b10e56e7b4fb09e75231aca3168d4": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a83d63d7ee664d0bbb88d0bb9d517c7d": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ad2046f76d5049c585a82eaf87a23851": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "adcff33dc6c5407fb8989bc8018a020e": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c35c7ff1c64346ce97b909614c7131c6",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_7ac344f11b1143c99154cdec88ed030a",
            "value": "‚Äá235k/?‚Äá[00:00&lt;00:00,‚Äá5.23MB/s]"
          }
        },
        "b107e1c202e94dd4bd8b67824c8decc5": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_eb8eb096667543d8ba606f331b691835",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_d52775c1aa674b89a882f01b7b43e877",
            "value": "config.json:‚Äá100%"
          }
        },
        "b2a5722782924366b943ffe6545a4c5d": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ba3b261121a247b4bad838168270c8a8": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "bfa4dbe867a3451bace9e47189ae1dbe": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c1d2527f7bc14999a0ecc0758c45d013": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_35682dc8794e4b3d9624cc96a755b765",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_950f3f5fb52e4df8b0c537e56810685a",
            "value": "‚Äá436k/436k‚Äá[00:00&lt;00:00,‚Äá5.71MB/s]"
          }
        },
        "c22560089e74473798a947ffa18dfac7": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_8b7c8cc0fb7844b4bce7442dfe428b83",
              "IPY_MODEL_132ea0df557247d6bf7fb38cc96525e0",
              "IPY_MODEL_adcff33dc6c5407fb8989bc8018a020e"
            ],
            "layout": "IPY_MODEL_80586b518e97488ea24544f4f9be3cef"
          }
        },
        "c27205f76c5a449e9d51dada5c00080c": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c35c7ff1c64346ce97b909614c7131c6": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c4c3e5a4861a453ab40d1a5a91fbbbcf": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c6a8644fe51b449aab1079cce7ea6dfe": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "cfa83458a9104476b4a075b167c05f67": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d52775c1aa674b89a882f01b7b43e877": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d5f66633f6a341d187f22d6cc9561dd7": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "dd5359b211914b2bb1cf18bb57fa8e5f": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "dd5de324b8414fe0a090f9b2b0bc5e06": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "dfc9a511003c4a58b2ab3b3979f05702": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "e2ec7cc8b545456f8eb1cada455af2ee": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ea1fbd88c645493a813f7846f6772861": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "eb8eb096667543d8ba606f331b691835": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ed92b1ab8994424393ccbf865b2ccf72": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f46c31e05f2e438f9ab5cccb12f31c58": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_366d6f6fff93419381d99f158d5f2cc4",
              "IPY_MODEL_64a9f52f113c48ea89f3466d38abeac4",
              "IPY_MODEL_5812199c640244d5857e590ece65af68"
            ],
            "layout": "IPY_MODEL_29a4d6a70f94463d9d6d6c56e9d552ad"
          }
        },
        "f4b3b22bb67049ee9b394b5057d3b87a": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_50b5a34fe5e446e2a4102b1378eb0ff1",
              "IPY_MODEL_51201d87be604c09a442651236ff1990",
              "IPY_MODEL_79ca501aa275412ea8e8eb8654c0395c"
            ],
            "layout": "IPY_MODEL_e2ec7cc8b545456f8eb1cada455af2ee"
          }
        },
        "fb9d410f37e04d869769988e72d0d944": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
