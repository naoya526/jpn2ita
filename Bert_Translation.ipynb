{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/naoya526/jpn2ita/blob/main/Bert_Translation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b42af237",
      "metadata": {
        "id": "b42af237"
      },
      "source": [
        "## Import Module"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5f189bde",
      "metadata": {
        "id": "5f189bde"
      },
      "source": [
        "I used materials below:\n",
        "[1]`06_Attention_and_Transformers_in_BERT.ipynb`\n",
        "[2]`English_to_italian_automatic_translation.ipynb`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "61e92cdc",
      "metadata": {
        "id": "61e92cdc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3bebd147-f0d0-46a8-e40f-21e5020cc191"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2.0.2\n",
            "2.6.0+cu124\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import re\n",
        "import random\n",
        "import itertools\n",
        "import math\n",
        "from pathlib import Path\n",
        "\n",
        "import tqdm\n",
        "\n",
        "import numpy as np\n",
        "print(np.__version__)\n",
        "\n",
        "import torch\n",
        "print(torch.__version__)\n",
        "\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.optim import Adam\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "\n",
        "import transformers\n",
        "from tokenizers import BertWordPieceTokenizer\n",
        "from transformers import BertTokenizer, BertConfig\n",
        "\n",
        "### Suppress useless warnings\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\", message=\"The secret `HF_TOKEN` does not exist\")\n",
        "\n",
        "from collections import defaultdict\n",
        "from transformers import AutoTokenizer"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6151fdbd",
      "metadata": {
        "id": "6151fdbd"
      },
      "source": [
        "## Define Model\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "C06d3zDIDp9k",
      "metadata": {
        "id": "C06d3zDIDp9k"
      },
      "source": [
        "\n",
        "### Encoder (Bert) part\n",
        "Here, There's the function for implementing Encoder(Bert). I implemented with refering to [1]`06_Attention_and_Transformers_in_BERT.ipynb` and the paper.\n",
        "- `MultiHeadAttention`\n",
        "- `PositionwiseFeedForward`\n",
        "- `Encoder Block`\n",
        "- `BertEmbeddings` (Embedding for words)\n",
        "- `Bert`\n",
        "Bert is highly possible to understand meaning, but it is not enough for produce translation.\n",
        "Hence, In the next part, I implement Decoder. It is quite similar to Bert."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "b9f946b7",
      "metadata": {
        "id": "b9f946b7"
      },
      "outputs": [],
      "source": [
        "class MultiHeadAttention(nn.Module):\n",
        "    \"\"\"\n",
        "    - Query, Key, Value\n",
        "    - Scaled Dot Product Attention: softmax(QK^T / sqrt(d_k))V\n",
        "    \"\"\"\n",
        "    def __init__(self, d_model, num_heads, dropout=0.1):\n",
        "        super().__init__()\n",
        "        assert d_model % num_heads == 0, \"d_model must be divisible by num_heads\"\n",
        "\n",
        "        self.d_model = d_model\n",
        "        self.num_heads = num_heads\n",
        "        self.head_dim = d_model // num_heads\n",
        "        self.dropout = torch.nn.Dropout(dropout)\n",
        "\n",
        "        # Q, K, V linear Conversion\n",
        "        self.query = torch.nn.Linear(d_model, d_model)\n",
        "        self.key = torch.nn.Linear(d_model, d_model)\n",
        "        self.value = torch.nn.Linear(d_model, d_model)\n",
        "\n",
        "        self.out_proj = torch.nn.Linear(d_model, d_model)\n",
        "\n",
        "    def forward(self, x, mask=None):\n",
        "        batch_size, seq_len, d_model = x.shape\n",
        "\n",
        "        # step1: Q, K, V\n",
        "        query = self.query(x)  # (batch, seq_len, d_model)\n",
        "        key = self.key(x)      # (batch, seq_len, d_model)\n",
        "        value = self.value(x)  # (batch, seq_len, d_model)\n",
        "\n",
        "        # step2: Multi-Head\n",
        "        query = query.view(batch_size, seq_len, self.num_heads, self.head_dim)\n",
        "        key = key.view(batch_size, seq_len, self.num_heads, self.head_dim)  # 修正: query.shape → batch_size\n",
        "        value = value.view(batch_size, seq_len, self.num_heads, self.head_dim)\n",
        "\n",
        "        # step3: Change Dimention for Calclate Efficiently\n",
        "        query = query.permute(0, 2, 1, 3)  # (batch, num_heads, seq_len, head_dim)\n",
        "        key = key.permute(0, 2, 1, 3)\n",
        "        value = value.permute(0, 2, 1, 3)\n",
        "\n",
        "        # ステップ4: Scaled Dot-Product Attention\n",
        "        # scores = Q @ K^T / sqrt(d_k)\n",
        "        scores = torch.matmul(query, key.transpose(-2, -1)) / math.sqrt(self.head_dim)\n",
        "\n",
        "        # ステップ5: マスク処理（オプション）\n",
        "        if mask is not None:\n",
        "            # mask形状: (batch, 1, 1, seq_len) または (batch, 1, seq_len, seq_len) など、scores形状にブロードキャスト可能な形状\n",
        "            # scores形状: (batch, num_heads, seq_len, seq_len)\n",
        "            # 0を-1e9に変換（Softmaxで0になるように）→ 加算によるマスキングに変更\n",
        "            # scores = scores.masked_fill(mask == 0, -1e9) # 元のコード\n",
        "            scores = scores + mask # 加算によるマスキングに変更\n",
        "\n",
        "        # ステップ6: Softmax + Dropout\n",
        "        weights = F.softmax(scores, dim=-1)  # (batch, num_heads, seq_len, seq_len)\n",
        "        weights = self.dropout(weights)\n",
        "        # ステップ7: Value との積\n",
        "        context = torch.matmul(weights, value)\n",
        "        # ステップ8: ヘッドを結合して元の形状に戻す\n",
        "        context = context.permute(0, 2, 1, 3)\n",
        "        # → (batch, seq_len, d_model)\n",
        "        context = context.contiguous().view(batch_size, seq_len, self.num_heads * self.head_dim)\n",
        "\n",
        "        # ステップ9: 最終的な線形変換\n",
        "        return self.out_proj(context)  # 修正: output_linear → out_proj\n",
        "\n",
        "class PositionwiseFeedForward(nn.Module):\n",
        "    \"\"\"\n",
        "    ヒント:\n",
        "    - 2層のフィードフォワードネットワーク\n",
        "    - 中間層では次元を拡張（通常4倍）\n",
        "    - GELU活性化関数を使用\n",
        "    - ドロップアウトも忘れずに\n",
        "    \"\"\"\n",
        "    def __init__(self, d_model, d_ff, dropout=0.1):\n",
        "        super().__init__()\n",
        "        self.linear1 = nn.Linear(d_model, d_ff)  # 入力次元 → 中間次元\n",
        "        self.linear2 = nn.Linear(d_ff, d_model)  # 中間次元\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "        self.gelu = nn.GELU()\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.linear1(x)\n",
        "        x = self.gelu(x)\n",
        "        x = self.dropout(x)\n",
        "        x = self.linear2(x)\n",
        "        x = self.dropout(x)\n",
        "        return x\n",
        "\n",
        "class EncoderBlock(nn.Module):\n",
        "    \"\"\"\n",
        "    ヒント:\n",
        "    - Multi-Head Attention + Residual Connection + Layer Norm\n",
        "    - Feed Forward + Residual Connection + Layer Norm\n",
        "    - Which is better??: Pre-LN vs Post-LN\n",
        "    \"\"\"\n",
        "    def __init__(self, d_model, num_heads, d_ff, dropout=0.1):\n",
        "        super().__init__()\n",
        "        self.attention = MultiHeadAttention(d_model,num_heads)\n",
        "        self.ffn = PositionwiseFeedForward(d_model,d_ff)\n",
        "\n",
        "        self.layer_norm1 = nn.LayerNorm(normalized_shape=d_model, eps=1e-6)\n",
        "        self.layer_norm2 = nn.LayerNorm(normalized_shape=d_model, eps=1e-6)\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "    def forward(self, x, mask=None):\n",
        "        #Attention block\n",
        "        #TODO implement transformer block\n",
        "        residual = x\n",
        "        #print(\"Took Residual...\",x.shape)\n",
        "        x = self.layer_norm1(x)\n",
        "        #print(\"calculating layer norm...\",x.shape)\n",
        "        x = self.dropout(self.attention(x,mask))\n",
        "        #print(\"calculating Attention...\",x.shape)\n",
        "        x = x + residual\n",
        "        #print(\"calculating Residual Connection...\",x.shape)\n",
        "        #ffnn\n",
        "        residual = x\n",
        "        x = self.layer_norm2(x)\n",
        "        #print(\"calculating layer norm...\",x.shape)\n",
        "        x = self.dropout(self.ffn(x))\n",
        "        #print(\"calculating ffn...\",x.shape)\n",
        "        x = x + residual\n",
        "        return x\n",
        "\n",
        "\n",
        "class BertEmbeddings(nn.Module):\n",
        "    \"\"\"\n",
        "    - Token Embeddings (語彙サイズ × d_model)\n",
        "    - Position Embeddings (最大系列長 × d_model)\n",
        "    - Segment Embeddings (2 × d_model, NSPタスク用)\n",
        "    - 3つを足し合わせてLayerNormとDropout\n",
        "    \"\"\"\n",
        "    def __init__(self, vocab_size, d_model, max_seq_len=512, dropout=0.1):\n",
        "        super().__init__()\n",
        "        # TODO: 3種類の埋め込みを実装\n",
        "        self.d_model = d_model\n",
        "        self.token = torch.nn.Embedding(vocab_size, d_model, padding_idx=0)\n",
        "        self.position = torch.nn.Embedding(max_seq_len, d_model)\n",
        "        self.segment = torch.nn.Embedding(2, d_model)  # 2つのセグメント（0と1）\n",
        "        self.layer_norm = nn.LayerNorm(d_model)\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "        #Embedding: Lookup table that keep meaning vector of words\n",
        "    def forward(self, input_ids, token_type_ids=None):\n",
        "        # TODO: 埋め込みの計算を実装\n",
        "        batch_size, seq_len = input_ids.shape\n",
        "        # Step 1: Token Embeddings\n",
        "        token_embeddings = self.token(input_ids)\n",
        "        # Step 2: Position Embeddings\n",
        "        position_ids = torch.arange(seq_len, device=input_ids.device).unsqueeze(0)\n",
        "        position_ids = position_ids.expand(batch_size, -1)  # 🔧 バッチ次元を拡張\n",
        "        position_embeddings = self.position(position_ids)\n",
        "        # Step 3: Segment Embeddings\n",
        "        if token_type_ids is None:\n",
        "            token_type_ids = torch.zeros_like(input_ids)  # 全て0（単一文）\n",
        "        segment_embeddings = self.segment(token_type_ids)  # (batch, seq_len, d_model)\n",
        "        embeddings = token_embeddings + position_embeddings + segment_embeddings\n",
        "        embeddings = self.dropout(self.layer_norm(embeddings))\n",
        "\n",
        "        return embeddings\n",
        "\n",
        "class Bert(nn.Module):\n",
        "    \"\"\"\n",
        "    BERT実装の最終形\n",
        "\n",
        "    学習のヒント:\n",
        "    1. 論文を読んで全体像を理解\n",
        "    2. 小さな部品から実装（Attention → FFN → Block → Full Model）\n",
        "    3. 各層で print(tensor.shape) してサイズを確認\n",
        "    4. 簡単なダミーデータでテスト\n",
        "    5. 事前学習は計算量が大きいので、小さいモデルから開始\n",
        "\n",
        "    重要な概念:\n",
        "    - Bidirectional: 左右両方向の文脈を見る\n",
        "    - Masked Language Model: ランダムにマスクした単語を予測\n",
        "    - Next Sentence Prediction: 2つの文が連続するかを予測\n",
        "    - Attention Weights: どの単語に注目しているかの可視化\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, vocab_size, d_model=768, num_layers=12, num_heads=12, d_ff=3072, max_seq_len=512, dropout=0.1):\n",
        "        super().__init__()\n",
        "        self.d_model = d_model\n",
        "        self.num_layers = num_layers\n",
        "        self.heads = num_heads\n",
        "        # paper noted 4*d_model size for ff\n",
        "        self.feed_forward_hidden = d_model * 4\n",
        "        # embedding for BERT, sum of positional, segment, token embeddings\n",
        "        self.embedding = BertEmbeddings(vocab_size, d_model, max_seq_len, dropout)\n",
        "\n",
        "        self.encoder_blocks = torch.nn.ModuleList(\n",
        "            [EncoderBlock(d_model, num_heads, d_model * 4, dropout) for _ in range(num_layers)])\n",
        "\n",
        "    def forward(self, input_ids, attention_mask=None, token_type_ids=None):\n",
        "        # TODO: BERT全体のforward passを実装\n",
        "        if attention_mask is None:\n",
        "            attention_mask = (input_ids != 0).float()\n",
        "        if attention_mask.dim() == 2:\n",
        "            # (batch, seq_len) → (batch, 1, 1, seq_len)\n",
        "            extended_attention_mask = attention_mask.unsqueeze(1).unsqueeze(2)\n",
        "            # print(\"squeeze is required\") # デバッグプリントを削除\n",
        "        elif attention_mask.dim() == 4:\n",
        "            # 既に正しい形状の場合はそのまま使用\n",
        "            extended_attention_mask = attention_mask\n",
        "            # print(\"squeeze is not required\") # デバッグプリントを削除\n",
        "        else:\n",
        "             raise ValueError(f\"Attention mask should be 2D or 4D, but got {attention_mask.dim()}D\")\n",
        "\n",
        "        # 0を-1e9に変換（Softmaxで0になるように） - 加算によるマスキングのために値を調整\n",
        "        extended_attention_mask = (1.0 - extended_attention_mask) * -1e9\n",
        "\n",
        "\n",
        "        # embedding the indexed sequence to sequence of vectors\n",
        "        x = self.embedding(input_ids, token_type_ids)\n",
        "        # running over multiple transformer blocks\n",
        "        for encoder in self.encoder_blocks:\n",
        "            x = encoder.forward(x, extended_attention_mask) # 修正後のMultiHeadAttentionは加算マスクを期待\n",
        "        return x"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "dfc507b7",
      "metadata": {
        "id": "dfc507b7"
      },
      "source": [
        "### Decoder part\n",
        "This part, I implemented these functions:\n",
        "- `CrossAttention`(English Queue, Italian Key, Italian Value)\n",
        "- `DecoderBlock`\n",
        "- `BertTranslationModel`(Bert + Decoder Embedding + DecoderBlock*`num_layers`)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "_pie-kLFt9PO",
      "metadata": {
        "id": "_pie-kLFt9PO"
      },
      "outputs": [],
      "source": [
        "class CrossAttention(nn.Module):\n",
        "    \"\"\"\n",
        "    this module is implemented with modifying MultiHeadAttention.\n",
        "    Query: English\n",
        "    Key, Value: Italian\n",
        "    You can see the difference in forward input\n",
        "    \"\"\"\n",
        "    def __init__(self, d_model, num_heads, dropout=0.1):\n",
        "        super().__init__() # initialization\n",
        "        assert d_model % num_heads == 0, \"d_model must be divisible by num_heads\"\n",
        "\n",
        "        self.d_model = d_model\n",
        "        self.num_heads = num_heads\n",
        "        self.head_dim = d_model // num_heads  # dimention of each head\n",
        "        self.dropout = torch.nn.Dropout(dropout)\n",
        "\n",
        "        # Q, K, V の線形変換（修正：torch.nn.linear → torch.nn.Linear）\n",
        "        self.query = torch.nn.Linear(d_model, d_model)\n",
        "        self.key = torch.nn.Linear(d_model, d_model)\n",
        "        self.value = torch.nn.Linear(d_model, d_model)\n",
        "\n",
        "        # 最終的な出力変換\n",
        "        self.out_proj = torch.nn.Linear(d_model, d_model)\n",
        "\n",
        "    def forward(self, query_input, key_value_input, mask=None): # here is the difference\n",
        "        batch_size, q_len, _ = query_input.shape\n",
        "        _, kv_len, _ = key_value_input.shape\n",
        "        # ステップ1: Q, K, V を線形変換で生成\n",
        "        query = self.query(query_input)  # (batch, seq_len, d_model)\n",
        "        key = self.key(key_value_input)      # (batch, seq_len, d_model)\n",
        "        value = self.value(key_value_input)  # (batch, seq_len, d_model)\n",
        "\n",
        "        # ステップ2: Multi-Head用に次元を変形\n",
        "        query = query.view(batch_size, q_len, self.num_heads, self.head_dim)\n",
        "        key = key.view(batch_size, kv_len, self.num_heads, self.head_dim)  # 修正: query.shape → batch_size\n",
        "        value = value.view(batch_size, kv_len, self.num_heads, self.head_dim)\n",
        "\n",
        "        query = query.permute(0, 2, 1, 3)  # (batch, num_heads, seq_len, head_dim)\n",
        "        key = key.permute(0, 2, 1, 3)\n",
        "        value = value.permute(0, 2, 1, 3)\n",
        "\n",
        "        # ステップ4: Scaled Dot-Product Attention\n",
        "        # scores = Q @ K^T / sqrt(d_k)\n",
        "        scores = torch.matmul(query, key.transpose(-2, -1)) / math.sqrt(self.head_dim)\n",
        "\n",
        "        # ステップ5: マスク処理（オプション）\n",
        "        if mask is not None:\n",
        "            # mask形状: (batch, 1, 1, seq_len) → scores形状: (batch, num_heads, seq_len, seq_len)\n",
        "            scores = scores + mask  # ブロードキャストで加算\n",
        "\n",
        "        # ステップ6: Softmax + Dropout\n",
        "        weights = F.softmax(scores, dim=-1)  # (batch, num_heads, seq_len, seq_len)\n",
        "        weights = self.dropout(weights)\n",
        "        # ステップ7: Value との積\n",
        "        context = torch.matmul(weights, value)\n",
        "        # ステップ8: ヘッドを結合して元の形状に戻す\n",
        "        context = context.permute(0, 2, 1, 3)\n",
        "        # → (batch, seq_len, d_model)\n",
        "        context = context.contiguous().view(batch_size, q_len, self.num_heads * self.head_dim)\n",
        "\n",
        "        # ステップ9: 最終的な線形変換\n",
        "        return self.out_proj(context)  # 修正: output_linear → out_proj\n",
        "\n",
        "class DecoderBlock(nn.Module):\n",
        "    \"\"\"\n",
        "    Basically similar to EncoderBlock, but refer to the infomation of Input(English context)\n",
        "    \"\"\"\n",
        "    def __init__(self, d_model, num_heads, d_ff, dropout=0.1):\n",
        "        super().__init__()\n",
        "        #First, implement Self Attention\n",
        "        self.self_attention = MultiHeadAttention(d_model,num_heads)\n",
        "        #Second, implement Cross Attention\n",
        "        self.cross_attention = CrossAttention(d_model, num_heads)\n",
        "        #Third, FFNN\n",
        "        self.ffn = PositionwiseFeedForward(d_model,d_ff)\n",
        "\n",
        "        self.layer_norm1 = nn.LayerNorm(normalized_shape=d_model, eps=1e-6)\n",
        "        self.layer_norm2 = nn.LayerNorm(normalized_shape=d_model, eps=1e-6)\n",
        "        self.layer_norm3 = nn.LayerNorm(normalized_shape=d_model, eps=1e-6)\n",
        "\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "    def forward(self, x, encoder_output, self_mask=None, cross_mask=None):\n",
        "        #Self Attention\n",
        "        residual = x\n",
        "        x = self.layer_norm1(x)\n",
        "        x = self.self_attention(x,mask=self_mask)\n",
        "        x = self.dropout(x) + residual\n",
        "\n",
        "        #Cross Attention\n",
        "        residual = x\n",
        "        x = self.layer_norm2(x)\n",
        "        x = self.cross_attention(\n",
        "            query_input=x,\n",
        "            key_value_input=encoder_output,\n",
        "            mask=cross_mask\n",
        "        )\n",
        "        x = self.dropout(x) + residual\n",
        "\n",
        "        residual = x\n",
        "        x = self.layer_norm3(x)\n",
        "        x = self.ffn(x)\n",
        "        x = self.dropout(x) + residual\n",
        "        return x\n",
        "\n",
        "class BertTranslationModel(nn.Module):\n",
        "    \"\"\"\n",
        "    Ita2Eng Translation Model\n",
        "    Encoder: Bert\n",
        "    Decoder: BertEmbedding, DecoderBlock*N, FFN\n",
        "    \"\"\"\n",
        "    def __init__(self,\n",
        "                 ita_vocab_size,  # イタリア語語彙サイズ\n",
        "                 eng_vocab_size,  # 英語語彙サイズ\n",
        "                 max_seq_len,\n",
        "                 d_model=512,\n",
        "                 num_layers=6,\n",
        "                 num_heads=8,\n",
        "                 dropout=0.1):\n",
        "        super().__init__()\n",
        "\n",
        "        self.encoder = Bert(\n",
        "            vocab_size=eng_vocab_size,\n",
        "            d_model=d_model,\n",
        "            num_layers=num_layers,\n",
        "            num_heads=num_heads,\n",
        "            max_seq_len=max_seq_len,\n",
        "            dropout=dropout\n",
        "        )\n",
        "\n",
        "        self.decoder_embeddings = BertEmbeddings(\n",
        "            vocab_size=ita_vocab_size,\n",
        "            d_model=d_model,\n",
        "            max_seq_len=max_seq_len,\n",
        "            dropout=dropout\n",
        "        )\n",
        "\n",
        "        self.decoder_blocks = nn.ModuleList([\n",
        "            DecoderBlock(\n",
        "                d_model=d_model,\n",
        "                num_heads=num_heads,\n",
        "                d_ff=d_model * 4, #based on the paper of Bert\n",
        "                dropout=dropout)\n",
        "            for _ in range(num_layers)\n",
        "        ])\n",
        "\n",
        "        self.output_proj = nn.Linear(d_model, ita_vocab_size)\n",
        "\n",
        "    def forward(self,\n",
        "                eng_ids,\n",
        "                ita_ids,\n",
        "                eng_mask=None,\n",
        "                ita_mask=None,\n",
        "                eng_token_type_ids=None,\n",
        "                ita_token_type_ids=None):\n",
        "        # understand english\n",
        "        encoder_output = self.encoder(input_ids=eng_ids, attention_mask=eng_mask, token_type_ids=eng_token_type_ids)\n",
        "        # produce Italian\n",
        "        decoder_input = self.decoder_embeddings(input_ids=ita_ids, token_type_ids=ita_token_type_ids)\n",
        "\n",
        "        for decoder_block in self.decoder_blocks:\n",
        "            decoder_input = decoder_block(\n",
        "                x=decoder_input,\n",
        "                encoder_output=encoder_output,\n",
        "                self_mask=ita_mask,               # 英語のCausal mask\n",
        "                cross_mask=eng_mask\n",
        "                )\n",
        "        logits = self.output_proj(decoder_input)\n",
        "        return logits"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d02d832e",
      "metadata": {
        "id": "d02d832e"
      },
      "source": [
        "## Use model\n",
        "In this part, I followed the configuration of [2]`English_to_italian_automatic_translation.ipynb`.\n",
        "\n",
        "---\n",
        "### Prepare Dataset\n",
        "for Bert, `<sos>`and `<eos>` are not required. Hence, ignore these token."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "EZbXW_bCx1Ef",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EZbXW_bCx1Ef",
        "outputId": "5cfdd24a-382a-4891-c573-6037ae4aa49a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1_npGYZk13fs5hE0kAggiSrmKkqW3OrLT\n",
            "To: <_io.BufferedWriter name='<stdout>'>\n",
            "100% 3.92M/3.92M [00:00<00:00, 15.4MB/s]\n"
          ]
        }
      ],
      "source": [
        "# Download the files\n",
        "URL = \"https://drive.google.com/file/d/1_npGYZk13fs5hE0kAggiSrmKkqW3OrLT/view?usp=sharing\"\n",
        "!gdown --fuzzy $URL -O- | tar -xz"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "7uYUnrAouYf1",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7uYUnrAouYf1",
        "outputId": "d5eba914-1756-489a-a72f-3c1a690a9e33"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['hi .', 'hi .', 'run !', 'run !', 'run !', 'who ?', 'wow !', 'duck !', 'duck !', 'jump !', 'jump !', 'jump !', 'jump .', 'jump .', 'jump .', 'stay .', 'stay .', 'stay .', 'stay .', 'stay .', 'stay .', 'stay .', 'stay .', 'stay .', 'stop !', 'stop !', 'stop !', 'wait !', 'wait !', 'wait !', 'wait .', 'wait .', 'wait .', 'do it .', 'do it .', 'do it .', 'do it .', 'do it .', 'do it .', 'go on .', 'go on .', 'go on .', 'go on .', 'go on .', 'go on .', 'hello !', 'hello !', 'hello !', 'hello .', 'i hid .']\n",
            "['ciao !', 'ciao .', 'corri !', 'corra !', 'correte !', 'chi ?', 'wow !', 'amore !', 'tesoro !', 'salta !', 'salti !', 'saltate !', 'salta .', 'salti .', 'saltate .', 'resta .', 'stai .', 'stia .', 'state .', 'resti .', 'restate .', 'rimani .', 'rimanga .', 'rimanete .', 'fermati !', 'fermatevi !', 'si fermi !', 'aspetta !', 'aspettate !', 'aspetti !', 'aspetta .', 'aspetti .', 'aspettate .', 'fallo .', 'falla .', 'lo faccia .', 'la faccia .', 'fatelo .', 'fatela .', 'vai avanti .', 'continua .', 'continui .', 'continuate .', 'vada avanti .', 'andate avanti .', 'buongiorno !', 'ciao !', 'salve .', 'ciao .', 'mi sono nascosto .']\n",
            "333112 333112\n"
          ]
        }
      ],
      "source": [
        "# for Bert, <sos> and <eos> are not required\n",
        "#SPECIAL = [\"<sos>\", \"<eos>\", \"<pad>\"]\n",
        "SPECIAL = [\"<pad>\"]\n",
        "MAXLEN = 20\n",
        "\n",
        "f = open(\"text-eng.txt\")\n",
        "# Define the list of all tokens in the English set ...\n",
        "ENG_VOCABULARY = []\n",
        "for line in f:\n",
        "    line = line.strip()\n",
        "    # Remove <sos> and <eos>\n",
        "    line = line.replace('<sos>', '').replace('<eos>', '').strip()\n",
        "    if line == \"\":\n",
        "        continue\n",
        "\n",
        "    ENG_VOCABULARY.append(line)\n",
        "f.close()\n",
        "print(ENG_VOCABULARY[:50])\n",
        "\n",
        "f = open(\"text-ita.txt\")\n",
        "# Define the list of all tokens in the Italian set ...\n",
        "ITA_VOCABULARY = []\n",
        "for line in f:\n",
        "    line = line.strip()\n",
        "    # Remove <sos> and <eos>\n",
        "    line = line.replace('<sos>', '').replace('<eos>', '').strip()\n",
        "    if line == \"\":\n",
        "        continue\n",
        "    ITA_VOCABULARY.append(line)\n",
        "f.close()\n",
        "print(ITA_VOCABULARY[:50])\n",
        "# Make sure that the three special tokens have the same indices in the two vocabularies.\n",
        "# Assign here the three indices...\n",
        "\n",
        "PAD = SPECIAL[0]\n",
        "\n",
        "# Inverse mappings.\n",
        "ENG_INVERSE = {w: n for n, w in enumerate(ENG_VOCABULARY)}\n",
        "ITA_INVERSE = {w: n for n, w in enumerate(ITA_VOCABULARY)}\n",
        "#print(ENG_INVERSE)\n",
        "print(len(ENG_VOCABULARY), len(ITA_VOCABULARY))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5I5NmJq4yeec",
      "metadata": {
        "id": "5I5NmJq4yeec"
      },
      "source": [
        "### Incremental approach to token vocabulary building\n",
        "In the lesson of Deep Learning, I learned the sophisticated way of tokenizing words called WordPiece tokenization.\n",
        "\n",
        "The WordPiece tokenization algorithm builds its vocabulary incrementally, starting from a basic alphabet and iteratively merging subword units based on their frequency and co-occurrence patterns. (cited from [1]`06_Attention_and_Transformers_in_Bert.ipynb`)\n",
        "\n",
        "---\n",
        "\n",
        "#### The demonstration of pretrained tokenizer\n",
        "\n",
        "In [1], Tokenizer `bert-base-cased` was used for English(For tokenization of English, it's used in this project as well). In this project, Tokenizier [3]`dbmdz/bert-base-italian-cased` for italian is used.\n",
        "[3]https://huggingface.co/dbmdz/bert-base-italian-cased  \n",
        "\\\n",
        "In this section, With using small scentence, The procedure will be explained.\n",
        "\n",
        "These procedure will be iterated:\n",
        "- Compute word frequencies\n",
        "- Split Words into Alphabet\n",
        "- Compute score of each pair\n",
        "- Merge the pair"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "TOiqXhYIus4m",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 635,
          "referenced_widgets": [
            "e730fe3287174c658026ff16ddb38be6",
            "93425a5dd2154ec78056b01f42da6272",
            "4cf84dfb07bd4d75a3229a571988ff8f",
            "046b3e585ce943abb8ab62090b175f75",
            "61942a7c31594de0995c6bd57dbf0d52",
            "3c21b117c2264f18b04f01fd24c4159e",
            "1faac31df4f242968897fe35b5d3858a",
            "9a5da6def2104ec4ad262072e2969db8",
            "1a7a4b1c490342a29e26ce84f2da1b14",
            "3c55b6fd02d9462dade1ca17fc1e53a2",
            "92d44168cbb140f494ad47a7de1e70e4",
            "6cc0e7ded24340f58b46c5c5e8be9a6d",
            "ffff2c66cb9e4bd5bf7a1b4d3eeb974e",
            "28cf104006514bf4b73acfdd65b98d2f",
            "c71c045bca0e48c9826962c2f56d4c26",
            "bbc1b5fa93594303950c3b9507d8732c",
            "4d5b5829682945c0bdac0377377fc9c7",
            "0d7a0c054fc147a58601a82be711e339",
            "d962fe2965324ce59e78f6fbe0c44506",
            "11988aa34ba6418d856ce1dfefa0f764",
            "07c09dd92e024ca9b49ab269a7a03e31",
            "7029077f0b1d4e61838c176c7c5608db",
            "e869e761b324408d844965f3a9e8efd2",
            "08a4d9e35c3a4abe8d96a40940bdc25a",
            "0046a269a98f419d82b3ddc3731788cc",
            "44f26125cfc14282ae02097f27435fc2",
            "bfe037dc18b041d1a37db5a4f24c3ff7",
            "d1629298b3444b649baa3ecc6442d1da",
            "4135cf72c80f4e59aa1f9efac33e2c62",
            "ce5a0391517a4030b9dd5932c36d7334",
            "1b44253544404c6b8518fbe601fdff11",
            "43de27cb1822499c8b1b564bd331f6b6",
            "aeeb5702b42a4c018eefb3427e86e5e9",
            "e55aa43cafa8419b9b9eb642ba15c79e",
            "52b40659c50543fbb22c2e66e4758f38",
            "404d3f74600f49fe94cbc22575eec9f1",
            "bd644608179141d08c7aa74f1d31dc5d",
            "f551861b0221406e8002613062414d9d",
            "4ac4f6eccb6b457bb8eeba3199aac948",
            "6c46d96052ef4a53b296103291f42f9f",
            "6fb0168fe6084301bd89b375a71b551f",
            "ecd34e97414542f58513aa42f77e9faf",
            "9db4384e50354c74be8e6d647a81a927",
            "d616a4a1d58745208464a40793226edd",
            "fa3d143d88cf406986a45f8adfcd274a",
            "030586334f094945a56620b325e9a902",
            "a7d7f6bcd35d4010a945946d04dc360a",
            "91191accb301443cb9fac8a4bd18af69",
            "1eb04629d9db448c85500cf7481b750a",
            "4e9f87b33ca24c18ae195d37470cf698",
            "15494d9a3cb04f5b890216f277d0ec15",
            "b77b1c4ccb2142daa6b9098cd881d85f",
            "89d3a0a9ef17429ab8622eba1f2accef",
            "fa1141b8cbe441a3a4977c0c5128f9e4",
            "bd52af6d297541f6b78a82f480d71faf",
            "38a5c3bfa063407d9d76772762031f4c",
            "0f6fa48b6473456190caab9d04f804fb",
            "e47e207f601c4fffaedf9a85da5c2fd7",
            "4ef3006f14e24662803ff8c0e36c0d17",
            "e991c1eef9494844a0bdac6a56b151c3",
            "5e6124e0d61e4d728e24c016ee6e30a5",
            "562f41b546d6492b902bdd802ffc7e2a",
            "310bacd5f5824731ac7444e70ebb975a",
            "c8b50cd2c0414bd080c2518e99c0f205",
            "14371a4507fd44f18be9f23f184d0bdb",
            "0f78d376d97b42698322700cad78c69e",
            "308d3d96f9264eaa916270e884772523",
            "ae9369d61fe14d92a39cd9961441ebcb",
            "a814ed25701d4149a2f4aeadd14f8acb",
            "f3908c3178304185b185843aeca8ccd8",
            "d50bcdd5a51a4c79bc16a6d7350664cd",
            "59fd4e7091f548b28e80b2f0d9bb0c8d",
            "18b68d908487465597772b0608dfe3af",
            "1d7d9b51cdfc40929b30f7d3d99e027d",
            "316553ca36e5466ea4ae08a46f821929",
            "e202c3d8254046868d484f7602580fdc",
            "faa686874fc54460a03dc86fbbd7ebf8"
          ]
        },
        "id": "TOiqXhYIus4m",
        "outputId": "d0f43e4c-6846-4746-84ab-f6f7e32454c4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/49.0 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "e730fe3287174c658026ff16ddb38be6"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config.json:   0%|          | 0.00/570 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "6cc0e7ded24340f58b46c5c5e8be9a6d"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "vocab.txt:   0%|          | 0.00/213k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "e869e761b324408d844965f3a9e8efd2"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer.json:   0%|          | 0.00/436k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "e55aa43cafa8419b9b9eb642ba15c79e"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/59.0 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "fa3d143d88cf406986a45f8adfcd274a"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config.json:   0%|          | 0.00/433 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "38a5c3bfa063407d9d76772762031f4c"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "vocab.txt: 0.00B [00:00, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "308d3d96f9264eaa916270e884772523"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "English: ['This', 'is', 'the', 'Hugging', 'Face', 'Course', '.']\n",
            "English: ['This', 'chapter', 'is', 'about', 'tokenization', '.']\n",
            "English: ['This', 'section', 'shows', 'several', 'tokenizer', 'algorithms', '.']\n",
            "English: ['Hopefully', ',', 'you', 'will', 'be', 'able', 'to', 'understand', 'how', 'they', 'are', 'trained', 'and', 'generate', 'tokens', '.']\n",
            "Italian: ['Questo', 'è', 'il', 'corso', 'di', 'Hugging', 'Face', '.']\n",
            "Italian: ['Questo', 'capitolo', 'riguarda', 'la', 'tokenizzazione', '.']\n",
            "Italian: ['Questa', 'sezione', 'mostra', 'diversi', 'algoritmi', 'di', 'tokenizzazione', '.']\n",
            "Italian: ['Speriamo', 'che', 'tu', 'sia', 'in', 'grado', 'di', 'capire', 'come', 'vengono', 'addestrati', 'e', 'generano', 'token', '.']\n",
            "\n",
            "English Word Frequency: defaultdict(<class 'int'>, {'This': 3, 'is': 2, 'the': 1, 'Hugging': 1, 'Face': 1, 'Course': 1, '.': 4, 'chapter': 1, 'about': 1, 'tokenization': 1, 'section': 1, 'shows': 1, 'several': 1, 'tokenizer': 1, 'algorithms': 1, 'Hopefully': 1, ',': 1, 'you': 1, 'will': 1, 'be': 1, 'able': 1, 'to': 1, 'understand': 1, 'how': 1, 'they': 1, 'are': 1, 'trained': 1, 'and': 1, 'generate': 1, 'tokens': 1})\n",
            "Italian Word Frequency: defaultdict(<class 'int'>, {'Questo': 2, 'è': 1, 'il': 1, 'corso': 1, 'di': 3, 'Hugging': 1, 'Face': 1, '.': 4, 'capitolo': 1, 'riguarda': 1, 'la': 1, 'tokenizzazione': 2, 'Questa': 1, 'sezione': 1, 'mostra': 1, 'diversi': 1, 'algoritmi': 1, 'Speriamo': 1, 'che': 1, 'tu': 1, 'sia': 1, 'in': 1, 'grado': 1, 'capire': 1, 'come': 1, 'vengono': 1, 'addestrati': 1, 'e': 1, 'generano': 1, 'token': 1})\n",
            "\n",
            "English vocab size: 28996\n",
            "Italian vocab size: 31102\n"
          ]
        }
      ],
      "source": [
        "eng_tokenizer = AutoTokenizer.from_pretrained(\"bert-base-cased\")  # English\n",
        "ita_tokenizer = AutoTokenizer.from_pretrained(\"dbmdz/bert-base-italian-cased\")  # Italian\n",
        "\n",
        "### Example bilingual corpus\n",
        "eng_corpus = [\n",
        "    \"This is the Hugging Face Course.\",\n",
        "    \"This chapter is about tokenization.\",\n",
        "    \"This section shows several tokenizer algorithms.\",\n",
        "    \"Hopefully, you will be able to understand how they are trained and generate tokens.\",\n",
        "]\n",
        "\n",
        "ita_corpus = [\n",
        "    \"Questo è il corso di Hugging Face.\",\n",
        "    \"Questo capitolo riguarda la tokenizzazione.\",\n",
        "    \"Questa sezione mostra diversi algoritmi di tokenizzazione.\",\n",
        "    \"Speriamo che tu sia in grado di capire come vengono addestrati e generano token.\",\n",
        "]\n",
        "\n",
        "### Get frequency for English\n",
        "eng_word_freqs = defaultdict(int)\n",
        "for text in eng_corpus:\n",
        "    words_with_offsets = eng_tokenizer.backend_tokenizer.pre_tokenizer.pre_tokenize_str(text)\n",
        "    new_words = [word for word, offset in words_with_offsets]\n",
        "    print(f\"English: {new_words}\")\n",
        "    for word in new_words:\n",
        "        eng_word_freqs[word] += 1\n",
        "\n",
        "### Get frequency for Italian\n",
        "ita_word_freqs = defaultdict(int)\n",
        "for text in ita_corpus:\n",
        "    words_with_offsets = ita_tokenizer.backend_tokenizer.pre_tokenizer.pre_tokenize_str(text)\n",
        "    new_words = [word for word, offset in words_with_offsets]\n",
        "    print(f\"Italian: {new_words}\")\n",
        "    for word in new_words:\n",
        "        ita_word_freqs[word] += 1\n",
        "\n",
        "print(f\"\\nEnglish Word Frequency: {eng_word_freqs}\")\n",
        "print(f\"Italian Word Frequency: {ita_word_freqs}\")\n",
        "\n",
        "# Get vocabulary sizes for model initialization\n",
        "eng_vocab_size = eng_tokenizer.vocab_size\n",
        "ita_vocab_size = ita_tokenizer.vocab_size\n",
        "print(f\"\\nEnglish vocab size: {eng_vocab_size}\")\n",
        "print(f\"Italian vocab size: {ita_vocab_size}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "fbd93b11",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fbd93b11",
        "outputId": "96994408-0e5c-4561-abdf-95b81924739e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "All alphabets: ['##a', '##c', '##d', '##e', '##g', '##h', '##i', '##k', '##l', '##m', '##n', '##o', '##p', '##r', '##s', '##t', '##u', '##v', '##z', '.', 'F', 'H', 'Q', 'S', 'a', 'c', 'd', 'e', 'g', 'i', 'l', 'm', 'r', 's', 't', 'v', 'è']\n",
            "\n",
            "Splitted Words: {'Questo': ['Q', '##u', '##e', '##s', '##t', '##o'], 'è': ['è'], 'il': ['i', '##l'], 'corso': ['c', '##o', '##r', '##s', '##o'], 'di': ['d', '##i'], 'Hugging': ['H', '##u', '##g', '##g', '##i', '##n', '##g'], 'Face': ['F', '##a', '##c', '##e'], '.': ['.'], 'capitolo': ['c', '##a', '##p', '##i', '##t', '##o', '##l', '##o'], 'riguarda': ['r', '##i', '##g', '##u', '##a', '##r', '##d', '##a'], 'la': ['l', '##a'], 'tokenizzazione': ['t', '##o', '##k', '##e', '##n', '##i', '##z', '##z', '##a', '##z', '##i', '##o', '##n', '##e'], 'Questa': ['Q', '##u', '##e', '##s', '##t', '##a'], 'sezione': ['s', '##e', '##z', '##i', '##o', '##n', '##e'], 'mostra': ['m', '##o', '##s', '##t', '##r', '##a'], 'diversi': ['d', '##i', '##v', '##e', '##r', '##s', '##i'], 'algoritmi': ['a', '##l', '##g', '##o', '##r', '##i', '##t', '##m', '##i'], 'Speriamo': ['S', '##p', '##e', '##r', '##i', '##a', '##m', '##o'], 'che': ['c', '##h', '##e'], 'tu': ['t', '##u'], 'sia': ['s', '##i', '##a'], 'in': ['i', '##n'], 'grado': ['g', '##r', '##a', '##d', '##o'], 'capire': ['c', '##a', '##p', '##i', '##r', '##e'], 'come': ['c', '##o', '##m', '##e'], 'vengono': ['v', '##e', '##n', '##g', '##o', '##n', '##o'], 'addestrati': ['a', '##d', '##d', '##e', '##s', '##t', '##r', '##a', '##t', '##i'], 'e': ['e'], 'generano': ['g', '##e', '##n', '##e', '##r', '##a', '##n', '##o'], 'token': ['t', '##o', '##k', '##e', '##n']}\n"
          ]
        }
      ],
      "source": [
        "### split all word into alphabet\n",
        "alphabet = []\n",
        "for word in ita_word_freqs.keys():\n",
        "    if word[0] not in alphabet:\n",
        "        alphabet.append(word[0])\n",
        "    for letter in word[1:]:\n",
        "        if f\"##{letter}\" not in alphabet:\n",
        "            alphabet.append(f\"##{letter}\")\n",
        "\n",
        "alphabet.sort()\n",
        "print(f'All alphabets: {alphabet}')\n",
        "\n",
        "### insert special token and subword\n",
        "vocab = [\"[PAD]\", \"[UNK]\", \"[CLS]\", \"[SEP]\", \"[MASK]\"] + alphabet.copy()\n",
        "splits = {word: [c if i == 0 else f\"##{c}\" for i, c in enumerate(word)] for word in ita_word_freqs.keys()}\n",
        "print(f'\\nSplitted Words: {splits}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "75de80da",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "75de80da",
        "outputId": "85b1070a-49a9-4930-d2c4-631d00b1999a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Scores for each Pair: {('Q', '##u'): 0.16666666666666666, ('##u', '##e'): 0.025, ('##e', '##s'): 0.02857142857142857, ('##s', '##t'): 0.08928571428571429, ('##t', '##o'): 0.01875, ('i', '##l'): 0.16666666666666666, ('c', '##o'): 0.02, ('##o', '##r'): 0.01, ('##r', '##s'): 0.02857142857142857, ('##s', '##o'): 0.007142857142857143, ('d', '##i'): 0.05263157894736842, ('H', '##u'): 0.16666666666666666, ('##u', '##g'): 0.027777777777777776, ('##g', '##g'): 0.027777777777777776, ('##g', '##i'): 0.008771929824561403, ('##i', '##n'): 0.0043859649122807015, ('##n', '##g'): 0.027777777777777776, ('F', '##a'): 0.06666666666666667, ('##a', '##c'): 0.06666666666666667, ('##c', '##e'): 0.05, ('c', '##a'): 0.02666666666666667, ('##a', '##p'): 0.044444444444444446, ('##p', '##i'): 0.03508771929824561, ('##i', '##t'): 0.013157894736842105, ('##o', '##l'): 0.016666666666666666, ('##l', '##o'): 0.016666666666666666, ('r', '##i'): 0.05263157894736842, ('##i', '##g'): 0.008771929824561403, ('##g', '##u'): 0.027777777777777776, ('##u', '##a'): 0.011111111111111112, ('##a', '##r'): 0.006666666666666667, ('##r', '##d'): 0.025, ('##d', '##a'): 0.016666666666666666, ('l', '##a'): 0.06666666666666667, ('t', '##o'): 0.0375, ('##o', '##k'): 0.05, ('##k', '##e'): 0.05, ('##e', '##n'): 0.020833333333333332, ('##n', '##i'): 0.008771929824561403, ('##i', '##z'): 0.015037593984962405, ('##z', '##z'): 0.04081632653061224, ('##z', '##a'): 0.01904761904761905, ('##a', '##z'): 0.01904761904761905, ('##z', '##i'): 0.022556390977443608, ('##i', '##o'): 0.007894736842105263, ('##o', '##n'): 0.016666666666666666, ('##n', '##e'): 0.016666666666666666, ('##t', '##a'): 0.008333333333333333, ('s', '##e'): 0.025, ('##e', '##z'): 0.007142857142857143, ('m', '##o'): 0.05, ('##o', '##s'): 0.007142857142857143, ('##t', '##r'): 0.025, ('##r', '##a'): 0.02666666666666667, ('##i', '##v'): 0.05263157894736842, ('##v', '##e'): 0.05, ('##e', '##r'): 0.015, ('##s', '##i'): 0.007518796992481203, ('a', '##l'): 0.16666666666666666, ('##l', '##g'): 0.05555555555555555, ('##g', '##o'): 0.016666666666666666, ('##r', '##i'): 0.010526315789473684, ('##t', '##m'): 0.041666666666666664, ('##m', '##i'): 0.017543859649122806, ('S', '##p'): 0.3333333333333333, ('##p', '##e'): 0.016666666666666666, ('##i', '##a'): 0.007017543859649123, ('##a', '##m'): 0.022222222222222223, ('##m', '##o'): 0.016666666666666666, ('c', '##h'): 0.2, ('##h', '##e'): 0.05, ('t', '##u'): 0.041666666666666664, ('s', '##i'): 0.02631578947368421, ('i', '##n'): 0.041666666666666664, ('g', '##r'): 0.05, ('##a', '##d'): 0.016666666666666666, ('##d', '##o'): 0.0125, ('##i', '##r'): 0.005263157894736842, ('##r', '##e'): 0.005, ('##o', '##m'): 0.016666666666666666, ('##m', '##e'): 0.016666666666666666, ('v', '##e'): 0.05, ('##n', '##o'): 0.008333333333333333, ('a', '##d'): 0.125, ('##d', '##d'): 0.0625, ('##d', '##e'): 0.0125, ('##a', '##t'): 0.008333333333333333, ('##t', '##i'): 0.006578947368421052, ('g', '##e'): 0.025, ('##a', '##n'): 0.005555555555555556}\n"
          ]
        }
      ],
      "source": [
        " ### compute score for merging\n",
        "\n",
        "def compute_pair_scores(splits):\n",
        "    letter_freqs = defaultdict(int)\n",
        "    pair_freqs = defaultdict(int)\n",
        "\n",
        "    for word, freq in ita_word_freqs.items():\n",
        "        split = splits[word]\n",
        "        if len(split) == 1:\n",
        "            letter_freqs[split[0]] += freq\n",
        "            continue\n",
        "        for i in range(len(split) - 1):\n",
        "            pair = (split[i], split[i + 1])\n",
        "            letter_freqs[split[i]] += freq\n",
        "            pair_freqs[pair] += freq\n",
        "        letter_freqs[split[-1]] += freq\n",
        "\n",
        "    scores = {\n",
        "        pair: freq / (letter_freqs[pair[0]] * letter_freqs[pair[1]])\n",
        "        for pair, freq in pair_freqs.items()\n",
        "    }\n",
        "    return scores\n",
        "\n",
        "pair_scores = compute_pair_scores(splits)\n",
        "print(f'Scores for each Pair: {pair_scores}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "6adc0481",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6adc0481",
        "outputId": "fda6e8c3-2c1b-496a-88dd-c0e14d284f80"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "('S', '##p') 0.3333333333333333\n",
            "['Qu', '##e', '##s', '##t', '##o']\n"
          ]
        }
      ],
      "source": [
        "### finding pair with best score\n",
        "\n",
        "best_pair = \"\"\n",
        "max_score = None\n",
        "for pair, score in pair_scores.items():\n",
        "    if max_score is None or max_score < score:\n",
        "        best_pair = pair\n",
        "        max_score = score\n",
        "\n",
        "print(best_pair, max_score)\n",
        "vocab.append(\"ab\")\n",
        "\n",
        "### merge pair ###\n",
        "def merge_pair(a, b, splits):\n",
        "    for word in ita_word_freqs:\n",
        "        split = splits[word]\n",
        "        if len(split) == 1:\n",
        "            continue\n",
        "        i = 0\n",
        "        while i < len(split) - 1:\n",
        "            if split[i] == a and split[i + 1] == b:\n",
        "                merge = a + b[2:] if b.startswith(\"##\") else a + b\n",
        "                split = split[:i] + [merge] + split[i + 2 :]\n",
        "            else:\n",
        "                i += 1\n",
        "        splits[word] = split\n",
        "    return splits\n",
        "\n",
        "splits = merge_pair(\"Q\", \"##u\", splits)\n",
        "print(splits[\"Questo\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "7943860a",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7943860a",
        "outputId": "93468ed7-0457-4d03-9cd6-5c03cd3a2dd6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Final Vocab: ['[PAD]', '[UNK]', '[CLS]', '[SEP]', '[MASK]', '##a', '##c', '##d', '##e', '##g', '##h', '##i', '##k', '##l', '##m', '##n', '##o', '##p', '##r', '##s', '##t', '##u', '##v', '##z', '.', 'F', 'H', 'Q', 'S', 'a', 'c', 'd', 'e', 'g', 'i', 'l', 'm', 'r', 's', 't', 'v', 'è', 'ab', 'Hu', 'Sp', 'ch', 'il', 'al', 'ad', 'add', 'Hug', 'Hugg', 'alg', '##gu', 'tu', '##st', '##tm', '##rs', '##ng', 'in', 'Fa', 'Fac', '##ap', 'cap', '##gua', '##guar', '##guard', '##guarda', 'la', '##ad']\n"
          ]
        }
      ],
      "source": [
        "### keep looping to merge more pair\n",
        "\n",
        "vocab_size = 70\n",
        "while len(vocab) < vocab_size:\n",
        "    scores = compute_pair_scores(splits)\n",
        "    best_pair, max_score = \"\", None\n",
        "    for pair, score in scores.items():\n",
        "        if max_score is None or max_score < score:\n",
        "            best_pair = pair\n",
        "            max_score = score\n",
        "    splits = merge_pair(*best_pair, splits)\n",
        "    new_token = (\n",
        "        best_pair[0] + best_pair[1][2:]\n",
        "        if best_pair[1].startswith(\"##\")\n",
        "        else best_pair[0] + best_pair[1]\n",
        "    )\n",
        "    vocab.append(new_token)\n",
        "\n",
        "print(f'Final Vocab: {vocab}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "1afe6c8b",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1afe6c8b",
        "outputId": "77479c47-2cfd-4c15-ab79-def12f1250fb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['Q', '##u', '##e', '##st', '##o']\n",
            "['Q', '##a', '##e', '##st', '##o']\n"
          ]
        }
      ],
      "source": [
        "### encode a word ###\n",
        "def encode_word(word):\n",
        "    tokens = []\n",
        "    while len(word) > 0:\n",
        "        i = len(word)\n",
        "        while i > 0 and word[:i] not in vocab:\n",
        "            i -= 1\n",
        "        if i == 0:\n",
        "            return [\"[UNK]\"]\n",
        "        tokens.append(word[:i])\n",
        "        word = word[i:]\n",
        "        if len(word) > 0:\n",
        "            word = f\"##{word}\"\n",
        "    return tokens\n",
        "\n",
        "print(encode_word(\"Questo\"))\n",
        "# This one should be unknown (within this corpus)\n",
        "print(encode_word(\"Qaesto\"))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## BERTDataset"
      ],
      "metadata": {
        "id": "jeHBuC79RMHm"
      },
      "id": "jeHBuC79RMHm"
    },
    {
      "cell_type": "code",
      "source": [
        "class BERTDataset(Dataset):\n",
        "    def __init__(self, data_pair, tokenizer, seq_len=64):\n",
        "\n",
        "        self.tokenizer = tokenizer\n",
        "        self.seq_len = seq_len\n",
        "        self.corpus_lines = len(data_pair)\n",
        "        self.lines = data_pair\n",
        "\n",
        "    def __len__(self):\n",
        "        return self.corpus_lines\n",
        "\n",
        "    def __getitem__(self, item):\n",
        "\n",
        "        # Step 1: get random sentence pair, either negative or positive (saved as is_next_label)\n",
        "        t1, t2, is_next_label = self.get_sent(item)\n",
        "\n",
        "        # Step 2: replace random words in sentence with mask / random words\n",
        "        t1_random, t1_label = self.random_word(t1)\n",
        "        t2_random, t2_label = self.random_word(t2)\n",
        "\n",
        "        # Step 3: Adding CLS and SEP tokens to the start and end of sentences\n",
        "        # Adding PAD token for labels\n",
        "        t1 = [self.tokenizer.vocab['[CLS]']] + t1_random + [self.tokenizer.vocab['[SEP]']]\n",
        "        t2 = t2_random + [self.tokenizer.vocab['[SEP]']]\n",
        "        t1_label = [self.tokenizer.vocab['[PAD]']] + t1_label + [self.tokenizer.vocab['[PAD]']]\n",
        "        t2_label = t2_label + [self.tokenizer.vocab['[PAD]']]\n",
        "\n",
        "        # Step 4: combine sentence 1 and 2 as one input\n",
        "        # adding PAD tokens to make the sentence same length as seq_len\n",
        "        segment_label = ([1 for _ in range(len(t1))] + [2 for _ in range(len(t2))])[:self.seq_len]\n",
        "        bert_input = (t1 + t2)[:self.seq_len]\n",
        "        bert_label = (t1_label + t2_label)[:self.seq_len]\n",
        "        padding = [self.tokenizer.vocab['[PAD]'] for _ in range(self.seq_len - len(bert_input))]\n",
        "        bert_input.extend(padding), bert_label.extend(padding), segment_label.extend(padding)\n",
        "\n",
        "        output = {\"bert_input\": bert_input,\n",
        "                  \"bert_label\": bert_label,\n",
        "                  \"segment_label\": segment_label,\n",
        "                  \"is_next\": is_next_label}\n",
        "\n",
        "        return {key: torch.tensor(value) for key, value in output.items()}\n",
        "\n",
        "    def random_word(self, sentence):\n",
        "        tokens = sentence.split()\n",
        "        output_label = []\n",
        "        output = []\n",
        "\n",
        "        # 15% of the tokens would be replaced\n",
        "        for i, token in enumerate(tokens):\n",
        "            prob = random.random()\n",
        "\n",
        "            # remove cls and sep token\n",
        "            token_id = self.tokenizer(token)['input_ids'][1:-1]\n",
        "\n",
        "            # 15% chance of altering token\n",
        "            if prob < 0.15:\n",
        "                prob /= 0.15\n",
        "\n",
        "                # 80% chance change token to mask token\n",
        "                if prob < 0.8:\n",
        "                    for i in range(len(token_id)):\n",
        "                        output.append(self.tokenizer.vocab['[MASK]'])\n",
        "\n",
        "                # 10% chance change token to random token\n",
        "                elif prob < 0.9:\n",
        "                    for i in range(len(token_id)):\n",
        "                        output.append(random.randrange(len(self.tokenizer.vocab)))\n",
        "\n",
        "                # 10% chance change token to current token\n",
        "                else:\n",
        "                    output.append(token_id)\n",
        "\n",
        "                output_label.append(token_id)\n",
        "\n",
        "            else:\n",
        "                output.append(token_id)\n",
        "                for i in range(len(token_id)):\n",
        "                    output_label.append(0)\n",
        "\n",
        "        # flattening\n",
        "        output = list(itertools.chain(*[[x] if not isinstance(x, list) else x for x in output]))\n",
        "        output_label = list(itertools.chain(*[[x] if not isinstance(x, list) else x for x in output_label]))\n",
        "        assert len(output) == len(output_label)\n",
        "        return output, output_label\n",
        "\n",
        "    def get_sent(self, index):\n",
        "        '''return random sentence pair'''\n",
        "        t1, t2 = self.get_corpus_line(index)\n",
        "\n",
        "        # negative or positive pair, for next sentence prediction\n",
        "        if random.random() > 0.5:\n",
        "            return t1, t2, 1\n",
        "        else:\n",
        "            return t1, self.get_random_line(), 0\n",
        "\n",
        "    def get_corpus_line(self, item):\n",
        "        '''return sentence pair'''\n",
        "        return self.lines[item][0], self.lines[item][1]\n",
        "\n",
        "    def get_random_line(self):\n",
        "        '''return random single sentence'''\n",
        "        return self.lines[random.randrange(len(self.lines))][1]"
      ],
      "metadata": {
        "id": "VCCMqd7JRKf6"
      },
      "id": "VCCMqd7JRKf6",
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "baf44a70"
      },
      "source": [
        "# Task\n",
        "Create a translation model using `BertTranslationModel` based on loaded text data. The model should translate from English to Italian. Outline the steps for Tokenization, Word Embedding, and training."
      ],
      "id": "baf44a70"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "510b5e99"
      },
      "source": [
        "## データセットの準備\n",
        "\n",
        "### Subtask:\n",
        "翻訳モデル用に、英語とイタリア語のペアを含むデータセットを準備します。これには、テキストデータの読み込み、トークン化、パディング、テンソルへの変換などが含まれます。`BERTDataset` クラスを翻訳タスクに合わせて修正または新しく定義する必要があるかもしれません。\n"
      ],
      "id": "510b5e99"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "163fc43b"
      },
      "source": [
        "**Reasoning**:\n",
        "The first step is to load the English and Italian sentence pairs from the text files and store them as a list of tuples.\n",
        "\n"
      ],
      "id": "163fc43b"
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "87909343",
        "outputId": "6641956d-0a57-4c45-9094-86441ce6c731"
      },
      "source": [
        "eng_sentences = []\n",
        "with open(\"text-eng.txt\", \"r\") as f:\n",
        "    for line in f:\n",
        "        line = line.strip().replace('<sos>', '').replace('<eos>', '').strip()\n",
        "        if line:\n",
        "            eng_sentences.append(line)\n",
        "\n",
        "ita_sentences = []\n",
        "with open(\"text-ita.txt\", \"r\") as f:\n",
        "    for line in f:\n",
        "        line = line.strip().replace('<sos>', '').replace('<eos>', '').strip()\n",
        "        if line:\n",
        "            ita_sentences.append(line)\n",
        "\n",
        "data_pair = list(zip(eng_sentences, ita_sentences))\n",
        "\n",
        "# Split data into training and validation sets\n",
        "# Using a simple split for now, can use train_test_split later if needed\n",
        "train_size = int(0.8 * len(data_pair))\n",
        "train_data = data_pair[:train_size]\n",
        "val_data = data_pair[train_size:]\n",
        "\n",
        "print(f\"Total pairs: {len(data_pair)}\")\n",
        "print(f\"Training pairs: {len(train_data)}\")\n",
        "print(f\"Validation pairs: {len(val_data)}\")"
      ],
      "id": "87909343",
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total pairs: 333112\n",
            "Training pairs: 266489\n",
            "Validation pairs: 66623\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ec81bb96"
      },
      "source": [
        "class TranslationDataset(Dataset):\n",
        "    def __init__(self, data_pair, eng_tokenizer, ita_tokenizer, seq_len=64):\n",
        "        self.data_pair = data_pair\n",
        "        self.eng_tokenizer = eng_tokenizer\n",
        "        self.ita_tokenizer = ita_tokenizer\n",
        "        self.seq_len = seq_len\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data_pair)\n",
        "\n",
        "    def __getitem__(self, item):\n",
        "        eng_sentence, ita_sentence = self.data_pair[item]\n",
        "\n",
        "        # Tokenize English sentence\n",
        "        eng_tokens = self.eng_tokenizer(\n",
        "            eng_sentence,\n",
        "            padding='max_length',\n",
        "            truncation=True,\n",
        "            max_length=self.seq_len,\n",
        "            return_attention_mask=True,\n",
        "            return_token_type_ids=True,\n",
        "            return_tensors='pt'\n",
        "        )\n",
        "\n",
        "        # Tokenize Italian sentence for decoder input and target\n",
        "        # Need to add [CLS] and [SEP] for decoder input, and [SEP] for target\n",
        "        # The target is the input shifted by one token, effectively predicting the next token\n",
        "        ita_input_tokens = self.ita_tokenizer(\n",
        "            ita_sentence,\n",
        "            padding='max_length',\n",
        "            truncation=True,\n",
        "            max_length=self.seq_len,\n",
        "            return_attention_mask=True, # This mask is for cross-attention from encoder\n",
        "            return_token_type_ids=True,\n",
        "            return_tensors='pt'\n",
        "        )\n",
        "\n",
        "        # Create decoder input by adding [CLS] and shifting\n",
        "        ita_input_ids = ita_input_tokens['input_ids'].squeeze(0)\n",
        "        ita_attention_mask = ita_input_tokens['attention_mask'].squeeze(0)\n",
        "        ita_token_type_ids = ita_input_tokens['token_type_ids'].squeeze(0)\n",
        "\n",
        "        # Create the causal mask for the decoder self-attention\n",
        "        # This ensures the decoder at a given position only attends to previous positions\n",
        "        seq_len = ita_input_ids.size(0)\n",
        "        casual_mask = torch.triu(torch.ones(seq_len, seq_len), diagonal=1).bool()\n",
        "        casual_mask = casual_mask.masked_fill(casual_mask, float('-inf'))\n",
        "        casual_mask = casual_mask.masked_fill(~casual_mask, 0.0)\n",
        "\n",
        "\n",
        "        # Create the target labels for Italian (shifted input)\n",
        "        # The target is the input sequence shifted by one position, with the first token ([CLS]) removed.\n",
        "        # The padding token at the end of the input sequence will correspond to the last real token in the target.\n",
        "        ita_target_ids = ita_input_ids.clone()\n",
        "        # Shift target sequence by one position\n",
        "        ita_target_ids = torch.cat([ita_target_ids[1:], torch.tensor([self.ita_tokenizer.pad_token_id])])\n",
        "\n",
        "        output = {\n",
        "            \"eng_ids\": eng_tokens['input_ids'].squeeze(0),\n",
        "            \"eng_mask\": eng_tokens['attention_mask'].squeeze(0),\n",
        "            \"eng_token_type_ids\": eng_tokens['token_type_ids'].squeeze(0),\n",
        "            \"ita_ids\": ita_input_ids,\n",
        "            \"ita_mask\": ita_attention_mask, # This will be used for cross attention.\n",
        "            \"ita_token_type_ids\": ita_token_type_ids,\n",
        "            \"ita_casual_mask\": casual_mask, # This will be used for self attention in decoder.\n",
        "            \"ita_target_ids\": ita_target_ids,\n",
        "        }\n",
        "\n",
        "        return output\n"
      ],
      "id": "ec81bb96",
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ad36cc19"
      },
      "source": [
        "**Reasoning**:\n",
        "Create Dataset objects for the training and validation sets using the defined `TranslationDataset` class and then create DataLoaders for both datasets to handle batching and shuffling during training and evaluation.\n",
        "\n"
      ],
      "id": "ad36cc19"
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2ddad872",
        "outputId": "af82b73a-cae9-4213-b59f-d4996ae8b10c"
      },
      "source": [
        "train_dataset = TranslationDataset(train_data, eng_tokenizer, ita_tokenizer, seq_len=MAXLEN)\n",
        "val_dataset = TranslationDataset(val_data, eng_tokenizer, ita_tokenizer, seq_len=MAXLEN)\n",
        "\n",
        "BATCH_SIZE = 32\n",
        "\n",
        "train_dataloader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
        "val_dataloader = DataLoader(val_dataset, batch_size=BATCH_SIZE)\n",
        "\n",
        "print(f\"Number of batches in training DataLoader: {len(train_dataloader)}\")\n",
        "print(f\"Number of batches in validation DataLoader: {len(val_dataloader)}\")"
      ],
      "id": "2ddad872",
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of batches in training DataLoader: 8328\n",
            "Number of batches in validation DataLoader: 2082\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a0a7819a"
      },
      "source": [
        "## モデルの定義\n",
        "\n",
        "### Subtask:\n",
        "`BertTranslationModel` クラスを使用してモデルをインスタンス化します。この際、適切な語彙サイズ、モデルの次元、レイヤー数、ヘッド数などを指定します。\n"
      ],
      "id": "a0a7819a"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d1ff30a3"
      },
      "source": [
        "**Reasoning**:\n",
        "BertTranslationModel クラスを適切な引数でインスタンス化し、その構造を確認します。\n",
        "\n"
      ],
      "id": "d1ff30a3"
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f8232374",
        "outputId": "bd02cb2e-b41b-42aa-cb28-db287a96f9fb"
      },
      "source": [
        "model = BertTranslationModel(\n",
        "    ita_vocab_size=ita_tokenizer.vocab_size,\n",
        "    eng_vocab_size=eng_tokenizer.vocab_size,\n",
        "    max_seq_len=MAXLEN,\n",
        "    d_model=768, # 使用するBERTモデルの一般的な次元\n",
        "    num_layers=6, # レイヤー数は適宜設定\n",
        "    num_heads=12, # ヘッド数は適宜設定 (d_modelで割り切れるように)\n",
        "    dropout=0.1\n",
        ")\n",
        "\n",
        "print(model)"
      ],
      "id": "f8232374",
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "BertTranslationModel(\n",
            "  (encoder): Bert(\n",
            "    (embedding): BertEmbeddings(\n",
            "      (token): Embedding(28996, 768, padding_idx=0)\n",
            "      (position): Embedding(20, 768)\n",
            "      (segment): Embedding(2, 768)\n",
            "      (layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "      (dropout): Dropout(p=0.1, inplace=False)\n",
            "    )\n",
            "    (encoder_blocks): ModuleList(\n",
            "      (0-5): 6 x EncoderBlock(\n",
            "        (attention): MultiHeadAttention(\n",
            "          (dropout): Dropout(p=0.1, inplace=False)\n",
            "          (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "          (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "          (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "          (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
            "        )\n",
            "        (ffn): PositionwiseFeedForward(\n",
            "          (linear1): Linear(in_features=768, out_features=3072, bias=True)\n",
            "          (linear2): Linear(in_features=3072, out_features=768, bias=True)\n",
            "          (dropout): Dropout(p=0.1, inplace=False)\n",
            "          (gelu): GELU(approximate='none')\n",
            "        )\n",
            "        (layer_norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
            "        (layer_norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
            "        (dropout): Dropout(p=0.1, inplace=False)\n",
            "      )\n",
            "    )\n",
            "  )\n",
            "  (decoder_embeddings): BertEmbeddings(\n",
            "    (token): Embedding(31102, 768, padding_idx=0)\n",
            "    (position): Embedding(20, 768)\n",
            "    (segment): Embedding(2, 768)\n",
            "    (layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "    (dropout): Dropout(p=0.1, inplace=False)\n",
            "  )\n",
            "  (decoder_blocks): ModuleList(\n",
            "    (0-5): 6 x DecoderBlock(\n",
            "      (self_attention): MultiHeadAttention(\n",
            "        (dropout): Dropout(p=0.1, inplace=False)\n",
            "        (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
            "      )\n",
            "      (cross_attention): CrossAttention(\n",
            "        (dropout): Dropout(p=0.1, inplace=False)\n",
            "        (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
            "      )\n",
            "      (ffn): PositionwiseFeedForward(\n",
            "        (linear1): Linear(in_features=768, out_features=3072, bias=True)\n",
            "        (linear2): Linear(in_features=3072, out_features=768, bias=True)\n",
            "        (dropout): Dropout(p=0.1, inplace=False)\n",
            "        (gelu): GELU(approximate='none')\n",
            "      )\n",
            "      (layer_norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
            "      (layer_norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
            "      (layer_norm3): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
            "      (dropout): Dropout(p=0.1, inplace=False)\n",
            "    )\n",
            "  )\n",
            "  (output_proj): Linear(in_features=768, out_features=31102, bias=True)\n",
            ")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4749b305"
      },
      "source": [
        "## 損失関数とオプティマイザの設定\n",
        "\n",
        "### Subtask:\n",
        "翻訳タスクに適した損失関数（例: `CrossEntropyLoss`）とオプティマイザ（例: `Adam`）を定義します。\n"
      ],
      "id": "4749b305"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bdf49b64"
      },
      "source": [
        "**Reasoning**:\n",
        "Define the loss function and the optimizer for the translation task as instructed.\n",
        "\n"
      ],
      "id": "bdf49b64"
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "107bb02a",
        "outputId": "0e261d17-4724-4435-aef7-2a137af9cecc"
      },
      "source": [
        "criterion = nn.CrossEntropyLoss(ignore_index=ita_tokenizer.pad_token_id)\n",
        "optimizer = Adam(model.parameters(), lr=1e-4)\n",
        "\n",
        "print(\"Loss function (criterion):\", criterion)\n",
        "print(\"Optimizer:\", optimizer)"
      ],
      "id": "107bb02a",
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss function (criterion): CrossEntropyLoss()\n",
            "Optimizer: Adam (\n",
            "Parameter Group 0\n",
            "    amsgrad: False\n",
            "    betas: (0.9, 0.999)\n",
            "    capturable: False\n",
            "    differentiable: False\n",
            "    eps: 1e-08\n",
            "    foreach: None\n",
            "    fused: None\n",
            "    lr: 0.0001\n",
            "    maximize: False\n",
            "    weight_decay: 0\n",
            ")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "02fbb8a9"
      },
      "source": [
        "## 訓練ループの実装\n",
        "\n",
        "### Subtask:\n",
        "モデルを訓練するためのループを作成します。これには、データのバッチ処理、モデルのフォワードパス、損失の計算、バックプロパゲーション、パラメータの更新などが含まれます。\n"
      ],
      "id": "02fbb8a9"
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1c57b767",
        "outputId": "83296295-d0e3-4800-fa64-851ff6029c4c"
      },
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(f\"Using device: {device}\")\n",
        "model.to(device)\n",
        "\n",
        "EPOCHS = 5 # Define the number of training epochs\n",
        "\n",
        "for epoch in range(EPOCHS):\n",
        "    model.train()\n",
        "    total_loss = 0\n",
        "    train_iterator = tqdm.tqdm(train_dataloader, desc=f\"Epoch {epoch+1}\")\n",
        "\n",
        "    for i, batch in enumerate(train_iterator):\n",
        "        # Move batch to device\n",
        "        eng_ids = batch['eng_ids'].to(device)\n",
        "        eng_mask = batch['eng_mask'].to(device)\n",
        "        eng_token_type_ids = batch['eng_token_type_ids'].to(device)\n",
        "        ita_ids = batch['ita_ids'].to(device)\n",
        "        # ita_mask from dataset is for cross-attention, shape (batch_size, seq_len)\n",
        "        ita_mask = batch['ita_mask'].to(device)\n",
        "        ita_target_ids = batch['ita_target_ids'].to(device)\n",
        "        ita_token_type_ids = batch['ita_token_type_ids'].to(device)\n",
        "        # ita_casual_mask from dataset is for self-attention, shape (seq_len, seq_len)\n",
        "        ita_casual_mask = batch['ita_casual_mask'].to(device)\n",
        "\n",
        "\n",
        "        # Prepare masks for the model forward pass\n",
        "        # Eng mask for encoder self-attention and decoder cross-attention\n",
        "        # Needs to be broadcastable to (batch, num_heads, q_len/seq_len, kv_len/seq_len)\n",
        "        batch_size, ita_seq_len = ita_ids.shape\n",
        "        _, eng_seq_len = eng_ids.shape\n",
        "        num_heads = model.decoder_blocks[0].cross_attention.num_heads # Assuming same number of heads for self and cross attention\n",
        "\n",
        "        # Eng mask for encoder self-attention\n",
        "        # Reshape to (batch, 1, 1, eng_seq_len) for broadcasting\n",
        "        eng_encoder_mask = eng_mask.unsqueeze(1).unsqueeze(2)\n",
        "        # Convert to additive mask format (0.0 and -1e9)\n",
        "        eng_encoder_mask = (1.0 - eng_encoder_mask.float()) * -1e9 # Ensure float for calculation\n",
        "\n",
        "\n",
        "        # Eng mask for decoder cross-attention\n",
        "        # Needs shape (batch, num_heads, ita_seq_len, eng_seq_len) for addition\n",
        "        # Start with (batch, 1, 1, eng_seq_len) and expand\n",
        "        eng_cross_mask = eng_mask.unsqueeze(1).unsqueeze(2)\n",
        "        eng_cross_mask = eng_cross_mask.expand(batch_size, num_heads, ita_seq_len, eng_seq_len)\n",
        "        # Convert to additive mask format (0.0 and -1e9)\n",
        "        eng_cross_mask = (1.0 - eng_cross_mask.float()) * -1e9 # Ensure float for calculation\n",
        "\n",
        "\n",
        "        # Ita causal mask for decoder self-attention\n",
        "        # Dataset provides (seq_len, seq_len) mask. After DataLoader, it's (batch_size, seq_len, seq_len).\n",
        "        # Needs shape (batch_size, num_heads, seq_len, seq_len) for addition.\n",
        "        # Add head dimension and expand.\n",
        "        ita_casual_mask = ita_casual_mask.unsqueeze(1) # shape (batch_size, 1, seq_len, seq_len)\n",
        "        ita_casual_mask = ita_casual_mask.expand(batch_size, num_heads, ita_seq_len, ita_seq_len)\n",
        "        # The mask from dataset is already in additive format (-inf and 0.0)\n",
        "\n",
        "\n",
        "        # Forward pass\n",
        "        # Pass appropriate masks to the model\n",
        "        # The model expects eng_mask to be the cross-attention mask and ita_mask to be the self-attention mask for the decoder\n",
        "        logits = model(\n",
        "            eng_ids=eng_ids,\n",
        "            ita_ids=ita_ids,\n",
        "            eng_mask=eng_cross_mask, # Use eng_cross_mask for cross-attention in the model\n",
        "            ita_mask=ita_casual_mask, # Use ita_casual_mask for self-attention in the model\n",
        "            eng_token_type_ids=eng_token_type_ids,\n",
        "            ita_token_type_ids=ita_token_type_ids\n",
        "            )\n",
        "\n",
        "        # Calculate loss, ignoring padding tokens\n",
        "        # Reshape logits and target for CrossEntropyLoss\n",
        "        loss = criterion(logits.view(-1, logits.size(-1)), ita_target_ids.view(-1))\n",
        "\n",
        "        # Backpropagation\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        total_loss += loss.item()\n",
        "        train_iterator.set_postfix({'loss': loss.item()})\n",
        "\n",
        "    avg_train_loss = total_loss / len(train_dataloader)\n",
        "    print(f\"Epoch {epoch+1} finished. Average training loss: {avg_train_loss:.4f}\")\n",
        "\n",
        "    # Optional: Add validation loop here\n",
        "    # model.eval()\n",
        "    # with torch.no_grad():\n",
        "    #     total_val_loss = 0\n",
        "    #     for batch in val_dataloader:\n",
        "    #         ... calculate validation loss ...\n",
        "    #     avg_val_loss = total_val_loss / len(val_dataloader)\n",
        "    #     print(f\"Epoch {epoch+1} validation loss: {avg_val_loss:.4f}\")"
      ],
      "id": "1c57b767",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device: cuda\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 1: 100%|██████████| 8328/8328 [31:44<00:00,  4.37it/s, loss=0.00184]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1 finished. Average training loss: 0.2999\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 2:  79%|███████▉  | 6615/8328 [25:07<06:19,  4.52it/s, loss=0.00198]"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "e730fe3287174c658026ff16ddb38be6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_93425a5dd2154ec78056b01f42da6272",
              "IPY_MODEL_4cf84dfb07bd4d75a3229a571988ff8f",
              "IPY_MODEL_046b3e585ce943abb8ab62090b175f75"
            ],
            "layout": "IPY_MODEL_61942a7c31594de0995c6bd57dbf0d52"
          }
        },
        "93425a5dd2154ec78056b01f42da6272": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3c21b117c2264f18b04f01fd24c4159e",
            "placeholder": "​",
            "style": "IPY_MODEL_1faac31df4f242968897fe35b5d3858a",
            "value": "tokenizer_config.json: 100%"
          }
        },
        "4cf84dfb07bd4d75a3229a571988ff8f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9a5da6def2104ec4ad262072e2969db8",
            "max": 49,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_1a7a4b1c490342a29e26ce84f2da1b14",
            "value": 49
          }
        },
        "046b3e585ce943abb8ab62090b175f75": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3c55b6fd02d9462dade1ca17fc1e53a2",
            "placeholder": "​",
            "style": "IPY_MODEL_92d44168cbb140f494ad47a7de1e70e4",
            "value": " 49.0/49.0 [00:00&lt;00:00, 2.57kB/s]"
          }
        },
        "61942a7c31594de0995c6bd57dbf0d52": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3c21b117c2264f18b04f01fd24c4159e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1faac31df4f242968897fe35b5d3858a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "9a5da6def2104ec4ad262072e2969db8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1a7a4b1c490342a29e26ce84f2da1b14": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "3c55b6fd02d9462dade1ca17fc1e53a2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "92d44168cbb140f494ad47a7de1e70e4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "6cc0e7ded24340f58b46c5c5e8be9a6d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_ffff2c66cb9e4bd5bf7a1b4d3eeb974e",
              "IPY_MODEL_28cf104006514bf4b73acfdd65b98d2f",
              "IPY_MODEL_c71c045bca0e48c9826962c2f56d4c26"
            ],
            "layout": "IPY_MODEL_bbc1b5fa93594303950c3b9507d8732c"
          }
        },
        "ffff2c66cb9e4bd5bf7a1b4d3eeb974e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4d5b5829682945c0bdac0377377fc9c7",
            "placeholder": "​",
            "style": "IPY_MODEL_0d7a0c054fc147a58601a82be711e339",
            "value": "config.json: 100%"
          }
        },
        "28cf104006514bf4b73acfdd65b98d2f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d962fe2965324ce59e78f6fbe0c44506",
            "max": 570,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_11988aa34ba6418d856ce1dfefa0f764",
            "value": 570
          }
        },
        "c71c045bca0e48c9826962c2f56d4c26": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_07c09dd92e024ca9b49ab269a7a03e31",
            "placeholder": "​",
            "style": "IPY_MODEL_7029077f0b1d4e61838c176c7c5608db",
            "value": " 570/570 [00:00&lt;00:00, 43.2kB/s]"
          }
        },
        "bbc1b5fa93594303950c3b9507d8732c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4d5b5829682945c0bdac0377377fc9c7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0d7a0c054fc147a58601a82be711e339": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d962fe2965324ce59e78f6fbe0c44506": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "11988aa34ba6418d856ce1dfefa0f764": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "07c09dd92e024ca9b49ab269a7a03e31": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7029077f0b1d4e61838c176c7c5608db": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e869e761b324408d844965f3a9e8efd2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_08a4d9e35c3a4abe8d96a40940bdc25a",
              "IPY_MODEL_0046a269a98f419d82b3ddc3731788cc",
              "IPY_MODEL_44f26125cfc14282ae02097f27435fc2"
            ],
            "layout": "IPY_MODEL_bfe037dc18b041d1a37db5a4f24c3ff7"
          }
        },
        "08a4d9e35c3a4abe8d96a40940bdc25a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d1629298b3444b649baa3ecc6442d1da",
            "placeholder": "​",
            "style": "IPY_MODEL_4135cf72c80f4e59aa1f9efac33e2c62",
            "value": "vocab.txt: 100%"
          }
        },
        "0046a269a98f419d82b3ddc3731788cc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ce5a0391517a4030b9dd5932c36d7334",
            "max": 213450,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_1b44253544404c6b8518fbe601fdff11",
            "value": 213450
          }
        },
        "44f26125cfc14282ae02097f27435fc2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_43de27cb1822499c8b1b564bd331f6b6",
            "placeholder": "​",
            "style": "IPY_MODEL_aeeb5702b42a4c018eefb3427e86e5e9",
            "value": " 213k/213k [00:00&lt;00:00, 7.56MB/s]"
          }
        },
        "bfe037dc18b041d1a37db5a4f24c3ff7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d1629298b3444b649baa3ecc6442d1da": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4135cf72c80f4e59aa1f9efac33e2c62": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ce5a0391517a4030b9dd5932c36d7334": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1b44253544404c6b8518fbe601fdff11": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "43de27cb1822499c8b1b564bd331f6b6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "aeeb5702b42a4c018eefb3427e86e5e9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e55aa43cafa8419b9b9eb642ba15c79e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_52b40659c50543fbb22c2e66e4758f38",
              "IPY_MODEL_404d3f74600f49fe94cbc22575eec9f1",
              "IPY_MODEL_bd644608179141d08c7aa74f1d31dc5d"
            ],
            "layout": "IPY_MODEL_f551861b0221406e8002613062414d9d"
          }
        },
        "52b40659c50543fbb22c2e66e4758f38": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4ac4f6eccb6b457bb8eeba3199aac948",
            "placeholder": "​",
            "style": "IPY_MODEL_6c46d96052ef4a53b296103291f42f9f",
            "value": "tokenizer.json: 100%"
          }
        },
        "404d3f74600f49fe94cbc22575eec9f1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6fb0168fe6084301bd89b375a71b551f",
            "max": 435797,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_ecd34e97414542f58513aa42f77e9faf",
            "value": 435797
          }
        },
        "bd644608179141d08c7aa74f1d31dc5d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9db4384e50354c74be8e6d647a81a927",
            "placeholder": "​",
            "style": "IPY_MODEL_d616a4a1d58745208464a40793226edd",
            "value": " 436k/436k [00:00&lt;00:00, 5.40MB/s]"
          }
        },
        "f551861b0221406e8002613062414d9d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4ac4f6eccb6b457bb8eeba3199aac948": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6c46d96052ef4a53b296103291f42f9f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "6fb0168fe6084301bd89b375a71b551f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ecd34e97414542f58513aa42f77e9faf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "9db4384e50354c74be8e6d647a81a927": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d616a4a1d58745208464a40793226edd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "fa3d143d88cf406986a45f8adfcd274a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_030586334f094945a56620b325e9a902",
              "IPY_MODEL_a7d7f6bcd35d4010a945946d04dc360a",
              "IPY_MODEL_91191accb301443cb9fac8a4bd18af69"
            ],
            "layout": "IPY_MODEL_1eb04629d9db448c85500cf7481b750a"
          }
        },
        "030586334f094945a56620b325e9a902": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4e9f87b33ca24c18ae195d37470cf698",
            "placeholder": "​",
            "style": "IPY_MODEL_15494d9a3cb04f5b890216f277d0ec15",
            "value": "tokenizer_config.json: 100%"
          }
        },
        "a7d7f6bcd35d4010a945946d04dc360a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b77b1c4ccb2142daa6b9098cd881d85f",
            "max": 59,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_89d3a0a9ef17429ab8622eba1f2accef",
            "value": 59
          }
        },
        "91191accb301443cb9fac8a4bd18af69": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_fa1141b8cbe441a3a4977c0c5128f9e4",
            "placeholder": "​",
            "style": "IPY_MODEL_bd52af6d297541f6b78a82f480d71faf",
            "value": " 59.0/59.0 [00:00&lt;00:00, 5.67kB/s]"
          }
        },
        "1eb04629d9db448c85500cf7481b750a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4e9f87b33ca24c18ae195d37470cf698": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "15494d9a3cb04f5b890216f277d0ec15": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b77b1c4ccb2142daa6b9098cd881d85f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "89d3a0a9ef17429ab8622eba1f2accef": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "fa1141b8cbe441a3a4977c0c5128f9e4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bd52af6d297541f6b78a82f480d71faf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "38a5c3bfa063407d9d76772762031f4c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_0f6fa48b6473456190caab9d04f804fb",
              "IPY_MODEL_e47e207f601c4fffaedf9a85da5c2fd7",
              "IPY_MODEL_4ef3006f14e24662803ff8c0e36c0d17"
            ],
            "layout": "IPY_MODEL_e991c1eef9494844a0bdac6a56b151c3"
          }
        },
        "0f6fa48b6473456190caab9d04f804fb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5e6124e0d61e4d728e24c016ee6e30a5",
            "placeholder": "​",
            "style": "IPY_MODEL_562f41b546d6492b902bdd802ffc7e2a",
            "value": "config.json: 100%"
          }
        },
        "e47e207f601c4fffaedf9a85da5c2fd7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_310bacd5f5824731ac7444e70ebb975a",
            "max": 433,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_c8b50cd2c0414bd080c2518e99c0f205",
            "value": 433
          }
        },
        "4ef3006f14e24662803ff8c0e36c0d17": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_14371a4507fd44f18be9f23f184d0bdb",
            "placeholder": "​",
            "style": "IPY_MODEL_0f78d376d97b42698322700cad78c69e",
            "value": " 433/433 [00:00&lt;00:00, 38.6kB/s]"
          }
        },
        "e991c1eef9494844a0bdac6a56b151c3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5e6124e0d61e4d728e24c016ee6e30a5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "562f41b546d6492b902bdd802ffc7e2a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "310bacd5f5824731ac7444e70ebb975a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c8b50cd2c0414bd080c2518e99c0f205": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "14371a4507fd44f18be9f23f184d0bdb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0f78d376d97b42698322700cad78c69e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "308d3d96f9264eaa916270e884772523": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_ae9369d61fe14d92a39cd9961441ebcb",
              "IPY_MODEL_a814ed25701d4149a2f4aeadd14f8acb",
              "IPY_MODEL_f3908c3178304185b185843aeca8ccd8"
            ],
            "layout": "IPY_MODEL_d50bcdd5a51a4c79bc16a6d7350664cd"
          }
        },
        "ae9369d61fe14d92a39cd9961441ebcb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_59fd4e7091f548b28e80b2f0d9bb0c8d",
            "placeholder": "​",
            "style": "IPY_MODEL_18b68d908487465597772b0608dfe3af",
            "value": "vocab.txt: "
          }
        },
        "a814ed25701d4149a2f4aeadd14f8acb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1d7d9b51cdfc40929b30f7d3d99e027d",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_316553ca36e5466ea4ae08a46f821929",
            "value": 1
          }
        },
        "f3908c3178304185b185843aeca8ccd8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e202c3d8254046868d484f7602580fdc",
            "placeholder": "​",
            "style": "IPY_MODEL_faa686874fc54460a03dc86fbbd7ebf8",
            "value": " 235k/? [00:00&lt;00:00, 17.5MB/s]"
          }
        },
        "d50bcdd5a51a4c79bc16a6d7350664cd": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "59fd4e7091f548b28e80b2f0d9bb0c8d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "18b68d908487465597772b0608dfe3af": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "1d7d9b51cdfc40929b30f7d3d99e027d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "20px"
          }
        },
        "316553ca36e5466ea4ae08a46f821929": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "e202c3d8254046868d484f7602580fdc": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "faa686874fc54460a03dc86fbbd7ebf8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}